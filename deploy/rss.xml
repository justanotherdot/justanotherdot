<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:media="http://search.yahoo.com/mrss/">
  <channel>
    <title>justanotherdot</title>
    <link>https://justanotherdot.com</link>
    <atom:link href="https://justanotherdot.com/rss.xml" rel="self" type="application/rss+xml" />
    <description>Personal blog of Ryan James Spencer</description>
    <category>Technology</category>
    <copyright>2018 Ryan James Spencer</copyright>
    <language>en-us</language>
    
    <item>
      <title>Discovering Problematic Commits With Git Bisect</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/discovering-problematic-commits-with-git-bisect.html</link>
      <guid>https://justanotherdot.com/posts/discovering-problematic-commits-with-git-bisect.html</guid>
      <pubDate>Tue, 30 Jun 2020 08:50:46 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>A problem has happened due to some offending code landing on your main,
production branch. You use <code>git</code> and your best bet is to keep rolling back
commits until the system finds itself in a steady state. You come late into this
picture and you're unsure how far back you need to go.</p>
<p>Firstly, you ought to be using something that alleviates the need for running
through out an entire CI pipeline in order to produce a deploy. I've talked a
bit about this in the past on my <a href="https://www.youtube.com/playlist?list=PLG8S6YrJRoYI3CIUqvGX4NBSaMWZxe9in">screencasts about setting up a
CI</a>
regarding the distinction between a deployment and a release. If you have
something like this, rolling back a fair few number of releases is probably
trivial to attempt.</p>
<p>However, if you don't have this in place or you really do need to roll through
an entire CI pipeline, then you can still using something like <code>git bisect</code> to
find the first offending commit.</p>
<p><code>git bisect</code> runs a binary search across a span of commits. The general
framework for running a <code>git bisect</code> is the following:</p>
<ol>
<li><code>git bisect start FROM_COMMIT TO_COMMIT</code></li>
<li>Test the commit, determine if it is good or bad, and tell <code>git</code> with <code>git bisect good</code> or <code>git bisect bad</code>. You can also skip commits with <code>git bisect skip</code>.</li>
</ol>
<p>The trick to finding the first offending commit isn't to run the same steps your
CI pipeline would; you should have all those builds available for review and
they will tell you whether or not a build truly succeeded, unless you can't
trust your CI and, in that case, you have other issues on your hand. Crafting
your own test and running it each time in (2) will help guide you in the
decision to making a choice for whether or not the commit is <code>good</code> or <code>bad</code> in
light of what you are trying to find.</p>
<p>You can alleviate the tedium of (2) by using <code>git bisect run</code> and supplying a
program. If the script fails or you ever want to abandon your search midway, you
can always run <code>git bisect reset</code> and start over again. There are some tricks to
how you can craft the exit codes from the script you write for <code>git bisect run</code>
that really make this process a lot faster. To give a sense of the range of use
for <code>git bisect</code> as a general search tool, let's call our test script
<code>predicate</code>.</p>
<pre><code class="language-bash">#!/bin/sh -eux

# NB.
# exiting with 125 tells `git bisect run` to skip this commit.
# exiting with 0 means the commit is `good'.
# exiting with 1 means the commit is `bad'.

cargo build || exit 125 # skip failed builds.
target/debug/program &gt; /tmp/program.out
[ ! diff /tmp/program.out /tmp/program.snapshot ] &amp;&amp; exit 1
</code></pre>
<p>You'll need to place this script somewhere outside of the current git repository
as it will mess up checkouts between commits, and, as always, ensure it is
executable. Another pitfall that can hurt is how you structure your git history;
if you use merge styled commits, as is the default for GitHub, then you will
probably not care if the commits in between the merge commits fail. You can do
one of two things: output the list of all merge commits that match a particular
pattern, e.g., the way GitHub does it, or you could also, if your history is
clean enough, use <code>git show --no-patch --format=&quot;%P&quot; &lt;commit hash&gt;</code> to determine
if a commit has more than one parent; you'll see more than one hash noted in the
output. You can find quick version I hacked together filtering out commits with
the GitHub styled subject lines you can tweak at <a href="https://gist.github.com/justanotherdot/d587f5bea0f6937ef7f7bda53f23ac56">this
gist</a>.</p>
<p>In the above example I show testing against a snapshot given some program
output, but really the predicate could be <em>anything</em>. Using <code>git bisect</code> to
drive things like textual search has better alternatives like the &quot;pickaxe&quot; with
<code>-S</code> in <code>git log</code>, but if you want to find the first commit where something
happened and it isn't part of the data that git saves, such as program behavior,
then <code>git bisect</code> will let you find it far faster. I've also used this in the
past to whip up quick, minimal tests that I can inject after the checkout and
run some test suite against. <code>git bisect run</code> takes any binary, too, meaning you
don't <em>have</em> to use a shell script like I have in the example above. The real
aim is not to think of the <code>predicate</code> script or program as something that has
to be about failures; you can easily use it to discover first instances of any
kind of particular behavior a program may exhibit, as long as it is reproducible
locally.</p>
<p>Granted, a system may be so complex in it's operation that there is no way for
you to locally verify the offending commit. Mitigating or &quot;stopping the
bleeding&quot; is something that needs to happen quick. With that said, <code>git bisect</code>
might be a better tool for analysis later, when the pressure is low and you can
better craft a test or predicate to find where the fault first occurred, but if
you haven't spent a lot of time with release engineering or you are in a place
where it could use some improvements, running <code>git bisect</code> in this matter might
help save you precious time, and even if you do have good release engineering in
place, it might help save you a pulling out a lot of hair finding the place
where code has effectively broken down.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Feature Flag Cleanly With Blocks</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/feature-flag-cleanly-with-blocks.html</link>
      <guid>https://justanotherdot.com/posts/feature-flag-cleanly-with-blocks.html</guid>
      <pubDate>Mon, 29 Jun 2020 19:45:44 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>I recently had to feature flag some code in JavaScript and felt myself wishing I
had Rust's expression-based blocks. In the JavaScript code, I didn't want to
break out the logic into its own function or module as I the code was a proof of
concept and deciding on an interface early on would distract me. In languages
that aren't expression and block oriented, you have one of two choices:</p>
<ol>
<li>Use an immediately invoked function</li>
<li>Have 'unset' or 'default' variables on the outside of some scope and a scope that
potentially assigns to the variables</li>
</ol>
<p>Here's an example of the two cases in JS:</p>
<pre><code>// with an IIFE.
const featureFlaggedItem = (() =&gt; {
  if (!featureFlag) {
    return {
      // defaults without the flag.
      // the steady state of the system.
    };
  }

  // feature flagged code.
})();
</code></pre>
<pre><code>// or with an assignment, relying on side effect.
let featureFlaggedItem = {
  // defaults without the flag.
  // the steady state of the system.
};
if (featureFlag) {
  featureFlaggedItem = {
    // featureFlagContent
  };
}
</code></pre>
<p>The problem with the side effect approach is that we lose the nice benefit of
having <code>featureFlaggedItem</code> as <code>const</code> as well as keeping things nice and tidy
for easier deletion later on. I personally refuse to use the second approach.
Rust let's you easily write the above code as following:</p>
<pre><code>let feature_flagged_item = {
  if (!featureFlag) {
    return {
      // defaults without the flag.
      // the steady state of the system.
    };
  }

  // feature flagged code.
};

// or ...

let feature_flagged_item = if (featureFlag) {
  // feature flagged code.
else {
  return {
    // defaults without the flag.
    // the steady state of the system.
  };
};
</code></pre>
<p>But this is wildly useful for a lot of things beyond one-off changes. Maybe you
need a one-off value for a function argument but you don't want to immediately
invoke a closure or define a function to call. With blocks you can tuck all
sorts of code into places with or without assignment. If you have a lot of
&quot;identifier&quot; pollution going on in a given scope, say with a lot of temporary
variables, you can tuck them under the rug with blocks. I tend to have a lot of
assignments that break up code like a newspaper article but there is some
dispute around shadowing. I am pro shadowing in Rust as I feel it bars a class
of bugs, but you can understandably avoid shadowing if you so care; <a href="https://github.com/rust-lang/rust-clippy/blob/master/clippy_lints/src/shadow.rs">using
<code>clippy</code>s lint on the
matter</a>,
or ensuring the temporary shadowed variable(s) are only present for the inner,
temporary, scope.</p>
<p>The best part is that when the &quot;one-off&quot; value becomes less &quot;one-off&quot;, you can
easily take the block and dump the contents straight into a function and it will
work as-is, with or without the superfluous curly braces! Splitting up the
decisions around what is done to build up the value versus the surface area of
the value (its interface) is a great way to guarantee the interface is what you
really want it to be rather than what it had to be in order to figure out its
implementation. In general it's best to split up work in such a way that you can
focus on each piece in isolation without the other pieces distracting you.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>An Opinionated Guide To Structuring Rust Projects</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/an-opinionated-guide-to-structuring-rust-projects.html</link>
      <guid>https://justanotherdot.com/posts/an-opinionated-guide-to-structuring-rust-projects.html</guid>
      <pubDate>Fri, 12 Jun 2020 20:49:59 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Cargo's initial project layout is good for bootstrapping a project but as time
goes on there is a growing need to automate chores, wrestle with compile times,
and increase discoverability for maintainers and contributors. I've previously
written about <a href="https://www.justanotherdot.com/posts/structuring-rust-projects-with-multiple-binaries.html">how I personally orchestrate chores on a Rust
project</a>
but this article will focus on the latter two points.</p>
<p>The highest leverage act you can do with structuring a Rust project is to break
it into independent crates. Chunks of logic that have shown stability over a
window of time are immediate candidates for splitting into a crate, as well as
semantic boundaries between concepts in a given codebase. For example, you may
want to keep sets of types distinct from one crate to the next in the same
project or you might want to enforce that driver logic should be as minimal as
possible with only some glue tying together other core logic libraries. Keeping
things cleanly separated means clustered concepts are easier to locate while we
can aggressively cache crates that don't change much. In terms of naming I
prefer each crate to be in kebab-case and to use the project's name as the
prefix for the sub crate. If our project name was &quot;foo&quot; then each crate would be
prefaced with &quot;foo-*&quot;. You can tie all of these crates into a workspace for a
central place to build the entirety of the project. If our project had three
crates in it, we could put a <code>Cargo.toml</code> at the root of our project with the
contents:</p>
<pre><code>[workspace]
members = [
  &quot;foo-core&quot;,
  &quot;foo-cli&quot;,
  &quot;foo-benchmark&quot;,
]
</code></pre>
<p>The general advice for build times is to first use something like <code>cargo check</code>
and move to <code>cargo test</code> and finally some form of <code>cargo build</code> with or without
options. A way to drive down build times is to keep building all the time as you
make changes. I prefer to run multiple loops with various subcommands specified
while I code. You can get around locking issues on the same <code>.cargo</code> and
<code>target</code> directories by changing these with <code>CARGO_HOME</code> and <code>CARGO_TARGET_DIR</code>
respectively. This means you can spin up several <code>watchex</code>, <code>cargo-watch</code>, or
<code>entr</code> loops as shell jobs or in separate terminals. To give an example I will
sometimes do <code>cargo watch</code>, which does <code>cargo check</code> by default, and then will
specify <code>CARGO_HOME=/tmp CARGO_TARGET_DIR=/tmp/target cargo watch -x test</code> to
get test information as it shows up.</p>
<p>If you're using a CI and can afford it, pushing jobs off to a remote server to
build at the same is yet another extension to this &quot;build all the time&quot;
mentality. When you're happy with your changes you are closer to merging. If you
pair this with something like <code>sccache</code> for caching crates across projects, you
can see some nice gains on compile times across several build bots or, if you
run a similar environment to your build bots, you can even share crates from
both local development machine and build bots at the same time. Once <code>sccache</code>
is installed, you can export <code>RUSTC_WRAPPER=$(which sccache)</code> and check if it's
running across builds with <code>sccache -s</code>. I'm unsure what gains you'd see over
<code>cargo</code> on a single machine as I've yet to dive into the core of how <code>sccache</code>
works under the hood but it's harmless to run for a try.</p>
<p>You have the option to be disciplined and keep all crates on the same version to
make downstream consumption easier, such that if you want to install <code>foo</code> and
<code>foo-bar</code> you could know that version <code>2.0.0</code> is valid for both crates. You can
also setup the installation as a transitive thing from some 'central' crate that
could always install the &quot;right&quot; version of <code>foo-bar</code> given some build feature
flag. You may want more flexibility in what version of <code>foo-bar</code> you use,
however, and as long as <code>foo</code> doesn't also depend on <code>foo-bar</code> you shouldn't
have to do any juggling.</p>
<p>I've left some stray tricks for last in the possibility that they may help your
specific case. You can try linking with <code>lld</code> or <code>gold</code> instead of the standard
linker. You can do this with <code>RUSTFLAGS=&quot;-C link-arg=-fuse-ld=lld&quot;</code> to use <code>lld</code>
at least on linux but I don't always see speedups from this. Setting
<code>CARGO_BUILD_JOBS</code> to a number higher than the number of capabilities (cores)
you have on your system is likely to <em>increase</em> compile times, but you could
split your test, check, and build jobs across lower number of cores, such as two
cores for <code>test</code> and another two for <code>check</code> on a four-core machine. If you are
truly desparate you can try gimmicks like building to a less intense target.
I've written a shell script that will build all possible cross-compile targets
<code>rustc</code> can attempt and report build times in the event that they succeed. You
can find the gist
<a href="https://gist.github.com/justanotherdot/ca1f163754e9a90f6c6b9dfb25a0598f">here</a>
and can invoke it with <code>x-compile-test</code>. You can also narrow down which targets
you want to use with a regex by specifying <code>FILTER=x86_64 x-compile-test</code>.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Picking Variants or Fields Out Of Collections of Enums</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/picking-variants-or-fields-out-of-collections-of-enums.html</link>
      <guid>https://justanotherdot.com/posts/picking-variants-or-fields-out-of-collections-of-enums.html</guid>
      <pubDate>Wed, 10 Jun 2020 20:06:54 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Occasionally you want to pull out a specific field or variant out of one or more
enums. Doing this with pattern matching is tedious and verbose, but there's a
simple way to use methods and combinators to do exactly what you want.</p>
<p>There's a pattern I use to solve both of these. If you already have the
collection in hand, you can write a simple method that operates on the type
named something like <code>as_foo</code> where foo is the name of the variant or field name
you are after. There's a clippy lint that says <code>as_*</code> functions should always
take references should I've followed the lint in the following example but it
doesn't really matter what you name the method and it's fine to have the method
take ownership of the value, too, if that makes sense for your use case. When
you define a method you can use it either with the basic method syntax
<code>value.as_foo()</code> or you can access it as an associated function e.g.
<code>Type::as_foo(value)</code>. Then we can use either method in tandem with the
<code>filter_map</code> or <code>flat_map</code> methods of an iterator. I personally prefer the more
terse way of passing the associated function instead of the closure, which is
somtime referred to as &quot;point free&quot; style where the arguments, or points, are
not mentioned:</p>
<pre><code>#[derive(Debug, Clone, PartialEq)]
enum E {
    A { x: i32 },
    B { x: i32 },
}

impl E {
    pub fn as_x(&amp;self) -&gt; Option&lt;i32&gt; {
        // might need to rearrange this
        // if a variant is added that
        // does not include x.
        Some(match self {
            E::A { x } =&gt; *x,
            E::B { x } =&gt; *x,
        })
    }

    pub fn as_b(&amp;self) -&gt; Option&lt;&amp;E&gt; {
        match self {
            x @ E::B { .. } =&gt; Some(x),
            E::A { .. } =&gt; None,
        }
    }
}

pub fn main() {
    // method access off type.
    let a = E::A { x: 1 };
    let b = E::B { x: 2 };
    assert_eq!(a.as_x(), Some(1));
    assert_eq!(b.as_x(), Some(2));

    // associated function on impl.
    let a = E::A { x: 1 };
    let b = E::B { x: 2 };
    assert_eq!(E::as_x(&amp;a), Some(1));
    assert_eq!(E::as_x(&amp;b), Some(2));

    // in a collection.
    let a = E::A { x: 1 };
    let b = E::B { x: 2 };
    let as_and_bs = vec![a, b];
    let xs = as_and_bs.iter().filter_map(E::as_x).collect::&lt;Vec&lt;i32&gt;&gt;();
    assert_eq!(xs, vec![1, 2]);

    // selecting a field as a dummy pattern match.
    let b = E::B { x: 2 };
    let xs = Some(&amp;b).and_then(E::as_b);
    assert_eq!(xs, Some(&amp;E::B { x: 2 }));
}
</code></pre>
<p><a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5bb110c4a9981caa3bc3317b9e2350c3">Playground</a>.</p>
<p>Pattern matching is powerful but sometimes you can reduce the number of explicit
pattern matches you perform by taking advantage of functions and combinators and
keeping the logic small and simple, letting you reason about what the result
ought to be on the other end. In the last case using <code>and_then</code> above, we can
reason that whenever we call <code>as_b</code> we're sure to get a single pattern match if
we must simply checking for <code>Some(E::B { .. })</code> or <code>None</code>. The compiler may not
understand that, though, and you'll most likely have to include a wildcard case,
but the brilliance of combinators is that you can chain them together in a
pipeline similarly to the fluid interface that iterators present.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Building An Intuition for Pattern Matching</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/building-an-intuition-for-pattern-matching.html</link>
      <guid>https://justanotherdot.com/posts/building-an-intuition-for-pattern-matching.html</guid>
      <pubDate>Tue, 19 May 2020 20:08:50 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p><em>What's the point of pattern matching if we already have conditionals and
variable assignment in a language?</em></p>
<p>Pattern matching helps tease apart values and construct control flow using the
shape of data rather than bespoke logic, methods on types, or special fields on
a struct. For example, in languages that don't have first-class support for sum
types, enums in Rust, you'd have to encode the variant as a unique tag on
something like a struct, e.g.,</p>
<pre><code>struct Option {
    tag: String, // maybe one of 'Some' or 'None'.
    // and so on.
}
</code></pre>
<p>Then the <code>tag</code> field can be checked by traditional control flow. This is precisely
how it is done in languages like TypeScript, but in Rust, where sum types are
supported, we have no unique <code>tag</code> field to check and, since the compiler hides
this information away from us, we can't write a method to describe which variant
we have in our hands. It would be a bit clumsy if the compiler generated methods
for us as we might want to have methods with the same name!</p>
<p>Any kind of syntactic sugar used to construct a value is known as a
<strong>constructor</strong>, such as building values for structs, enums, tuples, and so on.
Pattern matching gives us a way to describe the shape of data using constructors
to match on and what to do if the value matches. This analogy isn't perfect, but
I like to think of patterns as mirrors with outlines; if the reflection matches
the outline of a constructor, we go down that path of logic, possibly with some
new values drawn out of the data. Here are some common patterns for
constructors:</p>
<pre><code>pub struct S {
    field: i64,
}

pub enum E {
    FirstVariant,
    SecondVariant,
}

pub fn main() {
    // Tuples.
    let a = (&quot;Fizz&quot;, &quot;Buzz&quot;);
    match a {
        (p, q) =&gt; println!(&quot;{}&quot;, format!(&quot;{}{}&quot;, p, q)),
    }

    // Numeric literals.
    let b = 123;
    match b {
        std::i32::MIN..=99 =&gt; println!(&quot;under one-hundred&quot;),
        100 =&gt; println!(&quot;exactly one-hundred&quot;),
        101..=std::i32::MAX =&gt; println!(&quot;above one-hundred&quot;),
    }

    // Strings.
    let c = &quot;A string.&quot;;
    match c {
        &quot;A string.&quot; =&gt; println!(&quot;it's _the_ string.&quot;),
        _ =&gt; println!(&quot;some other string.&quot;),
    }

    // Enums.
    let x = E::SecondVariant;
    match x {
        E::FirstVariant =&gt; println!(&quot;first variant of E&quot;),
        E::SecondVariant =&gt; println!(&quot;second variant of E&quot;),
    }

    // Structs.
    let y = S { field: 100 };
    match y {
        S { field } =&gt; println!(&quot;field is: {}&quot;, field),
    }

    // Slices.
    let z = vec![1, 2, 3];
    match *z { // we need * to dereference Vec to a slice.
        [a, b] =&gt; println!(&quot;{} + {} = {}&quot;, a, b, a + b),
        [a, b, c] =&gt; println!(&quot;{} + {} * {} = {}&quot;, a, b, c, a + b * c),
        _ =&gt; println!(&quot;any other unmatched vector&quot;),
    }
}
</code></pre>
<p><a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=483dd9713719d848f7e221047961e8c8">Playground</a></p>
<p><em>Where can we put patterns?</em></p>
<p><code>match</code> is the traditional way of doing pattern matching but not the only way.
Matches work top-to-bottom, and they ensure that every case is handled, known as
<strong>exhaustivity checking</strong>.</p>
<pre><code>enum Val {
    Integer(i64),
    Float(f64),
}

match {
    Val::Integer(x) =&gt; println!(&quot;It's an integer: {}&quot;, x), // one &quot;arm&quot; or &quot;case&quot;
    // without anything else, this is non-exhaustive; it doesn't include Val::Float!
}
</code></pre>
<p>which fails to compile with the following error:</p>
<pre><code>error[E0004]: non-exhaustive patterns: `Float(_)` not covered
 --&gt; src/main.rs:8:11
  |
1 | / enum Val {
2 | |     Integer(i64),
3 | |     Float(f64),
  | |     -- not covered
4 | | }
  | |_- `Val` defined here
...
8 |       match v {
  |             ^ pattern `Float(_)` not covered
  |
  = help: ensure that all possible cases are being handled, possibly by adding wildcards or more match arms

error: aborting due to previous error
</code></pre>
<p><a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=65e0688f852c45e4c1712f2481ef2231">Playground</a></p>
<p>Pattern matches in <code>let</code>s and function arguments will also work but must be
<strong>irrefutable</strong>, which is a fancy way of saying that the pattern can never fail.
Any pattern that covers all possible values of a type is irrefutable. It could
be literal like a range or with a variable, which will always capture a value
and, therefore, match.</p>
<pre><code>// works.
pub fn f((x, y): (i32, i32)) -&gt; i32 {
    x + y
}

// does not work.
//pub fn g((1, 2): (i32, i32)) {
// fails on anything other than g(1, 2).
// the compiler rejects this as a refutable pattern
// which is in place where only an irrefutable pattern can be.
//}

pub fn main() {
    //let 12 = 12; // fails.
    let x = 12; // succeeds.
    f((x, x));
    let std::i32::MIN..=std::i32::MAX = 12; // succeeds, covers all values.
}
</code></pre>
<p><a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=d21343054645f8500c7701fdcc174171">Playground</a></p>
<p>With functions, this is a bit different from other functional languages like
Erlang or Haskell. In those languages, you can write multiple function
declarations, each with their pattern match, and the function that matches the
pattern will be the one that executes. You can think of this like match
expressions but for functions! Rust, unfortunately doesn't have this, but it's
still fine to take the full value from the argument and make the entire function
body a <code>match</code>. So this in Elixir:</p>
<pre><code>def f(1) do
  // first case.
end

def f(2) do
  // first case.
end

def f(x) do
  // final, irrefutable case.
end
</code></pre>
<p>could be expressed as:</p>
<pre><code>pub fn f(x) {
    match x {
        1 =&gt; , // first case.
        2 =&gt; , // second case.
        x =&gt; , // final, irrefutable case.
    }
}
</code></pre>
<p><em>Isn't this a bit tedious? What if you don't care about particular portions of a
shape?</em></p>
<p>Ignoring particular values is easy with the <code>_</code> variable, or we can prefix a
variable name with <code>_</code> if we want to keep the name but ensure it can't be used.
This is formally known as a <strong>wildcard</strong>, but informally known as the &quot;don't
care&quot; variable. The equivalent for structs is <code>..</code> where we can specify only the
fields we care about and ignore the rest. These two dots, a bit like an
ellipse, must be mentioned in the last place of the struct.</p>
<pre><code>struct S {
    field: i32,
    property: (i32, i64),
}

pub fn main() {
    let s = S {
        field: 42,
        property: (12, 13),
    };
    match s {
        S { property: (12, _), .. } =&gt; println!(&quot;{}&quot;, 12),
        S { field, .. } =&gt; println!(&quot;{}&quot;, field),
        // or `S { field, property: _ } =&gt; println!(&quot;{}&quot;, field),`
    };
}
</code></pre>
<p><a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5045a6587c31f5d954ab52467b735d67">Playground</a></p>
<p><em>What if I want to describe some nested shape, but match on the whole thing?</em></p>
<p>To do this you can use <code>@</code> in front of the pattern, known informally as the
&quot;as-pattern&quot;. As of this writing, binding both the whole pattern plus parts of
the pattern isn't allowed.</p>
<pre><code>#[derive(Debug)]
struct S {
    field: i32,
}

pub fn main() {
    let s = S { field: 42 };
    match s {
        S { field: x @ 10..=100, } =&gt; println!(&quot;{:?}&quot;, x),
        S { field } =&gt; println!(&quot;{}&quot;, field),
    };
}
</code></pre>
<p><a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c0afcb3477a7e0b66e2aaa1a1912abf8">Playground</a></p>
<p><em>What if you don't want to specify literals or bind to variables?</em></p>
<p>If you want to do more complicated checking on bound variables, you can use a
match guard. A guard is introduced with an <code>if</code> after the pattern, but before
the fat arrow <code>=&gt;</code>, and the resulting value must be a boolean value, as would be
the case for other conditionals. You can't use guards on <code>let</code> and function
argument patterns.</p>
<pre><code>#[derive(Debug)]
struct S {
    field: i32,
}

pub fn main() {
    let s = S { field: 42 };
    match s {
        S { field } if field % 2 == 0 =&gt; println!(&quot;only executes when field is even&quot;),
        _ =&gt; println!(&quot;all remaining values go here&quot;),
    };
}
</code></pre>
<p><a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=41ed619c36361f7c9481df2c2c6b9ccc">Playground</a></p>
<p><em>What about cases where you might want to combine several possible patterns into
one match arm?</em></p>
<p>You can combine patterns using what is known as an <code>or-pattern</code> by using a <code>|</code>
to try several patterns in a row. This way you can compress several patterns
into one match arm.</p>
<pre><code>enum Enum {
    A,
    B,
}

pub fn main() {
    let x = Enum::A;
    match x {
        Enum::A | Enum::B =&gt; println!(&quot;matches&quot;),
    };

    // or possibly in an if/while-let pattern match.
    let x = Some(12);
    if let Some(13) | Some(12) = x {
        println!(&quot;works&quot;);
    }
}
</code></pre>
<p><a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=3727a37c698f041316e3b382b11fb3ab">Playground</a></p>
<p><em>What if I want to check a pattern but I don't want all of the machinery of a
<code>match</code> statement?</em></p>
<p>The <code>matches!</code> macro lets us write a test to see if a supplied pattern will
match a given value. The macro doesn't allow you to bind values, but it can
allow you to extend a pattern using guards which is another handy use I've found
for it (see the quirks later for more details on a precise application).</p>
<pre><code>pub fn main() {
    assert_eq!(matches!(12, std::i32::MIN..=100), true);
    assert_eq!(matches!(None, Some(42)), false);
}
</code></pre>
<p><a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=f523c33e7bf8b893a4253b41c78eb7b3">Playground</a></p>
<h3>Conclusion</h3>
<p>And now you know the bulk there is to pattern matching in Rust! As a recap,
patterns are tested on a value, and if they line up, they will execute some branch of
logic or bind some values to identifiers, or both! You can check
complicated logic with guards, ignore portions of patterns with wildcards, bind
whole matches with as-patterns, combine patterns with or-patterns, and
test for pattern matches with the <code>matches!</code> macro. You also can use patterns in
a number of places outside of <code>match</code> and the relevant control flow expressions
such as in <code>let</code> bindings and function arguments.</p>
<h3>Quirks</h3>
<p>These quirks are more around ergonomic uses of patterns rather than any
dealbreakers for writing production-grade code. You can happily skip this
section if you are still processing the information from above.</p>
<p>First up, nested or-patterns or in other locations, such as function arguments,
are unstable and require the <code>#![feature(or_patterns)]</code> attribute. Another way
around the nested or-patterns is to use the <code>matches!</code> macro in a guard:</p>
<pre><code>#[derive(Debug)]
struct Container(Possibly);

#[derive(Debug)]
enum Possibly {
    A,
    B,
}

fn main() {
    let container = Container(Possibly::A);
    match container {
        // Container(Possibly::A | Possibly::B) =&gt; // won't work
        Container(inner) if matches!(inner, Possibly::A | Possibly::B) =&gt; {
            dbg!(inner);
        }
        _ =&gt; {
            dbg!(&quot;won't happen unless Possibly changes&quot;);
        }
    };
}
</code></pre>
<p><a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=3c204e9bed56ff5c292d1d84e80226bb">Playground</a></p>
<p>Exclusive ranges for matching against numbers that aren't literals can be
enabled with <code>#![feature(exclusive_range_pattern)]</code>. As it stands, you can
only express inclusive ranges:</p>
<pre><code>fn main() {
    let std::i32::MIN..=std::i32::MAX = 12; // works.
    //let std::i32::MIN..std::i32::MAX = 12; // refuses to compile.
}
</code></pre>
<p>And lastly, bindings after <code>@</code> aren't supported unless you turn them on with
<code>#![feature(bindings_after_at)]</code>. This is a bit tricky anyway given ownership
and borrowing semantics and how that plays into binding both the top-level value
and the values inside of them.</p>
<pre><code>#![feature(bindings_after_at)]

#[derive(Debug)]
struct S {
    field: (i32, i32),
}

fn main() {
    let x = S { field: (1, 2) };
    match x {
        S {
            field: tuple @ (ref a, ref b),
        } =&gt; println!(&quot;{:?}, {} + {} = {}&quot;, tuple, a, b, a + b),
    }
}
</code></pre>
<p><a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=2b605ec39ed4884bb4ab92b5c3cc69bc">Playground</a></p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Benchmark It!</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/benchmark-it.html</link>
      <guid>https://justanotherdot.com/posts/benchmark-it.html</guid>
      <pubDate>Sat, 09 May 2020 15:22:46 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Performance is something users <em>feel</em>. Maybe you're in an organization that
doesn't care about performance, and you think they should. Perhaps there are
lofty claims that performance <em>does</em> matter, but loose arguments for one
approach over another filled with baseless claims like &quot;X is <em>fast</em>!&quot;. The only
way to get past this conjecture is with numbers, and we collect numbers with
benchmarks.</p>
<p><strong>Benchmarking</strong> is the act of measuring latency or throughput of some component
regardless of size. <strong>Profiling</strong> is a means to explore the constituent parts of
where code spends its time. There is a dizzying array of variables we can tweak
to impact the performance of user experience on modern platforms, but benchmarks
should come first before we begin profiling. With benchmarks, we get
reproducibility, enabling others to test our claims and verify our results for
their use cases. As we generate measurements for targets, we can store the
results away so we can visualize the data however we please or compare
particular runs tied to specific code changes. In this sense, benchmarks provie
us a historical context of performance.</p>
<p><strong>Latency</strong> is the duration of time the component in question takes to complete.
<strong>Throughput</strong>, on the other hand, is the amount of work completed in a window of
time. <strong>You cannot trust the first number you get out of a single trial.</strong> Hence, we
focus on arithmetic mean averages or medians from multiple measurements. A
server might have an average latency of 123 milliseconds, or a JSON parser might
boast an average of 2.6GiB processed per second.</p>
<p>Cargo does have built-in support for benchmarking, and it works in a pinch but
hides the influence of outliers on your results. This is handy if you want
something you can quickly run and glance at to make improvements, but tests are
<strong>reliable</strong> if they are low on noise.</p>
<p>To gain this insight, I strongly recommend
<a href="https://github.com/bheisler/criterion.rs">criterion.rs</a>. It does all the things
<code>cargo-bench</code> does, along with providing additional statistical metrics to help
us determine if a benchmark is worth trusting.</p>
<p>By default, criterion takes one-hundred measurements. It then tries to find a
line that fits these measurements using linear regression. How well this line
fits the data is designated by the metric <strong>R^2</strong>. The <strong>slope</strong> of this line,
along with the <strong>mean</strong> and <strong>median</strong>, offer ways of viewing &quot;center&quot; for the
data. If there are no outliers, then slope, mean, and median should be similar.
<strong>Standard deviation</strong> is the dispersal of values around the mean, and <strong>MAD or
Median Absolute Deviation</strong> is the same for the median. A high standard
deviation or MAD might indicate a higher than expected level of noise.
Similarly, if the R^2 is low, then the difference between timings is high. To
get reliable tests, we want each iteration to be the same. There is bound to be
<em>some</em> noise and differences between runs, but we are trying to find the values
we are confident aren't merely aberrations.</p>
<p>You can add it to a project by adding the dependency to your Cargo.toml:</p>
<pre><code>[dev-dependencies]
criterion = &quot;0.3&quot;
</code></pre>
<p>Then, in the same file we can add the benchmark:</p>
<pre><code>[[bench]]
name = &quot;benchmark_it&quot;
harness = false
</code></pre>
<p>benchmarks live in distinct files under the <code>benches</code> directory in the root of
your project, named the same as the name we gave in the manifest:</p>
<pre><code>$ fd benchmark_it
benches/benchmark_it.rs
</code></pre>
<p>Imagine our crate is called <code>crate</code> and it exposes a public function named
<code>function</code> that we want to measure, the most basic benchmark looks something
like the following:</p>
<pre><code>use criterion::{black_box, criterion_group, criterion_main, Criterion};
use crate::function;

pub fn criterion_benchmark(c: &amp;mut Criterion) {
    c.bench_function(&quot;benchmark_function&quot;, |b| b.iter(|| function(black_box(20))));
}

criterion_group!(benches, criterion_benchmark);
criterion_main!(benches);
</code></pre>
<p>and you can run this benchmark with <code>cargo bench</code>. After the tests run you get
output on the command line. If you have gnuplot installed you can also view
an HTML report generated at <code>target/criterion/report/index.html</code> you can open in
a browser. If you want access to the raw data, you can find that dumped as
CSVs under <code>target/criterion/benchmark_function/{base,change,new}/raw.csv</code>. As
you run the benchmarks, the base gets replaced with the last latest run, and the
latest run is compared to visualize improvements or regressions.</p>
<p>Criterion's reports include explanations in reports, along with <a href="https://bheisler.github.io/criterion.rs/book/index.html">fantastic
documentation</a>
outlining how the test harness works and how the statistics are calculated,
including diagnostics in the output about when different outliers are detected.</p>
<p>To further reduce noise, you want to run on a machine that matches your target
environment as much as possible, which depends on your domain in question. If
you are running a server on a specific configuration, test the code on that
hardware with that configuration. If you are building a CLI tool used by
developers, it might make sense to have many benchmarks from commodity hardware
that developers are using, such as laptops with little to nothing else running
on the system. We might also want to benchmark on the fastest, quality hardware
we can find to determine limits of what you could hope to attain given empirical
results.</p>
<p>Benchmarks can explain performance under various loads. Input now comes into the
picture. If you are a data-regulation compliant company, and I hope you are
self-compliant if not, then generating data that has the same characteristics
and cardinality of what you tend to expect is vital to feed into your benchmarks
as expected &quot;normal load&quot; under the system. You also want to try to record
pathological cases where the system is exceptionally slow under particular
input. This isn't to say these pathological cases need to be your primary target
for the profiling and optimization that comes later. You might want to improve
the life of 99% of your users rather than worrying about an edge case that
happens 0.001% of the time. However, pathological cases still give us insight
into the limits of the component under measurement.</p>
<p>Independent of where you store your benchmarks, having them recorded for every
commit, or possibly every master commit, can let you easily compare two changes
using something like Andrew Gallant's tool
<a href="https://github.com/BurntSushi/critcmp">cargo-critcmp</a>. If you have
different hardware to test, you can script checking out changes, running the
benchmarks, and comparing the results. When making comparisons, make sure to
minimize variables of change across the various measurements! You don't want one
to have programs running in the background while the other was on a totally
silent system, for example.</p>
<p>Andy Gavin talks about how they <a href="https://www.youtube.com/watch?v=izxXGuVL21o&amp;feature=youtu.be&amp;t=513">benchmarked the various display
modes</a> for
the Sony Playstation during the making of Crash Bandicoot. He remarks how if he
had not done this and taken the recommended mode at face value, it would have
been subpar for their situation! This is precisely the kind of speculation that
measurements help dispel. <strong>Performance matters and numbers help make
performance tangible.</strong> Write benchmarks that work for <em>your</em> data and <em>your</em>
setup! Arm yourself to the teeth with numbers and ensure they are <em>valid</em>
numbers to be confident in your fight against lofty claims. <em>Valid</em> measurements
are useful to the community, whether it's your local team or the open-source
community as a whole. Write more benchmarks!</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Magnifying Glasses for Rust Assembly</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/magnifying-glasses-for-rust-assembly.html</link>
      <guid>https://justanotherdot.com/posts/magnifying-glasses-for-rust-assembly.html</guid>
      <pubDate>Sun, 03 May 2020 14:40:08 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Compilers are complicated beasts. Our high-level source code goes through many
transformations until it winds up becoming machine code that runs on real or
virtual hardware. Assembly is the final destination before machine code, and it
doesn't have to be menacing! <strong>Whether you intend to write assembly directly or
not, knowing how your code translates to assembly can drastically improve your
ability to analyze programs from the standpoint of performance.</strong></p>
<p>Yes, we need numbers to guide us towards improvements, and yes, that means
having benchmarks. <strong>Arguments over performance that don't include data are
conjecture but understanding assembly gives you a magnifying glass to help guide
you in your optimization adventures.</strong> With some experience, we can learn how to
look at assembly and determine such things as whether or not the assembly
contains efficient instructions, chunks of code are replaced with constant
values, and so on. Benchmarks and analyzing assembly can go hand in hand, but
how do you even get at the assembly in the first place?</p>
<p>If you want to look at Rust's assembly in your project using just <code>cargo</code>, there
are two ways. You can call</p>
<pre><code>$ cargo rustc --release -- --emit asm &lt;ARGS&gt;
</code></pre>
<p><code>--release</code> is optional here. The primary argument that's needed is <code>--emit asm</code>. <code>ARGS</code> is the list of arguments you want to pass to <code>rustc</code> that might
influence compilation. By default, <code>rustc</code> generates AT&amp;T syntax. Still, you can
change to Intel syntax if that's what you prefer by passing <code>-C llvm-args=--x86-asm-syntax=intel</code>, which may not matter to you if this is your
first foray into analyzing assembly, but it can be fun to see as an experiment!</p>
<p>If you want a good starting point for flags, try using:</p>
<pre><code>&lt;snip&gt;
-C target-cpu=native -C opt-level=3
&lt;snip&gt;
</code></pre>
<p>These two codegen options instruct the compiler to emit code specifically for
the processor it guesses you are running the compiler on as well as using all
optimizations. You can also pass <code>opt-level=z</code> or <code>opt-level=s</code> if you want to
optimize for total disk space, instead. <strong>As a note, fewer instructions doesn't
necessarily mean efficient code.</strong> A short set of instructions may end up taking
more cycles than the more verbose alternative.</p>
<p>If, instead, you want to call the standard <code>cargo build</code>, you can pass all these
arguments with the <code>RUSTFLAGS</code> environment variable. For example:</p>
<pre><code>$ RUSTFLAGS=&quot;--emit asm -C opt-level=3 -C target-cpu=native&quot; cargo build --release
</code></pre>
<p>When the build finishes, the assembly will live in a file with the suffix of<code>.s</code>
under <code>target/debug/deps/CRATE_NAME-HASH.s</code>
or<code>target/release/deps/CRATE_NAME-HASH.s</code>, depending on whether or not you
builtwith the <code>--release</code> flag. If I run the above command on a crate with the
name<code>project</code> I'll get something like the following:</p>
<pre><code>$ find . -name &quot;*.s&quot; -type f
./target/release/deps/project-1693e028130a9fa3.s
</code></pre>
<p>Keep in mind that there may be several of these outputs. If you are confused,
which is the latest, you can try <code>cargo clean</code> and building fresh. By default,
the names are going to look pretty weird in the output due to mangling!
<strong>Mangling</strong> ensures that names for identifiers are unique across the process of
compilation. You can try feeding the resulting assembly into
<a href="https://github.com/luser/rustfilt">rustfilt</a> to get cleaner names:</p>
<pre><code>$ find . -name &quot;*.s&quot; -type f | xargs cat | rustfilt
</code></pre>
<p>Ok, this is great if you have a project going, but maybe you have some transient
code in the <a href="https://play.rust-lang.org/">Rust playground</a> and want to know what
the assembly is there. You can emit assembly there, too! If you click on the
ellipses next to the <code>Run</code> button, you'll get a menu that has several options.
Select <code>ASM</code> for assembly output in another tab. There isn't much control over
compilation options with the Rust playground approach besides picking stable,
beta, or nightly. A more fully-featured web version for picking apart assembly
is <a href="https://godbolt.org/">godbolt</a>, describes itself as a &quot;compiler explorer&quot;
and provides a <em>lot</em> of features to aid you in exploration over the above
bare-bones approaches. Advantage of using godbolt include:</p>
<ul>
<li>Viewing highlighted segments of our source code and where they line up to the assembly</li>
<li>Access to a bevy of compilers from a wide variety of languages, even  selecting which version of Rust you want to use</li>
<li>Passing arbitrary flags to influence how the generated output is produced</li>
<li>Diffing changes in assembly between source code assembly</li>
<li>Looking up the documentation for instructions on the fly</li>
</ul>
<p>You now know three ways to emit assembly, whether it's on your machine, the Rust
playground, or godbolt! To the uninitiated, this can be overwhelming, but
opening the hood can be liberating and allow us to start exploring the various
instructions and how they all tie together.</p>
<p>To reiterate, you don't always have to look at assembly to guide performance
optimization. Benchmarks are crucial at guiding us towards real-world results.
Try to make it a habit to look at assembly when you're curious about what's
going on under the hood. If you start optimizing, it can be interesting to
compare how assembly changes as you make high-level changes. If things seem to
speed up, try to explore how the assembly itself has changed!</p>
<p><em><strong>Update May 4 2020, 2:12PM</strong></em></p>
<p><code>u/ibeforeyou</code> on
<a href="https://www.reddit.com/r/rust/comments/gd1wtd/magnifying_glasses_for_rust_assembly/fpf4grv/">Reddit</a>
mentioned <a href="https://github.com/gnzlbg/cargo-asm"><code>cargo-asm</code></a> to help alleviate a
lot of the pain of dumping out the raw assembly above with <code>cargo</code>. By default,
it will produce Intel syntax, and it can even overlay the rust code over the
lines of assembly. The twist is that you need to give a path to the assembly you
want to see dumped. If you want to see function <code>foo</code> of the crate <code>crate_name</code>,
you could specify the path:</p>
<pre><code>$ cargo asm --rust crate_name::foo
</code></pre>
<p>I did have to shuffle around the flags to get it to emit AT&amp;T syntax for me, in
the end, this ended up working:</p>
<pre><code>$ cargo asm --rust --asm-style att crate_name::foo
</code></pre>
<p>Running <code>cargo asm</code> dumps all the available paths that you can list, which is
pretty neat if you're confused about which path to put down. What I like about
this is you can jam it into a <a href="https://www.justanotherdot.com/posts/a-love-letter-to-feedback-loops.html">feedback
loop</a>
using something like <code>cargo-watch</code> or <code>entr</code>. This way you can make changes on
an individual function and watch how the benchmarks and assembly change without
having to invoke commands manually!</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Cut Down On Clones With Cows</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/cut-down-on-clones-with-cows.html</link>
      <guid>https://justanotherdot.com/posts/cut-down-on-clones-with-cows.html</guid>
      <pubDate>Wed, 29 Apr 2020 18:59:34 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>At the start of a program, it is straightforward to <code>clone</code> data all over the
place to get things working, and, soon enough, the program is overrun by them.
Switching away from clones can be hard because it requires fighting with the
borrow checker, and <a href="https://www.justanotherdot.com/posts/four-ways-to-avoid-the-wrath-of-the-borrow-checker.html">alternative
solutions</a>
aren't quite right for the job. How do you cut down allocations from cloning as
if you were borrowing without winding up in borrow hell? Consider using a Cow.</p>
<p><code>Cow</code> stands for <strong>C</strong>lone <strong>o</strong>n <strong>Write</strong> and they are underrated for what
they can do in this regard. On their own <a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=ceab3b70e17fc69d254404ae3357d0b4">cows are usually larger than their
owned or borrowed
variants</a>,
but cutting down careless memory allocations may help improve performance.</p>
<p>Use a <code>Cow</code> when there is data allocated outside of a function or block, and
there is some runtime logic that determines whether a write takes place. <strong>Cows
are a useful mechanism for transferring ownership lazily by cloning data once
and only once</strong>.</p>
<p>Cows are like hybrids such that at runtime, they might be borrowing data that's
already been around, or they may be handing out borrows to an owned piece of
data that <em>they</em> own.</p>
<p>Consider a function that replaces values in a string that we already have
allocated outside of the function. Replacing characters might mean changing the
size of the string or it could be a case of soft failure where we replace
invalid characters with the unicode replacement character
<a href="https://doc.rust-lang.org/std/char/constant.REPLACEMENT_CHARACTER.html">U+FFFD</a>,
as is the case for
<a href="https://doc.rust-lang.org/std/string/struct.String.html#method.from_utf8_lossy"><code>String::from_utf8_lossy</code></a>.
<strong>We should strive to recycle what values are already hanging around if we can
help it</strong>. We can recycle in other ways, such as taking a reference to a default
rather than assuming it must always be allocated on the fly, or having a
collection lazily clone and take ownership of values as it needs to rather than
cloning the collection from the start. With a bit of imagination, there are
several places that Cows can be used to improve performance and cut down on
clones.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Untangle Your Errors With Enums</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/untangle-your-errors-with-enums.html</link>
      <guid>https://justanotherdot.com/posts/untangle-your-errors-with-enums.html</guid>
      <pubDate>Wed, 22 Apr 2020 21:04:16 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Do you find it far too easy to reach for panics or shoehorn pre-existing errors
to fit your needs? Is it unsatisfying that there are no exceptions in Rust and
challenging to adjust to handling errors with <code>Result</code>? Here is a fundamental
method for modeling data that will help untangle error handling in your
programs.</p>
<p>Programs laden with <code>unwrap</code>, <code>expect</code>, <code>assert</code>, and <code>panic</code> are quick to gain
momentum, but this approach is clunky. For those coming from languages where
exceptions are the norm for error handling, it can feel natural to reach for,
but also awkward to use, something as blunt as a panic. Exceptions have handlers
registered, whereas panics do not, which is the primary difference between the
two.</p>
<p>Panics are for critical situations where a program has no other option but to
commit suicide. These vital situations are why capturing a panic in Rust carries
a stigma. Recovering from a panic depends on how the panic unwinds or aborts,
which is not always under our control.</p>
<p>Handle errors in Rust with <code>Result</code>. However, for newcomers, it's not apparent
how to best design error types. <code>Result&lt;A, B&gt;</code> implies that <code>B</code> could be
anything and we don't want to put <em>anything</em> in there; ad hoc matching of
strings or cross-referencing integers for errors is the pits.</p>
<p>The problem with strings, integers, and other unrefined types is that the range
of values you can express with them is <em>vast</em>, and when it comes to errors, we
want to categorize them neatly, so the range of things we can express is
<em>concise</em>. Unstructured data is hard to check against, parse by a machine, and
find in a codebase. If you do not want to be caught in molasses later in your
project, error handling brevity and classification matter a lot.</p>
<p>Enter the endlessly useful enum. <strong>The beauty of enums is that we can refine
and, therefore, narrow down the range of things we can express</strong>. Enums expose a
handle other coders can rely on, whether they be consumers of your crate or
internal maintainers. Enums optimize for categorization and aggregation, which
makes errors easy to find in code.</p>
<p>To start, create a bare-bones <code>error</code> module in your project with a top-level
<code>Error</code> enum. I'll put some things in here for demonstration purposes, but I'm
sure you can extrapolate for your own needs:</p>
<pre><code>use std::fmt::Display;

mod error {
  pub enum Error {
    IoError(std::io::Error),
    SerdeError(serde_json::Error),
    // ... and so on.
  }

  impl Display {
    // display implementations for each variant.
  }
}
</code></pre>
<p>Once we have this top-level <code>Error</code>, keep pushing; Maybe <code>Error</code> is too much of a
grab bag. <a href="https://www.justanotherdot.com/posts/make-your-errors-clearer-by-splitting-them-in-half.html">Keep clarifying your error
types</a>.
In the above example, we only expressed external errors but we will inevitably
need to express errors relating to our concerns. I'll extend our top-level
error and even grow some new ones:</p>
<pre><code>use std::fmt::Display;
use crate::token::Token;

mod error {
  pub enum Error {
    pub Vendor(VendorError),
    pub StdError(StdError),
    pub Internal(InternalError),
  }

  pub enum InternalError {
    pub Lex(LexError),
  }

  pub struct LexError {
    pub path: Path,
    pub line: i64,
    pub column: i64,
    pub token: Token,
  }

  pub enum VendorError {
    pub SerdeError(serde_json::Error),
    // ... and so on.
  }

  pub enum StdError {
    pub IoError(std::io::Error),
    // ... and so on.
  }

  impl Display {
    // display implementations for each variant.
  }
}
</code></pre>
<p>From such small beginnings we have grown a relatively comprehensive error type
to use in a variety of situations for our program or library. With all of this
in place there is little reason to turn to a panic. The astute observer noted
that we had <code>Display</code> impls laying around. I've structured the output in the
&quot;NASA&quot; style of error reporting, showing a 'stack' of errors. Each layer of the
classification above might have nested descriptions with colons or some other
nested format, for example:</p>
<pre><code>&lt;snip&gt;
  //  top level, we start with [foo] to help describe things.
  impl Display for Error {
    fn fmt(error: Error, f: Formatter) -&gt; {
      match error {
        Error::Vendor(ve) =&gt; fmt.write(&quot;vendor: {}&quot;, ve),
        Error::StdError(se) =&gt; fmt.write(&quot;stdlib:  {}&quot;, se),
        Error::Internal(ie) =&gt; fmt.write(&quot;internal: {}&quot;, ie),
      }
    }
  }

  impl Display for InternalError {
    fn fmt(error: InternalError, f: Formatter) -&gt; {
      match error {
        Internal::Lex(e) =&gt; fmt.write(&quot;could not lex source: {}&quot;, e),
      }
    }
  }

  impl Display for LexError {
    fn fmt(le: LexError, f: Formatter) -&gt; {
      fmt.write(&quot;unrecognized token `{}' in {}:{}:{}&quot;, le.token, le.path, le.line, le.column),
    }
  }
&lt;snip&gt;
</code></pre>
<p>If we had a lexing error we could get a nice output like this:</p>
<pre><code>internal: could not lex source: unrecognized token `asdf' in src/main.rs:3:4
</code></pre>
<p>In a language with sum types, or as Rust calls them, enums, there's no excuse
not to use them liberally for data modeling of all kinds. Being meticulous about
how you design errors and using categorization as a guiding heuristic makes
error handling a snap rather than a grind.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Skip Unnecessary Allocations In Your Collections</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/skip-unnecessary-allocations-in-your-collections.html</link>
      <guid>https://justanotherdot.com/posts/skip-unnecessary-allocations-in-your-collections.html</guid>
      <pubDate>Tue, 14 Apr 2020 19:47:45 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Rust's standard library offers a lot of neat dynamically-sized data structures
for use in Rust programs. They are quite performant, but the allocations they
conduct behind the scenes to grow may add up and cause performance issues in
your programs.</p>
<p>Rust intentionally avoids costly uses of <code>new</code> in a program by having the
allocation be empty by default, including types outside of<code>std::collections</code>,
too, such as <code>String::new</code>.</p>
<p>The backing store usually grows with a doubling strategy, and the growth tends
to happen right as it is needed, as is the case for <code>Vec</code>, see
<a href="https://github.com/rust-lang/rust/blob/42abbd8878d3b67238f3611b0587c704ba94f39c/src/liballoc/raw_vec.rs#L462-L464">here</a>
and
<a href="https://github.com/rust-lang/rust/blob/42abbd8878d3b67238f3611b0587c704ba94f39c/src/liballoc/raw_vec.rs#L476-L540">here</a>
for references to code as of this writing, but it may not always be the same
story for other collections. I strongly encourage looking at the actual source
code for the standard library when you are curious. Rust uses the language of
<strong>capacity</strong> to designate the total possible amount of memory the backing store
has room for and <strong>length</strong> to designate the total number of actual values in
the data structure.</p>
<p>One of the core tenants of optimization is to avoid doing needless work. Putting
data on the heap isn't necessarily expensive if you've already paid the price
upfront for allocating it. Doing work in this way is called <strong>amortization</strong>.
Imagine I have to store 4096 things in a vector. By default, the vector grows in
powers of two with capacities of 0, 2, 4, 8, 16, 32, 64, and so on, in that
order. That's already six allocations I've mentioned and not done reaching the
final size. Avoiding unnecessary work is at the heart of performance
optimization and these are intermediate steps are unnecessary!</p>
<p>A fantastic part of the Rust standard library collections is they tend to have
common interfaces precisely for this sort of thing! You can avoid these
allocations by using<code>with_capacity</code> if you know the value or upper bound you
need initially. If you already have the data structure hanging around, you can
also call <code>reserve</code> to request additional capacity to avoid needless allocation.</p>
<p>The way allocation happens with the doubling strategy <em>is</em> a form of
amortization. As the collection grows in powers of two, the number of calls
reduces, but the cost of growing the vector increases. Each time the vector
grows, it will copy all the values over to a new backing store. In general, any
time you think you can use a big chunk of data up front, you should allocate the
full capacity, but if the exact amount you are requesting is unknown, isn't that
a bit wasteful? An alternative strategy where the amount may only be partly
known is to request a large chunk of memory and size it down either with
<code>shrink_to_fit</code> or <code>resize</code>, but be careful with <code>resize</code> as it may truncate the
collection if you aren't careful!</p>
<p>It is always best to get empirical data on how to reasonably size the collection
upfront or while the program is running. If we instead take a chaotic approach
to allocations we may do more harm than good. At the end of the day, the reason
why these data structures grow on their own is to avoid thinking about them
<em>until</em> performance is an issue and we reveal that spending our time on this is
important through profiling.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Ways Wildcards Hide Bugs</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/ways-wildcards-hide-bugs.html</link>
      <guid>https://justanotherdot.com/posts/ways-wildcards-hide-bugs.html</guid>
      <pubDate>Thu, 09 Apr 2020 20:42:10 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>We call the wildcard variable, denoted by an underscore (<code>_</code>), the &quot;don't care&quot;
variable to throw away values we don't care to keep. Wildcards don't bind any
values, so wildcards have specific support in the language, as opposed to other
languages where an underscore may be yet another variable name.</p>
<p>I'll discuss three ways bugs can lurk innocently behind wildcards. Wildcards are useful, but reckless use of them can lead to bugs! I'll discuss three ways this can happen and how to be a bit more vigilant with their use. The general principle across these fixes is to think twice when you find yourself writing a wildcard. Ask if it is a value you want to ignore?</p>
<h3>Throwing away values</h3>
<p>The <code>;</code> without a <code>let</code> statement in Rust means &quot;turn this thing into a <code>()</code>because I want to cast the value into something that isn't an error but isn't a useful value.&quot; If you write a <code>Result</code> in Rust and don't propagate the value with <code>?</code> and don't assign the value to a variable name, say something like this:</p>
<pre><code>pub fn main() -&gt; Result&lt;(), std::io::Error&gt;  {
    std::fs::remove_file(&quot;/hello&quot;);
    Ok(())
}
</code></pre>
<p>rustc whinges, stating:</p>
<pre><code>   Compiling playground v0.0.1 (/playground)
warning: unused `std::result::Result` that must be used
 --&gt; src/main.rs:2:5
  |
2 |     std::fs::remove_file(&quot;/hello&quot;);
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |
  = note: `#[warn(unused_must_use)]` on by default
  = note: this `Result` may be an `Err` variant, which should be handled

    Finished dev [unoptimized + debuginfo] target(s) in 0.61s
     Running `target/debug/playground`
</code></pre>
<p>However, we can entirely silence this with a wildcard:</p>
<pre><code>pub fn main() -&gt; Result&lt;(), std::io::Error&gt;  {
    let _ = std::fs::remove_file(&quot;/hello&quot;);
    Ok(())
}
</code></pre>
<p>It may seem like you don't care about the value, but if the value represents a failure in any way, including, say, an <code>Option</code>, you want to ensure that value is not lost. Silencing any error generally means failures aren't be handled or reported, and that can mean things <em>seem</em> fine on the surface, but might be broken.</p>
<p>To give a production example of this, I recently fixed a test bug that used a database transaction but discarded its <code>Result</code>. It did this with the same sort of wildcard binding we saw above. As such, when it encountered any failure in the transaction and ignored it, the test became a false positive because nothing would panic. Two ways to fix this are to turn the enclosing test as one that returns <code>Result</code>, which you can do and is excellent, and the other is to bind the value and <code>unwrap</code>, <code>expect</code> or even do an <code>assert</code> on it given what sort of ergonomics and output you like.</p>
<h3>Using wildcard cases in a match carelessly</h3>
<p>Not everyone coming to Rust is used to match expressions. The anatomy of a match expression is pretty straightforward; you <code>match</code> on the term of interest, and each 'arm' is a case that we consider. Match statements are exhaustive, which means we either check every possible value we are matching against or we slap in a wildcard because we don't care or can't feasibly match on every possible value. When things have high-cardinality of the values they can represent, a wildcard might be funneling unexpected value into the wrong logic.
rustc is great at calling you out on this sort of stuff. Consider this code that
matches on an integer:</p>
<pre><code>pub fn main() {
    let x: i32 = 12;
    match x {
      y if y == 12 =&gt; x,
      y if y &lt; 12 =&gt; x,
      y if y &gt; 12 =&gt; x,
    };
}
</code></pre>
<p>Integers have many values, and we're trying to narrow down the selection to an exact match, values that are greater than the exact match, and values that are lesser than the exact match. However, rustc wants to make sure we've genuinely considered every angle:</p>
<pre><code>   Compiling playground v0.0.1 (/playground)
error[E0004]: non-exhaustive patterns: `_` not covered
 --&gt; src/main.rs:3:11
  |
3 |     match x {
  |           ^ pattern `_` not covered
  |
  = help: ensure that all possible cases are being handled, possibly by adding wildcards or more match arms

error: aborting due to previous error

For more information about this error, try `rustc --explain E0004`.
error: could not compile `playground`.

To learn more, run the command again with --verbose.
</code></pre>
<p>If you make the first match case <code>12 =&gt; x</code> rustc tells us that we aren't considering full ranges:</p>
<pre><code>   Compiling playground v0.0.1 (/playground)
error[E0004]: non-exhaustive patterns: `std::i32::MIN..=11i32` and `13i32..=std::i32::MAX` not covered
 --&gt; src/main.rs:3:11
  |
3 |     match x {
  |           ^ patterns `std::i32::MIN..=11i32` and `13i32..=std::i32::MAX` not covered
  |
  = help: ensure that all possible cases are being handled, possibly by adding wildcards or more match arms

error: aborting due to previous error

For more information about this error, try `rustc --explain E0004`.
error: could not compile `playground`.

To learn more, run the command again with --verbose.
</code></pre>
<p>rustc is already nudging us towards a solution specifically here where guards aren't doing much for us by spelling out the exact patterns for us. With some changes, this builds cleanly:</p>
<pre><code>pub fn main() {
    let x: i32 = 12;
    match x {
      12 =&gt; x,
      std::i32::MIN..=11i32 =&gt; x,
      13i32..=std::i32::MAX =&gt; x,
    };
}
</code></pre>
<p>If possible, it's best to refine the type into something like a sum type (enum) so that we can match on exact variants. In our example above, if we were to <code>x.cmp(12i32)</code>, we'd have three cases to check for; <code>LessThan</code>, <code>MoreThan</code>, and <code>Eq</code>.</p>
<pre><code>use std::cmp::Ordering;

pub fn main() {
    let x: i32 = 12;
    match x.cmp(&amp;12i32) {
        Ordering::Equal =&gt; x,
        Ordering::Less =&gt; x,
        Ordering::Greater =&gt; x,
    };
}
</code></pre>
<p>If you still need to use a wildcard, a useful tool is to turn to property-based testing or fuzzing to ensure that the specific branches are covered. Property-based testing and fuzzing are ways to generate test input randomly. Many libraries have support for generating specific ranges of values, such that you could focus more on the &quot;black hole&quot; that the wildcard case is creating, which is &quot;everything that isn't the cases I <em>have</em> covered.&quot; For example, you might have three branches, where one of the branches is a wildcard. 10-20% could go into the first two known branches, and the remaining 60-80% could be left to generate data that isn't of those two known branches to shine a flashlight into the dark crevices. When values become known that have special treatment, you can add them to the branches of the <code>match</code> and adjust the percentages accordingly.</p>
<h3>Leaving arguments dormant in a function</h3>
<p>When we design public-facing interfaces, it can be tempting to try to keep them stable by softening some of their fields. One way to do this with functions is to treat arguments as &quot;unused&quot; by prefixing them with an underscore. The surface seems the same, but now the value isn't used.</p>
<p>Since the function ignores these values, callers may make incorrect assumptions about how arguments might change the output. Leaving arguments dormant is especially nefarious when the function is non-deterministic, and it can <em>feel</em> like the different arguments are making a change. We can't always trust that users of our code are going to, or even be able to, read the source code.</p>
<p>Ignoring arguments has a straightforward fix; don't ignore arguments. Favor deprecating the function for a new version as the alternative and signal new versions with some precise apparatus. This principle is the same across a lot of interface design: make a new thing and migrate over to it rather than trying to change the other thing in place. When you rig up the new version, you can delete the old one, but you need to keep the old one around until you finalize the transition. Changing things in place is fine if the consumption is still light, but the breathing room gained from doing it the immutable way far outweighs the 'ease' of trying to modify the pre-existing.</p>
<h3>Wildcards aren't bad!</h3>
<p>Don't get me wrong, wildcards <em>are</em> useful, but they are easy to abuse if you are new to them. Hopefully, these points come to mind next time you write a <code>match</code> expression or modify a function!</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Make Your Errors Clearer By Splitting Them In Half</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/make-your-errors-clearer-by-splitting-them-in-half.html</link>
      <guid>https://justanotherdot.com/posts/make-your-errors-clearer-by-splitting-them-in-half.html</guid>
      <pubDate>Mon, 06 Apr 2020 20:26:18 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Are your errors type devolving into grab bags with varying degrees of
categorization? Frequently <em>who</em> is at fault is not clear, and that can be one
of the most ergonomically essential classifications. If a program makes it clear
that an error is due to a user mistake, an internal complication, or possibly a
bug, that dramatically eases the usability of the service/library/tool in
question.</p>
<p>Making this clear is trivial with a top-level enum. I'm going to pretend we an
interface with two sides in question; the program authors (the providers) and
the users of the program (the consumers). For simplicity, I've called these
<code>External</code> and <code>Internal</code>, but it could also be <code>Provider</code> and <code>Consumer</code> or
whatever makes the designation clear for your use case.</p>
<pre><code>mod error {
  pub enum ExternalError {
    // e.g. MalformedInput, MissingArguments, and so on.
  }

  pub enum InternalError {
    // e.g. IoError, SerdeError, and so on.
  }

  pub enum Error {
    External(ExternalError),
    Internal(InternalError),
  }
}
</code></pre>
<p>A sum type lets you easily pattern match and analyze the error itself
without fickle operations or messy validation logic. Sum types (enums) are
fantastic, and you should be looking for ways to leverage them whenever
possible.</p>
<p>A mental model for this I like is thinking every error has an owner. Then you
can write functions that have clear offenders. Then, by signature, you are
assured that a module only deals with internally related failures or externally
associated concerns.</p>
<p>I love this approach because when you get to debugging, you can quickly
ascertain if an error is from mishandling, some operational concern, or perhaps
a bug. The user sees each diagnostic without any ambiguity to who is at fault.
In the same vein that a bug may be breaking an invariant, we might have an
<code>Invariant</code> case, which stipulates that an invariant has been breached, without
necessarily having to reach for assertions, or hoping that <code>debug_assertion</code>s
will fire in tests. And by all means, if there are more than two offenders, it
is best to define them clearly!</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>How to pick stable, beta, or nightly Rust</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/how-to-pick-stable-beta-or-nightly-rust.html</link>
      <guid>https://justanotherdot.com/posts/how-to-pick-stable-beta-or-nightly-rust.html</guid>
      <pubDate>Thu, 02 Apr 2020 19:04:29 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>It would seem natural to always pick stable Rust, but how much awesome new
stuff do beta and nightly have and how unstable are they? It can be confusing
that such a plethora of feature flags sits in nightly but we don't want to
sacrifice stability.</p>
<p>Stability is a guarantee that something won't change. With that said, unstable
features theoretically have no guarantees, but in practice there is generally a
modicum of acceptable change and stability in nightly releases for most
purposes.</p>
<p>Before we begin, I've condensed my thought process into a simple diagram:</p>
<figure>
  <img
    src="/assets/images/pick-rust-toolchain-flowchart.png"
    alt="a flowchart describing how to choose between rust toolchains"
    title="A flowchart for choosing between stable, beta, and nightly toolchains">
  </img>
</figure>
<p><strong>If you don't need anything specifically from nightly or beta, stable should be
your default option.</strong> Cargo is quite good at mentioning what features you can
possibly turn on to help guide you into nightly. If you want a full guide on all
current and prior unstable features you can check out the <a href="https://doc.rust-lang.org/unstable-book/index.html">unstable
book</a>.</p>
<p>A way to run nightly with a slightly increased sense of stability is to use a
pinned variant. Cargo supports finding <code>rust-toolchain</code> files (the <a href="https://github.com/rust-lang/rustup#the-toolchain-file">toolchain
file</a>, as it's called)
at the root of crates which specify the specific version to use when building
the project. You can pin a nightly with a date, so something like</p>
<pre><code>nightly-2020-01-01
</code></pre>
<p>will ensure the nightly released on January 1st, 2020 will be the toolchain
picked.</p>
<p>In my own experience, when I encounter a bug in a pinned nightly I am using, I
can usually bump the pinned version to the latest nightly and go on with my
life. Although nightly Rust is still a moving target but in my experience it is
a remarkably sturdy moving target! Having run Rust for work and personal uses,
I've used pinned nightlies in both cases to great effect.</p>
<p>What's the difference between beta and nightly? <code>beta</code> is the first step before
a stable release. Beta is continually improved as nightlies progress and
regressions and features are discovered. The flow goes from nightly, to beta, to
stable, as you can see here in the <a href="https://doc.rust-lang.org/book/appendix-07-nightly-rust.html">Rust Programming Language Book Appendix
G</a>. As stated in
the same appendix:</p>
<blockquote>
<p>Most Rust users do not use beta releases actively, but test against beta in
their CI system to help Rust discover possible regressions.</p>
</blockquote>
<p>Or, another way of putting it; if you use stable, having beta and nightly builds
can help point out failures to be raised with the Rust core team, i.e. beta
should do everything stable does, and more. In the same vein, nightly should do
everything beta does, and more, but with the caveat that unstable APIs are
subject to change. Technically, one could try stable, then go to a pinned beta,
then go to a pinned nightly if they really want to tracking changes to specific
features.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Catching panics in dependencies</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/catching-panics-in-dependencies.html</link>
      <guid>https://justanotherdot.com/posts/catching-panics-in-dependencies.html</guid>
      <pubDate>Fri, 27 Mar 2020 11:55:26 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Having crates panic on you feels random because the specific conditions that
trigger the panic may not seem clear. Having external crates bring down your
program is a pain, but there is currently no static analysis tool to help us
easily find panics in external crates. You can get pretty close with fuzzing,
though!</p>
<p>The format for fuzzing is generally:</p>
<ol>
<li>Get some random bytes</li>
<li>Shape them into the right shape needed for our interface</li>
<li>Run the interface with the random data and see if it blows up</li>
</ol>
<p>Some fuzzing libraries take the input that leads to a crash and continually mutates it
to find other cases where it might crash as well. I'm going to use <code>cargo fuzz</code>
to reproduce finding a panic in an external dependency. <a href="https://github.com/rust-num/num/issues/268">Here's a
case</a> taken from the <code>rust-fuzz</code>
organisations <a href="https://github.com/rust-fuzz/trophy-case">trophy case</a>. I'll use
<code>num</code> v0.1.31 which panics when parsing <code>BigInt</code>s as per the linked issue. I'll
add it to the <code>Cargo.toml</code> of our project:</p>
<pre><code>[dependencies]
num = &quot;=0.1.31&quot;
</code></pre>
<p>Then, I'll install <code>cargo fuzz</code>.</p>
<pre><code>cargo install cargo-fuzz
</code></pre>
<p>then in our project, we can initialize cargo fuzz.</p>
<pre><code>cargo fuzz init
</code></pre>
<p>Which gives me a single fuzz target which I can rename if I want. I'll rename it
to <code>parse.rs</code> so the name is <code>parse</code> when listed but you can call it anything
that fits. To do this I will change the <code>fuzz</code> subdirectories <code>Cargo.toml</code>. A
<code>[[bin]]</code> key is in there that designates what targets are available. Since
we're moving <code>fuzz_target_1</code> to <code>parse</code>, we have to do this in the TOML file
since the <code>cargo fuzz</code> subcommand doesn't have this ability, but we <em>can</em> use
the <code>cargo fuzz add</code> subcommand to add extra targets with custom names in the
future.</p>
<p>The new key should look like this</p>
<pre><code>[[bin]]
name = &quot;parse&quot;
path = &quot;fuzz_targets/parse.rs&quot;
</code></pre>
<p>with the rest of the <code>fuzz/Cargo.toml</code> left as-is.</p>
<p>Then we can write a simple case for our function. This can be a little tricky
because the fuzzer will hand us raw bytes and it's up to us to shape them into
the right format, whether that be a struct, i64, f32, and so on. For this case
I'll make a string from the random bytes and feed it into our project's <code>parse</code>
function:</p>
<pre><code>#![no_main]
use our_project::parse;
use libfuzzer_sys::fuzz_target;

fuzz_target!(|data: &amp;[u8]| {
    if let Ok(s) = std::str::from_utf8(data) {
        let _ = parse(&amp;s);
    }
});
</code></pre>
<p>the <code>parse</code> function might look something like this (lifted from the issue):</p>
<pre><code>use num::Num;

pub fn parse(str: &amp;str) {
    num::BigUint::from_str_radix(str, 10);
}
</code></pre>
<p>and then I'll run the fuzzer for this target:</p>
<pre><code>cargo fuzz run parse
</code></pre>
<p>This finds offending strings similar to the trophy case example quite quickly:</p>
<pre><code>&lt;snip&gt;


Failing input:

        fuzz/artifacts/parse/crash-00a78c613a00b21ea723de12e16f32a0385d9bdc

Output of `std::fmt::Debug`:

        [48, 43, 49]

Reproduce with:

        cargo fuzz run parse fuzz/artifacts/parse/crash-00a78c613a00b21ea723de12e16f32a0385d9bdc

Minimize test case with:

        cargo fuzz tmin parse fuzz/artifacts/parse/crash-00a78c613a00b21ea723de12e16f32a0385d9bdc



Error: Fuzz target exited with exit code: 77
</code></pre>
<p>Hang on, that debug output doesn't look like the offending case mentioned in the
issue we linked above from the trophy case, does it? Again, this is because it's
the raw bytes. A handy trick I use when running regressions is to utilize the
stored failing input. In this case it's stored at
<code>fuzz/artifacts/parse/crash-00a78c613a00b21ea723de12e16f32a0385d9bdc</code> per the
output above. We can write a regression that uses this directly with the macro
<code>include_bytes!</code>:</p>
<pre><code>#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn fuzz_regression_01() {
        let data = include_bytes!(
            &quot;../fuzz/artifacts/parse/crash-00a78c613a00b21ea723de12e16f32a0385d9bdc&quot;
        );
        let s = std::str::from_utf8(data).expect(&quot;should be able to make test input&quot;);
        dbg!(&amp;s);
        parse(&amp;s);
    }
}
</code></pre>
<p>You can run the tests the usual way with <code>cargo test</code> which should panic. I've
lobbed a <code>dbg!</code> in there of the transformed raw bytes into the string. When the
test panics we see:</p>
<pre><code>running 1 test
test tests::fuzz_regression_01 ... FAILED

failures:

- tests::fuzz_regression_01 stdout -
[src/lib.rs:17] &amp;s = &quot;0+1&quot;
thread 'tests::fuzz_regression_01' panicked at 'called `Result::unwrap_err()` on an `Ok` value: 1', /home/rjs/.cargo/registry/src/github.com-1ecc6299db9ec823/num-0.1.31/src/bigint.rs:388:25
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace

failures:
    tests::fuzz_regression_01

test result: FAILED. 0 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out

error: test failed, to rerun pass '--lib'
</code></pre>
<p>And there is our offending input, <code>&quot;0+1&quot;</code>! Beautiful. I can use these specific
cases in issues for upstream projects instead of wasting time trying to find
exact cases on my own. Switching to <code>num</code> v0.1.41 avoids the panic and we can
run <code>cargo fuzz</code> again. We can also change the fuzzing library used, such as
libfuzz or <a href="https://rust-fuzz.github.io/book/afl.html">afl</a>, which <code>cargo fuzz</code>
supports. You can also use <code>honggfuzz</code> via the <code>honggfuzz.rs</code> library over at
<a href="https://github.com/rust-fuzz/honggfuzz-rs">honggfuzz-rs</a>. Different fuzzers
have different features and guarantees but most are relatively easy to write
targets for and get fuzzing so it can pay to try a few alternatives to see if
other cases are lurking around.</p>
<p>Before I go, I want to talk about a related concept known as &quot;property based
testing&quot; where we define how random data should be generated. We'll dig more
into that another day but for now, it suffices to say that both approaches help
to drive out test cases you might not have imagined! I am in the habit of making
my own regression suites from cases I find from either method, but you don't
<em>have</em> to do this as some fuzzers and property-based testing libraries will keep
a &quot;corpus&quot; of data that has failed that it can try again on future runs, but I
find it helpful to have the regressions as unit tests so there is a fast way to
verify earlier failures aren't still happening.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>How To Return An Iterator From a Function</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/how-to-return-an-iterator-from-a-function.html</link>
      <guid>https://justanotherdot.com/posts/how-to-return-an-iterator-from-a-function.html</guid>
      <pubDate>Thu, 19 Mar 2020 19:40:42 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Iterators are handy ways to describe the potential for looping over data but
without eagerly evaluating it. In other words, we can describe the shape of
looping over things but we only do work when we call something like <code>collect</code>.
The compiler can do several optimizations around iterators and each <code>collect</code>
needs to allocate memory to store our results. To avoid a lot of needless
allocations it pays to returns iterators sometimes from functions.</p>
<p>Alright, that's great but you're hitting a wall returning one from a function.
I'll provide two ways you can do just that:</p>
<p>We could use the <code>impl Trait</code> syntax where <code>Trait</code> is the trait in question we
want to return. In this case, we'd have:</p>
<pre><code>fn unboxed_iterator() -&gt; impl Iterator&lt;Item = usize&gt; {
  (0..3).into_iter()
}
</code></pre>
<p>This is where the compiler will determine the exact type that is being returned
and substitute that in. This approach, albeit with static dispatch, has its
limits. You can read Bodil Stokke's <a href="https://bodil.lol/parser-combinators/">wonderful introduction to parser
combinators</a> as an example where the
<code>impl Trait</code> approach starts to get too complex and require turning to our next
approach of <code>Box</code>ing the iterators. This static approach also doesn't work when
we have anonymous types, such as with async functions. Marking a function as
<code>async</code> has support from the compiler to return the right type.</p>
<p>We could also use a <code>Box</code>. It is the simplest way to package up an iterator but
at the cost of allocation. Anything behind a <code>Box</code> is allocated on the heap.</p>
<pre><code>fn boxed_iterator() -&gt; Box&lt;dyn Iterator&lt;Item = usize&gt;&gt; {
  Box::new((0..3).into_iter())
}
</code></pre>
<p>We have to pay the price of dereferencing a pointer each time we want to deal
with this specific boxed iterator. We can manipulate both iterators in the same
way because <code>Box</code> implements <code>Deref</code> which lets you access the methods
underneath. So we can call <code>map</code> and friends on the resulting <code>Box</code>. Both of
these forms can usually be used with one another, as, for example, we can chain
both together since they both can be turned <code>IntoIterator</code>s.</p>
<pre><code>fn unboxed_iterator() -&gt; impl Iterator&lt;Item = usize&gt; {
  (0..3).into_iter()
}

fn boxed_iterator() -&gt; Box&lt;dyn Iterator&lt;Item = usize&gt;&gt; {
  Box::new((0..3).into_iter())
}

fn main() {
  dbg!(boxed_iterator().chain(unboxed_iterator()).collect::&lt;Vec&lt;_&gt;&gt;());
}
</code></pre>
<p>The above prints:</p>
<pre><code>[src/main.rs:10] boxed_iterator().chain(unboxed_iterator()).collect::&lt;Vec&lt;_&gt;&gt;() = [
    0,
    1,
    2,
    0,
    1,
    2,
]
</code></pre>
<p>You preferably want to use the <code>impl Trait</code> approach as much as you can and
fall back to the <code>Box</code> approach when that starts to fail or become inordinately
slow to compile. With time this restriction may go away as work on the compiler
continues.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Working From Home Without Clawing At The Walls</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/working-from-home-without-clawing-at-the-walls.html</link>
      <guid>https://justanotherdot.com/posts/working-from-home-without-clawing-at-the-walls.html</guid>
      <pubDate>Mon, 16 Mar 2020 18:49:21 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Swaths of people are shifting into working from home, otherwise acronymized as
&quot;wfh&quot;, and for some, it's a drastic shift. For those with kids, the reduced
productivity will be a change even for those that are used to working from home.
I have a fair amount of experience working from home and I thought I'd share
some thoughts from my experience of key things that have helped keep me
productive but also, more importantly, sane. After all, long periods locked up
inside can easily drive one to cabin fever; how do all the introverts and remote
workers keep from space madness?</p>
<p>Welcome. You are now working from home. You have a computer, a brain, and a way
to link the two, and this is (for purposes of simplifying this article) largely
what you need to get your job done.</p>
<p>Parts of what I'm to recommend are peppered with caveats due to the nature of
why people are coming in droves to the practice of working remotely. Take what I
say with a grain of salt.</p>
<p><em>NB. I started writing this on a Sunday and became aware of Alice Goldfuss's
<a href="https://blog.alicegoldfuss.com/work-in-the-time-of-corona/">fantastic article</a>
on the same subject the Monday after. It is far more thorough and I strongly
recommend it.</em></p>
<ul>
<li>
<p>Wear your work clothes. This is going to set off the &quot;I'm wearing work
clothes, I'm going to work&quot; cells firing. Resist the urge to wear the same
clothes you wore last night post-shower and relaxation. There are a few points
here that are about separation</p>
</li>
<li>
<p>Get outside. If you have a morning routine, say with tea or coffee, it can
help to simply exit your house for a brief period in the morning. Getting some
time outside the confines of the walls of your home may seem inconsequential
but I've found it to have a profound impact on my psyche. Lots of these points
may seem like &quot;well of course!&quot; but the reality is that working from home
tends to get you into tunnel vision about work.</p>
</li>
<li>
<p>Dedicate space to where you work if you can. Productivity can dwindle, and
your ability to relax, if you mix and match places for use of work and
leisure. If you don't have the space to dedicate as an office you can always
pick strategic places in your house that are more for business than they are
for recreation. For example, it might be cool to work at the dining table or
the kitchen island but not in bed and on the couch.</p>
</li>
<li>
<p>Do a bit of exercise. Doing a small run or bike around the block, some yoga at
home, or doing pushups, situps, and jumping jacks throughout your day in small
spurts can add up. Lack of exercise can lead to a reduction in energy and
alertness but you don't need to be doing really heavy exercise to get back
into the habit.</p>
</li>
<li>
<p>Do a bit of stretching at regular intervals. I make this a separate point
because if you work at a computer like me, it's vital to remember to get up
and move around constantly and stretch out all the muscles attached your hands
are up in your back, neck, and so on. I also own a foam roller and massage
ball for my back and neck that I use for about ten minutes at the end of each
day.</p>
</li>
<li>
<p>If you work in a high-pace work environment, having lunch at the ready so you
don't have to cook it helps reduce stress. Ditto breakfast and dinner
although, in another point we'll cover, hours of work can sort of distort a
bit.</p>
</li>
<li>
<p>Depending on what you can do, if you do anything with a deep work effort, be
free with how you organize your day during the &quot;deep work&quot; period. There might
be the time where everyone catches up, perhaps with a standup or quick chat,
but the idea is that you should feel a bit freer to, say, read a bit for
fifteen minutes or take a bike ride. This is important because it breaks up
your day and time you reclaim from the commute shouldn't all be poured into
work. You need to structure the demarcation of you-time and work-time
responsibly because things like getting on the train won't be present.</p>
</li>
<li>
<p>If you are a social person, it can help to have things like podcasts and
audiobooks at the ready so you can get an influx of other humans talking into
your daily psyche diet. I call this the morning-television effect. When people
put on morning television it is more to create the presence of people than the
content they broadcast. It can pay to have a little bit of human communication
on a quick ten to fifteen-minute call per day either for work or with a
friend, too.</p>
</li>
<li>
<p>In some ways, we are basically like plants in that we need water, oxygen, and
light. Getting plenty of these in some form or another improves quality of
life while working from home. This is a bit more than the &quot;get out of the
house&quot; point because it can be done without leaving the home, although getting
out of the house also makes you feel a bit &quot;free&quot; from the confines of your
home as well. Physiological needs can be the first place to try to supplement
and repair when things are feeling funky at home.</p>
</li>
<li>
<p>When you feel flustered, shut off the computer for a bit. I know not everyone
can do this as some people's jobs, say in software operations, need to be
present for most of their clocked time when on duty. If you do have the
option, it is powerful to push your laptop away and go someplace with just
your journal. Once there, try to de-stress a bit and forget work. Once your
head is a bit clear, focus on whatever problem you are dealing with on paper
first. Being indoors is claustrophobic. Being indoors inside the mental space
of a computer is doubly so.</p>
</li>
</ul>
<p>A majority of these boil down to a couple of heuristics:</p>
<ol>
<li>Focus on your physiological needs when things seem off</li>
<li>Ensure you have routines and structure in place to keep your mind focused</li>
<li>Be flexible with your expectations on yourself and on your work,
particularly concerning where hours are dedicated</li>
</ol>
<p>As I write this it's a stressful period. Go easy on yourself and those around
you while everyone adjusts. I hope some points here help ease the adjustment.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Why Are There Two Types of Strings In Rust?</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/why-are-there-two-types-of-strings-in-rust.html</link>
      <guid>https://justanotherdot.com/posts/why-are-there-two-types-of-strings-in-rust.html</guid>
      <pubDate>Sat, 14 Mar 2020 10:45:46 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Understanding the distinction between <code>str</code> and <code>String</code> can be painful if you
need to get something done in Rust <em>now</em>. Rust doesn't sugar coat a lot of the
ugliness and complexity of string handling from developers like other languages
do and therefore helps in avoiding critical mistakes in the future.</p>
<p>By construction, both string types are valid UTF-8. This ensures there are no
misbehaving strings in a program. A <code>char</code> is always four-bytes in Rust, but a
string doesn't have to be composed of just four-byte chunks (that would be a
UTF-32 encoding!). Being UTF-8 means that Strings can be encoded with
variable-width code points, but you can iterate across the <code>char</code>s if you want
without them being stored as such.</p>
<p>I'll cover the remaining difference between a <code>String</code> and a <code>str</code> through
arrays, vecs, and slices.</p>
<p>An array is a contiguous chunk of memory where every element is the same type
and adjacent. Arrays are, however, of a fixed size. If we want to actually grow
or shrink an array we can turn to a <code>Vec</code> which is sometimes known as a
&quot;resizable array&quot;. This type abstracts away the housekeeping around allocating
bigger or smaller arrays.</p>
<p>A vec grow as elements fill the backing memory near or at capacity. Without
getting too distracted, a vec doesn't quite use an array but it does use a
contiguous chunk of allocated memory that is similar to an array. Vecs also
shrink to size if requested. The perks of ownership in Rust mean we, the vec,
can do whatever we please to the data we own. We can always borrow owned things
to temporarily read or change data. Why do you need more?</p>
<p>A slice is a view into a portion, or <em>slice</em>, of owned, contiguous memory.
Whenever we have a slice we know we can access its elements safely without
exposing any elements outside of the portion described by the slice and without
copying any data over to a new owner. Slices give us the capacity to provide
entire views of the original data rather than just a segment.</p>
<p>This relationship between an owned piece of data and a view into an owned piece
of data is pervasive in Rust. Not every view may exclude access outside of its
elements but it may provide a copy-free access such as an <code>Entry</code> for a
<code>BTreeMap</code> or a <code>Cursor</code> to a <code>File</code>.</p>
<p>This is the same relationship between <code>String</code> and <code>str</code>. A <code>String</code> is the
<code>Vec</code> and <code>str</code> is the slice. Since a slice is its own type, we can borrow it to
change or read as we please. This is the difference between <code>str</code> and <code>&amp;str</code> in
that you will only ever manipulate a <code>&amp;str</code> but it's technically a borrowed
&quot;string slice&quot; <code>str</code>.</p>
<p>There is one bit of &quot;magic&quot; that Rust allows which is that taking a borrow to an
owned string to a function will cast it to a string slice for you.</p>
<pre><code>let s = String::new();
fn takes_a_string_slice(the_string: &amp;str) {
  // reads the_string.
}
takes_a_string_slice(&amp;s);
</code></pre>
<p>This is a convenience so that you don't have to describe the bounds as you would
for an array or vector slice, a la <code>&amp;xs[0..n]</code>, although you <em>can</em> use the same
syntax to create a slice into a portion of a string if you want.</p>
<p>As a final point, the backing store of a <code>String</code> is actually <code>Vec</code>; <code>String</code>
just brings along the requirement that the contents are valid UTF-8 and heaps of
convenience functions, as does <code>&amp;str</code>. A slice is what we commonly call a &quot;fat
pointer&quot; which consists of two machine words: one pointing to the start of data
and another dictating the length. In this sense casting between a slice and back
is cheap in the sense that we do not copy any data besides creating a fat
pointer which is possibly reused it when we borrow.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>When to move, copy, or clone?</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/when-to-move-copy-or-clone.html</link>
      <guid>https://justanotherdot.com/posts/when-to-move-copy-or-clone.html</guid>
      <pubDate>Mon, 09 Mar 2020 19:35:28 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Do you understand ownership and borrowing in theory but find it hard in
practice? Do the differences between things like <code>iter</code> and <code>into_iter</code> still
confuse you? Maybe the difference between <code>Copy</code> and <code>Clone</code> is still unclear? I
will shed some light on practical examples that should help you gain a better
grip on owning and borrowing values.</p>
<p>As you may know, all values in Rust need an owner. <em>Owners are about
responsibility</em>; some resource, usually, but not always, memory, is allocated and
the responsibility for releasing it is up to the owner. Ownership, or rather,
responsibility, is only transferred on a move, hence borrowing, not counting
towards releasing resources, is a <em>view</em> into the data. Rust's borrowing rules
mimic the solution to the readers-writers problem of concurrency; there may be
any number of readers but no writers and only ever one writer and no readers.
These two states are the same as immutable borrows and mutable borrows,
respectively.</p>
<p>When we rebind values that aren't <code>Copy</code>, by default we use move semantics and
transfer ownership to the new identifier. However, if somthing is <code>Copy</code> this
action now performs a bit-wise copy of the contents. An <code>i64</code> that is
re-assigned to a new variable will be a bit-wise copy. Contrast this to <code>Clone</code>
where the copying is explicit with the call to <code>Clone</code>. <em>Thus both <code>Clone</code> and
<code>Copy</code> signify copying of some kind, whether cheap or expensive, but the choice
is dependent on when the copying is preferred.</em></p>
<h3>tl;dr</h3>
<ol>
<li>
<p>I borrow values to avoid producing new values. In other words, I re-use
values that are already hanging around so as not to be wasteful with
allocations.</p>
</li>
<li>
<p>I copy/clone based on how I want to reduce allocations in the face of needing
to duplicate data, picking to allocate automatically or explicitly respectively.</p>
</li>
<li>
<p>I own values when I want total control of the data in question. I like to
think of this as <em>data recycling</em>.</p>
</li>
</ol>
<p>Here's some examples centered around iterators to give you a sense in practice.</p>
<h3>When to borrow</h3>
<p>Firstly, we can make a Vec of references, since the owner still lives while the
references live we don't need to allocate any new data.</p>
<pre><code>struct Wrapper {
  id: i64,
}

let values: Vec&lt;Wrapper&gt; = vec![
    Wrapper { id: 1 },
    Wrapper { id: 2 },
    Wrapper { id: 3 },
];
let xs: Vec&lt;&amp;Wrapper&gt; = values.iter().collect();
</code></pre>
<h3>When to clone or copy</h3>
<p>Next up, we might want to keep two copies of our <code>values</code>, if we change the
<code>Wrapper</code> to derive <code>Clone</code> we can use <code>cloned</code> on our iterator which is
functionally the same as <code>.map(|x| x.clone())</code>:</p>
<pre><code>#[derive(Clone)]
struct Wrapper {
  id: i64,
}

let values: Vec&lt;Wrapper&gt; = vec![
    Wrapper { id: 1 },
    Wrapper { id: 2 },
    Wrapper { id: 3 },
];
let xs: Vec&lt;Wrapper&gt; = values.iter().cloned().collect();
</code></pre>
<p>By default, most primitives are <code>Copy</code> because it's easy enough and usually
performant for the compiler to bitwise copy them. Since our <code>Wrapper</code> type in
the previous examples is just wrapping up a primitive <code>i64</code> integer, we can make
it also derive <code>Copy</code>:</p>
<pre><code>#[derive(Copy)]
struct Wrapper {
  id: i64,
}

let values: Vec&lt;Wrapper&gt; = vec![
    Wrapper { id: 1 },
    Wrapper { id: 2 },
    Wrapper { id: 3 },
];
let xs: Vec&lt;Wrapper&gt; = values.iter().copied().collect();
</code></pre>
<p>You might use <code>copied</code> if you don't want to write <code>.map(|x| *x)</code> if you happen
to have a collection of borrowed values at your disposal (imagine you are passed
a <code>Vec&lt;&amp;Wrapper&gt;</code>), this could be handy. The same logic stands for <code>cloned</code>. The
case is a little bit different for <code>Copy</code>, though. If we can own the iterator
with <code>into_iter</code> then any move of the values will result in a bitwise copy. This
is why you will sometimes see the rust compiler complain that a value is moved
and doesn't implement the <code>Copy</code> trait: it can't make a copy for you and it also
can't re-use a moved value.</p>
<h3>When to own</h3>
<p>Ownership is the basis of why we don't need garbage collection in Rust. Passing
an owned value across several different method calls could make copies or pass
pointers depending on what optimizations the compiler wishes to perform, hence
they could be <code>memcpy</code>s or as copied pointers. Regardless of how they work under
the hood, they prevent a host of bugs by ensuring <em>only one thing</em> has the
responsibility of finalizing the release of memory.</p>
<p>Expecting owned values is a nice way to push the decision to allocate on the
caller. If the caller wants to keep the value it owns, it must clone the value
itself, instead of guessing if a clone is happening elsewhere. More importantly,
writing code that expects values to be owned exposes the intent that I want to
have full control over the memory to do as I please, rather than trying to work
around what may already exist. This is why anytime you want to transform
something from one shape to another and don't care much or at all about the
original shape, taking ownership is the right choice.</p>
<pre><code>#[derive(Copy)]
struct Wrapper {
  id: i64,
}

let values: Vec&lt;Wrapper&gt; = vec![
    Wrapper { id: 1 },
    Wrapper { id: 2 },
    Wrapper { id: 3 },
];
let values: Vec&lt;Wrapper&gt; = values.into_iter().collect();
</code></pre>
<p>Note how I re-assign <code>values</code> after the transformation; albeit not necessary, it
does let me think a bit less about re-naming the original binding that I can't
use anymore.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Four Ways To Avoid The Wrath Of The Borrow Checker</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/four-ways-to-avoid-the-wrath-of-the-borrow-checker.html</link>
      <guid>https://justanotherdot.com/posts/four-ways-to-avoid-the-wrath-of-the-borrow-checker.html</guid>
      <pubDate>Sun, 01 Mar 2020 16:07:25 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Maybe you've tried to write a simple program in Rust using references that would
normally have taken less than an hour in C only to find yourself <em>hours</em> later
still fussing about with the Rust compiler. If the borrow checker seems too
restricting, here are four ways to loosen its grip.</p>
<h3>Shared Ownership with <code>Arc</code> or <code>Rc</code></h3>
<p>Shared ownership is what most garbage collected languages support. This is done
using a reference counting to objects in memory. We can mimic this in Rust with
the wrapper type <code>Rc</code>. If you plan on reference counting in multi-threaded code
you can use <code>Arc</code> where the <code>A</code> stands for <code>Atomic</code>.</p>
<p>Passing around an <code>Rc</code> means that if someone wants to jointly own the data, they
can simply call <code>clone</code> on the <code>Rc</code>. This can be used as a drop-in replacement
for places where you would borrow. Since these reference bumps count as new
owners there is no borrowing at all. However, now that we can express shared
ownership we also express a <em>graph</em> and graphs can have cycles (place where
pointers loop back on themselves). A cycle in a graph means a value may never be
deallocated, hence any self-referential structure poses a memory leak in our
program. You can avoid this by having the pointer that &quot;ties the knot&quot; be a
<code>Weak</code> pointer, which just means it's a non-owning pointer. A classic example is
with a cache: you want to have entries in the cache to objects owned outside of
the cache but you don't want the entries to count towards owning anything,
otherwise keeping the cache around means keeping all of the memory! Also, <code>Rc</code>
means you won't be able to take mutable borrows to the contents. This is easily
remedied with the use of <code>Rc&lt;RefCell&lt;T&gt;&gt;</code> or even <code>RwLock</code> as we'll see later.</p>
<p>&quot;When in doubt, reference count&quot; is appropriate for places where laying out
borrows and static lifetimes can be a pain and you want to get things passing
quick. Places where you temporarily use an <code>Rc</code> can easily be targeted for
borrows, so going back to fix things is clear. It may take some jiggling to get
things into place but at least it can happen later down the line when you've got
the breathing room, perhaps.</p>
<p><code>Rc</code> can be particularly handy when you want to pass around function references
in all sorts of ways. I used <code>Rc</code> extensively when porting a functional library
from F# and Haskell directly into Rust and needed to easily get mutual recursion
working quickly where using direct references or owned trait generics (e.g. F:
Fn(A) -&gt; B). I was later able to swap out the calls to references, which meant
the ergonomics of the first call simplified to borrowing rather than wrapping
the closures in question in <code>Rc</code>s.</p>
<h3>Interior Mutability with Cell or RefCell</h3>
<p>Exterior mutability (otherwise known as &quot;inherited mutability&quot;) is great because
it lets us know what things are actually changing beneath us. But sometimes
clients don't care that some housekeeping state is changing underneath an
operation. Perhaps we memoize the result of a function or manipulate a counter;
in both of these cases, with exterior mutability, the function wrapping this
action would have to be marked as mutable in some way, but if we want to keep
things looking immutable on the surface, we can use <code>Cell</code> or <code>RefCell</code> instead.</p>
<p>To give a concrete example with memoization, you might have an expensive
computation that you only want to do once and stash the result. As such, you
have a function that only need to be mutable for this one time and can be
immutable the rest of the time, so it doesn't make sense to have it marked as
<code>mut</code>. Whatever the result type is, we can wrap that in a <code>Cell</code> or <code>RefCell</code>,
depending on type: <code>Cell</code> is generally for things that support <code>Copy</code> and
<code>RefCell</code> for the rest.</p>
<p>As <code>RefCell</code> uses dynamic borrow checking, it can panic if multiple mutable
borrows are taken to the contents. <code>Cell</code> doesn't suffer from the same issue as
it moves the values in and out of the internals of the <code>Cell</code>. As such, you may
want to use something like <code>RwLock</code> if you are using an <code>Rc&lt;RefCell&lt;T&gt;&gt;</code> for
multi-threaded code. <code>Rc&lt;RefCell&lt;T&gt;&gt;</code> is a common way to have a shared object,
such as a <code>HashMap</code>, across several owners, but still mutate it. If one used
<code>Rc::get_mut</code> one would need to mark the <code>HashMap</code> itself as <code>mut</code>.</p>
<h3>Duplicate the data</h3>
<p>Often people think that coming to Rust means programs should be completely
devoid of <code>clone</code> but if you think about the language you may be coming from,
whatever <code>clone</code>ing you are doing is in Rust probably pales in comparison.</p>
<p>You don't need to feel bound to a <code>clone</code>less program by default. By abandoning
this idea of a slim program from the outset and move towards something far more
flexible. This generally means having duplicate formats of a data structure for
varying purposes such as one be a game map where walls are located whereas
another could be where someone has explored and yet another could contain items
on each tile, etc. It can also mean having a duplicate you want to make changes
to, leaving the original in-tact. This is more of the pure approach functional
programming languages tend to take, but these languages can also make particular
optimizations around immutability such as persistent data structures or
&quot;sharing&quot; of data since <em>everything</em> is immutable by default. Here's an example
that having some duplication of data might help. Perhaps you are trying to
iterate over a collection and mutate it:</p>
<pre><code>let mut xs = vec![1,2,3];
for x in xs.iter_mut() {
  if x % 2 == 0 {
    xs.push(x+1);
  }
}
</code></pre>
<p>In fact, this fails because we are borrowing to <code>xs</code> mutably twice! Once when we
construct the iterator and another time when we push to the <code>Vec</code>. This is a
classic &quot;modify a data structure while you iterate over it&quot; issue. However, we
could easily do this:</p>
<pre><code>let mux xs = vec![1,2,3];
let ys = xs.clone();
for x in xs.iter() {
  if x % 2 == 0 {
    ys.push(x+1);
  }
}
</code></pre>
<p>and hum along. In fact, we can keep these allocations to be short-lived, which
may or may not be a performance issue but that can always be addressed later
with proper profiling.</p>
<h3>Single ownership and data pipelines</h3>
<p>Lastly, you can try to go away from references entirely. Ownership is ideal for
the kinds of problems best described as transforming values into other kinds of
values.</p>
<p>Pipelines have stages or steps. Steps may build up required changes or apply
earlier changesets. Pipelines are useful for a variety of solutions. Parsers,
compilers, streaming analysis, and so on, however that isn't the end of it.
Configuration could be seen as a stream that updates when new values are added.
This isn't to say all pipelines are pull models but it is to say the solutions
are broad.</p>
<p>If the use of borrows is for performance (want to ensure a large structure isn't
<code>memcpy</code>d to a function), this type of optimization should already happen behind
the scenes with move semantics; an owned type will typically get passed by
<code>memcpy</code> for smaller sized objects and may be passed as a pointer for larger
objects. This means that there is no mechanical difference for borrows besides
marking the earlier variable as uninitialized meaning we always have no more
than one owner of a value at a time.</p>
<p>When data flows through a pipeline, doing it all by mutable reference can
achieve the same effect and the owner doesn't relinquish control. Although this
<em>might</em> mean there are less allocations, it will mean each step of the way we
are passing a pointer where copying an object might have actually been faster.
This is also limiting in that we can only have on mutable borrow at a time! If
callers allocate the objects they own and request they be transformed into a new
shape, any number of threads could pass values into this pipeline for changes
and be content that value changes will be isolated from one-another.</p>
<h3>Recap</h3>
<ol>
<li>Use <code>Rc</code> or <code>Arc</code> when you want to quickly get past tricky borrow issues and
want to convert back to borrows possibly later in time to reap the benefits
they offer</li>
<li>Use <code>Cell</code> or <code>RefCell</code> when you have an API that doesn't need to expose
mutability to a client</li>
<li>Get comfortable with cloning data for multiple purposes to avoid conflicting
borrows</li>
<li>Don't borrow at all and create pipelines that pass ownership from step to
step, producing a final, desired result</li>
</ol>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Bindings Are Cheap: Managing Rightward Drift</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/bindings-are-cheap-managing-rightward-drift.html</link>
      <guid>https://justanotherdot.com/posts/bindings-are-cheap-managing-rightward-drift.html</guid>
      <pubDate>Thu, 20 Feb 2020 20:34:34 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>How do you avoid deeply nested <code>if let</code> or <code>match</code> statements when you're first
coming to Rust? Rightward drift is a pain to decipher in any language, but the
good news is you can manage rightward drift in Rust with a few techniques and
some mental shifting. Maybe this is the code you're writing which has a lot of
if-let chaining:</p>
<pre><code>if let Some(x) = some_func() {
    // do stuff with x
    if let Some(y) = some_func2() {
        // do other stuff with y
        if let Some(z) = some_func3() {
          // and so on
        } else {
          reticulating_splines()
        }
    } else {
        engage_thrusters()
    }
} else {
    launch_the_missiles()
}
</code></pre>
<p>In Rust, everything is an expression, and every expression has a value. For
control flow, that means all branches must return values of the same type. If
you look at the code above you ought to see that whole thing as <code>()</code>, assuming
the functions in the <code>else</code> blocks above return <code>()</code>. When I look at the above
code snippet I think &quot;this code is always meant to succeed but with different
results on the types of success&quot;. This code is always mapping <code>Some</code> and <code>None</code>
to <code>()</code>, which doesn't tell the caller much besides &quot;I might have done
something.&quot;</p>
<p><strong>A <code>None</code> implies the absence of something. If we want more information for
<em>why</em> the data we want isn't there we can use the <code>Err</code> variant on <code>Result</code></strong>.
The intent with the <code>try</code> (<code>?</code>) operator is to always allow a way to express
this 'failure' back to the caller when it first happens; we should not assume we
can go ahead safely with the subsequent code and return from the current
function.</p>
<p>A style I like to recommend to people is known by some as &quot;newspaper article&quot;
style. Since Rust is an expression-oriented language we can <code>let</code>-bind to almost
anything! This means we can write our fix as:</p>
<pre><code>let x = some_func()
  .or_else(|| { launch_the_missiles(); None } )?;
let y = some_func2()
  .or_else(|| { engage_thrusters(); None } )?;
let z = some_func3()
  .or_else(|| { reticulating_splines(); None } )?;
// and so on.
</code></pre>
<p>If we wanted to only give the caller the sense that nothing bad happened,
we could wrap the whole thing in a block and discard the result (NB. the
semicolon at the end of the block):</p>
<pre><code>fn top_level() {
    fn go&lt;T&gt;() -&gt; Option&lt;T&gt; {
        let x = some_func()
          .or_else(|| { launch_the_missiles(); None } )?;
        let y = some_func2()
          .or_else(|| { engage_thrusters(); None } )?;
        let z = some_func3()
          .or_else(|| { reticulating_splines(); None } )?;
        // and so on.
    }
    go(); // throw away the result for the caller.
}
</code></pre>
<p><strong>But this is weird</strong>. Giving callers control is at the crux of good error
handling, especially when it comes to something as powerful as errors as values!</p>
<p>What I absolutely love about the rampant <code>let</code>-bindings approach is that it
provides a lot of flexibility for modification; with <code>let</code> bindings we can
remove or modify the offending assignments exactly, rather than mangling a
rather delicately constructed expression.</p>
<p>Rust also lets us shadow variables and with its move semantics we can avoid
unexpected allocations when doing things like expressing data as it changes
throughout various steps but under the same name:</p>
<pre><code>struct Json {
  property: i64,
}

struct Error {
  SerdeError(serde::Error),
  IoError(std::fs::IoError),
}

fn update_json() -&gt; Result&lt;(), Error&gt; {
  let json = include_str!(&quot;../some.json&quot;);
  let json: Json = serde_json::from_str(&amp;json);
  json.property = 42;
  let json = serde_json::to_string(&amp;json);
  fs::write(&quot;../some.json&quot;, json)?;
}
</code></pre>
<p>Use <code>let</code> bindings and the <code>try</code> operator liberally and you'll make your code
easier to modify and read. If you have custom types you've written yourself you
might,</p>
<ul>
<li>one day be able to write an implementation for the <code>Try</code> trait yourself when it stabilizes (its currently experimental)</li>
<li>take a cue from <code>Option</code> and <code>Result</code> and write similar combinators that let you get at internal data for your type</li>
<li>merely wrap things in <code>Option</code> and <code>Result</code> and use the bevy of methods they expose</li>
</ul>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Idiomatic Argument Passing in Rust</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/idiomatic-argument-passing-in-rust.html</link>
      <guid>https://justanotherdot.com/posts/idiomatic-argument-passing-in-rust.html</guid>
      <pubDate>Fri, 14 Feb 2020 06:05:17 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>If you're coming from a language that supports automatically taking references
to arguments you may wonder why Rust can't do the same. Rust is all about giving
developers a better control of the memory layout of the data in their programs.
Since Rust has the notion of ownership, we don't have to worry about large
objects being copied into a function when the arguments to a function are owned.
Instead, they are moved (pass-by-move), and when I first started writing Rust I
assumed the idiom was to always use owned types for function arguments. For
clarity, we call something an &quot;owned&quot; typed when it isn't behind a reference
(<code>&amp;</code>). When an argument is behind a reference, we call that a &quot;borrowed&quot; type.</p>
<p><strong>tl;dr</strong>
<em>Idiomatic Rust functions ought to borrow arguments unless a function needs to
completely own an argument for ergonomics (say, method chaining) or allocation
(the caller won't need to re-use the data, perhaps).</em></p>
<p>What's the case against owned types for function arguments as the default? All
data in Rust must have an owner and that owner is a variable. Function arguments
are variables. This means that when you give a function an owned type, you force
a caller to give away ownership of the data it has allocated and probably wanted
to use further down the line. If the function doesn't give back the value, it is
lost to the caller, and the memory will be de-allocated at the end of the call's
scope. Often callers <em>do</em> want to keep ownership of the values they pass into
functions.</p>
<p>Immutable borrows let functions decide if they want to make selective
allocations but that does mean a function may be allocating when the caller may
want to know all allocations upfront. Owned types are a good fit for this as it
is the caller's responsibility to allocate and give up ownership to the function
for its use. <em>Alternatively</em>, if a function wants to make a change (mutate) an
argument, it will be clear to the caller that data may change signaled by adding
<code>mut</code> after the <code>&amp;</code>. The common practice in C is to take pointers to
non-primitive values. This is done so large objects don't get copied on each
function call. However, with this approach of using raw pointers there is no way
to clarify when a pointer is simply going to read data and when it is going to
change it. With borrowed types in Rust we get this clarity at the syntactic
level.</p>
<p><strong>Idiomatic Rust functions borrow arguments unless it truly needs to own the
values or they are primitives.</strong> Rust copies primitive values as they are part
of the <code>Copy</code> trait. And this isn't to say you should <em>never</em> take owned
arguments. The <a href="https://doc.rust-lang.org/1.0.0/style/ownership/builders.html">builder
pattern</a>
explicitly takes ownership and gives it back at each method call, allowing us to
chain together calls prior to a <code>let</code> assignment. If we used <code>&amp;mut self</code> instead
we'd need to first assign the value with <code>let mut</code> and make the calls
separately.</p>
<p>This leads us to an interesting example: How would we write the inside of this
function?</p>
<pre><code>fn thin_air() -&gt; &amp;Vec&lt;i32&gt; {
    unimplemented!()
}
</code></pre>
<p>We could try to allocate and take a reference to the allocation?</p>
<pre><code>fn thin_air() -&gt; &amp;Vec&lt;i32&gt; {
    &amp;vec![]
}
</code></pre>
<p>But the borrow checker will refuse this program because our <code>Vec</code> only exists
for the scope of <code>thin_air</code> and if we held a reference after the point it was
dropped (its memory is freed) we'd be holding a pointer to garbage which is not
safe to read or write to. Thus, if we want to return a borrowed type, we must
also take a borrowed type or something that holds a borrowed type.</p>
<pre><code>struct&lt;'a&gt; Data {
  integers: &amp;'a Vec&lt;i32&gt;
}

fn thin_air(data: Data) -&gt; &amp;Vec&lt;i32&gt; {
  data.integers
}
</code></pre>
<p>To recap, Rust cares about memory safety and layout a fair amount and puts the
work on the programmer to decide when references to arguments should be taken.
Choosing immutable borrows by default means you won't cause any unintended
consequences besides maybe some stray allocations. If you want to change the
content that the caller owns and, hence, has allocated, switch to a mutable
borrow. Lastly, if you know the caller won't need the argument anymore or if it
wants to return an owned type in exchange of the passed in argument(s), the
function ought to take ownership.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Error Handling With Closures In Iterators</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/error-handling-with-closures-in-iterators.html</link>
      <guid>https://justanotherdot.com/posts/error-handling-with-closures-in-iterators.html</guid>
      <pubDate>Mon, 03 Feb 2020 19:38:54 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Iterators give us a wonderful array of functional-style combinators. Past
readability, the rust compiler can occasionally optimize iterators better than
it can for-loops, too. However, as iterators work by taking closures it can be
confusing on how to best handle them compared to using classic for-loops. Here's
a toy example:</p>
<pre><code>fn parse_str_of_i32(input: &amp;str) -&gt; Vec&lt;i32&gt; {
    input.split(&quot;,&quot;)
        .map(|char| char.parse().unwrap()) // `unwrap`!
        .collect()
}

let input = &quot;1,2,3,4,5,6,7,8,9,0&quot;;
let numbers = parse_str_of_i32(input);
assert_eq!(numbers, vec![1,2,3,4,5,6,7,8,9,0]);
</code></pre>
<p>This works but it has an <code>unwrap</code> which means that if callers pass invalid
strings, such as <code>&quot;oh boy, here we go again&quot;</code>, it will panic, which gives
callers of this code little control when things go wrong. How can we convert
this to use <code>Result</code> and be more ergonomic? Consider the for-loops variant,
first:</p>
<pre><code>use std::num::ParseIntError;

fn parse_str_of_i32(input: &amp;str) -&gt; Result&lt;Vec&lt;i32&gt;, ParseIntError&gt; {
    let mut numbers = vec![];
    for char in input.split(&quot;,&quot;) {
        numbers.push(char.parse()?)
    }
    Ok(numbers)
}

let input = &quot;1,2,3,4,5,6,7,8,9,0&quot;;
let numbers = parse_str_of_i32(input).unwrap();
assert_eq!(numbers, vec![1,2,3,4,5,6,7,8,9,0]);
</code></pre>
<p>You might think this means if you want to use error handling while iterating you
need to have a for-loop instead of using Iterator but you can still have an
Iterator and have get the same type signature above for our parser!</p>
<pre><code>use std::num::ParseIntError;

fn parse_str_of_i32(input: &amp;str) -&gt; Result&lt;Vec&lt;i32&gt;, ParseIntError&gt; {
    input.split(&quot;,&quot;)
        .map(|char| char.parse())
        .collect()
}

let input = &quot;1,2,3,4,5,6,7,8,9,0&quot;;
let numbers = parse_str_of_i32(input).unwrap();
assert_eq!(numbers, vec![1,2,3,4,5,6,7,8,9,0]);
</code></pre>
<p>How does this work? <code>collect</code> knows how to take an Iterator of <code>Result</code>s and
turn it into an <code>Result&lt;Vec&lt;A&gt;, B&gt;</code>. At the first sight of an <code>Err</code> the whole
expression will become the <code>Err</code> case but if everything works out with <code>Ok</code> then
the Iterator will take all the values into their own <code>Vec</code> and return <code>Ok</code> of
the enclosing <code>Vec</code>. This is sometimes referred to as a &quot;transpose&quot; and you can
see similar 'inside-out' behaviour elsewhere, including <code>Result</code>
<a href="https://doc.rust-lang.org/std/option/enum.Option.html#method.transpose">itself</a>.</p>
<p>You can also specify collections other than <code>Vec</code>. If <code>A</code> is something that can
be <code>collect</code>ed into some container <code>V</code>, then an <code>Iterator&lt;Item=Result&lt;V, B&gt;&gt;</code> is
possible. Have a poke around the <code>FromIterator</code> <a href="https://doc.rust-lang.org/std/iter/trait.FromIterator.html">trait
docs</a> to get a
better sense of what <code>collect</code> can roll up!</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Structuring Rust Projects With Multiple Binaries</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/structuring-rust-projects-with-multiple-binaries.html</link>
      <guid>https://justanotherdot.com/posts/structuring-rust-projects-with-multiple-binaries.html</guid>
      <pubDate>Thu, 30 Jan 2020 16:31:53 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>How do you organize Rust projects with multiple binaries so that the build
output winds up in a common subdirectory? Should you be looking for a solution
other than cargo? Regardless of whether you are using nested crates within a
workspace or simply a mixture of <code>.rs</code> files under <code>src/bin/</code>, <strong>you absolutely
should be looking for something other than cargo.</strong> What you need is a proper
task runner and the most portable task runner ships with every unix
flavored operating system; <code>sh</code>.</p>
<p>People seem to conflate task runners with build tools. Build tools generate
artifacts such as binaries or libraries whereas task runners act as the glue for
teams to share ways to achieve particular chores. Some people use tools like
<code>make</code> to do both jobs and the crossed responsibility brings a lot of pain and
maintenance burden. People need to be aware of the many nuances of <code>make</code> such
as the fact that tabs for indenting are semantic, rules for tasks need to be
marked as <code>.PHONY</code> if there is a target they relate to, and so on. Others end up
using scripting languages such as python or javascript or they may use some
hybrid domain specific language that mixes a bit of programming and
configuration to specify how tasks are run, e.g. <code>gulp</code>. You don't need any of
these options.</p>
<p>I'll call this script <code>bin/build</code>. We will assume there are several crates in a
workspace for this example and that we use <code>git</code> since cargo bootstraps projects
with it by default.</p>
<pre><code>#!/bin/sh -eux

ROOT=$(git rev-parse --show-toplevel)
cd &quot;$ROOT&quot;
mkdir -p dist/bin
for crate in crate1 crate2 crate3; do
  cd &quot;$crate&quot;
  cargo build --release
  cp target/release/$crate &quot;$ROOT/dist/bin/&quot;
  cd &quot;$ROOT&quot;
done
</code></pre>
<p>This script is dead-simple. It shoots to the root of the project, makes the
directories <code>dist</code> and its subdirectory <code>bin</code>. We have a list of crates in a
loop we iterate across but we could make this dynamic, as well. Then, in each
crate we create a release build and copy the binary from the project up to the
common subdirectory. Then, we shoot back to the root directory again and repeat.
All we have to do now to do now is make the script executable and call it:</p>
<pre><code>$ chmod +x bin/build
$ bin/build
</code></pre>
<p>You don't need to let scripts grow out of control, either. What's awesome about
keeping scripts, and, more generally, programs small means you can compose
things like this:</p>
<pre><code>
bin/init
bin/run
</code></pre>
<p>Where <code>init</code> might do some stubbing or setup work and <code>run</code> might launch a
service, whatever those tasks may be.</p>
<p><code>sh</code> is POSIX compliant, which means it allows us to write highly portable, and
therefore shareable, scripts. Like anything there are ways things can go wrong
but you can address this by using the linter
<a href="https://github.com/koalaman/shellcheck">shellcheck</a>. Every shell script you
write should have the following</p>
<pre><code>#!/bin/sh -eux
</code></pre>
<p>Which says to use <code>sh</code> instead of, say, <code>bash</code>. shellcheck will actually
recommend things intelligently based on which shell you specify. <code>bash</code> is not
ideal here because support for particular features differs between versions and
we are aiming to have something pretty much anyone on a team can use at a
moment's notice so long as they are using linux, bsd, darwin, or any other *nix
flavor. This prelude also turns on some common flags.</p>
<ol>
<li><strong>e</strong> to stop on the first <strong>e</strong>rror</li>
<li><strong>u</strong> to stop if a variable is <strong>u</strong>nset</li>
<li><strong>x</strong> to print tracing output of each e<strong>x</strong>ecuted statement</li>
</ol>
<p>(3) can be optionally dropped if you don't want to expose details or want
cleaner output.</p>
<p>The last convention is to keep scripts in a common <code>bin</code> directory at the root
of your project which enhances discoverability of scripts for others. Allowing
people to make less guesses about which directory is the single source of truth
for automation scripts helps people move faster. If they want a chore done, they
can see what's present under <code>bin</code>, or if they need to add a chore they know
exactly where it's added for every project. The reason for why its called <code>bin</code>
is that they are executables!</p>
<p>In summary, for shell script success all you need is:</p>
<ol>
<li>A common prelude that uses <code>sh</code> and some options set</li>
<li>Using shellcheck to ensure you're writing sensible and POSIX compliant scripts</li>
<li>A common directory for scripts that is the same for all projects</li>
</ol>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Peer Pressure Is The Sign Of Ownership</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/peer-pressure-is-the-sign-of-ownership.html</link>
      <guid>https://justanotherdot.com/posts/peer-pressure-is-the-sign-of-ownership.html</guid>
      <pubDate>Tue, 21 Jan 2020 19:27:28 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>I'm nearing 6,000 contributions on GitHub. I mix personal and private
contributions but I estimate a large portion of of the changes are from work.
This is up from about 1,700 contributions back in 2018. Not all valuable
contributions to a tech business are GitHub related; people write documentation,
sketch out strategic plans for the business, spend time researching technical
details, design user experiences, analyze user data for purposes of sales and
marketing, and so on. All of these things don't wind up being issues,
pull-requests, code review, or direct commits into a codebase and yet
nonetheless help keep the company move forward.</p>
<p>Nonetheless, a tech company has healthy codebase(s) when there is a fervor of
activity. Likewise, if your codebase(s) are highly active they may suffer a lot
of churn, where changes that are introduced are swiftly eased back out only to
be re-introduced again in rapid cycle. The true mark of health on codebase(s) is
a mark of steady progress despite the occasional setback. Sure, <strong>stable systems
do exist</strong> where activity is but the occasional patch but when something is
deemed stable can vary drastically depending on the complexity of the project
and the requirements that steer its growth.</p>
<p>Giving ownership away can be scary. What if we render control to members of the
team and all we get in return is a product running in circles? What if nothing
of value gets built and the product stagnates and rots?</p>
<p>Top down management makes sense in a factory setting; if you have a large room
full of people manually slaving away building widgets, you can treat them and
their process much like a chariot driver and its steeds; whip and hurl insults
at will and the workers will move faster. There is enough generality to
optimizing assembly lines that the illusion of optimizing <em>all</em> forms of
business or systems are alike. <em>Wrong</em>. This management by microscope devolves
into micromanagement and creative output can't be managed in the same way. Jobs
that require a lot of thought in addition to output require a more hands-off
approach to achieve excellent results. Optimizing for output for creative output
means giving away the keys.</p>
<p>You can't create an illusion of ownership, either. Managers sometimes think they
can retain authority over decisions on a project while paying lip-service to
'owners'. This is a recipe for disaster when the truth is unveiled. Allowing
others to own systems (or projects) or subsections of systems (or projects)
allows them to thrive. Ownership leads one towards <a href="https://www.justanotherdot.com/posts/make-a-home.html">home
making</a> where members
focus on the pursuit of an ideal lifestyle and surroundings.</p>
<p>A product rarely has a single project as a neighborhood rarely has a single
home. Imagine a partially isolated village with inhabits of various skills; for
the village to prosper everyone has to have a certain level of interdependence
for their survival and happiness.</p>
<p>And here's the rub, owners of projects put demands on other owners, without
expecting some central authority to put the demands on them instead. The sign of
ownership is peer pressure. Work gets queued up and prioritized in manageable
pools. All of our goals needed to be aligned to the business, sure, but it is up
to these owners to figure out how to best accomplish that goal within reason. A
central authority can still keep watch that things are on theme. People can
still move across a system and do changes where they need to with respect to
owners of the system the proposed changes are occurring. Ownership imbues a
sense of care on all parties. If no one owns anything, then everyone will do as
they please with little regard to 2nd or 3rd order consequences.</p>
<p>If you can't start fresh with respective owners at the get-go, try starting
small and handing out keys to smaller chunks of the larger system. You need
trust to make this work otherwise you'll wind up with a self-fulfilling
prophecy. The experiment will change you and your teams for the better.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Consistent Date Handling</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/consistent-date-handling.html</link>
      <guid>https://justanotherdot.com/posts/consistent-date-handling.html</guid>
      <pubDate>Sat, 18 Jan 2020 19:27:50 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Date handling is the kind of funny where you sob from of the ways it can
horribly cut you when you least expect it. Developers either pretend that <em>all</em>
date handling concerns can be shoved onto third-party libraries or that they
don't exist at all. Here's a short, incomplete primer.</p>
<p>There are two common formats for storage; as strings or as integers. Although
integers have a history of heavy optimization on modern CPUs and compilers,
strings can have reasonable performance with the right memory structure. This
integer format is typically known as <a href="https://en.wikipedia.org/wiki/Unix_time">Unix Epoch
Time</a> and the start of the world for
this format is January 1st, 1970; the birth of Unix. A 32-bit integer,
expressing seconds since January 1st, 1970, ends at 19 January 2038. 64-bit Unix
Epoch's will end <a href="https://en.wikipedia.org/wiki/Year_2038_problem#Possible_solutions">292 billion years from now, at 15:30:08 UTC on Sunday, 4
December 292,277,026,59</a>.
This is far after the estimated death of the universe and if your system is
still running after that I think that deserves a nice pat on the back.</p>
<p>Where you are is your <em>time zone</em> based on wobbly, vertical slices of the world.
UTC is the &quot;base&quot; time zone and is such because it's on the prime meridian (zero
degrees longitude). Think &quot;base time zone&quot; where the offset is <code>00:00</code>. Let's
pretend we are sitting in a lawn chair in this time zone, which is the same as
GMT or &quot;Greenwich Mean Time&quot;, so, not a sunny day.</p>
<p>As you recline in the lawn chair time passes by but the earth's rotations and
the solar orbits are complicated things. Time doesn't <em>just</em> pass bit-by-bit. It
does in a mathematical sense, sure, but time is a construct with ideas such as
days, weeks, and years. To fit time into these relatively standard quantities,
such as the number of days per given month or total days in year, we must make
small adjustments to time, such as leap years, leap seconds, and daylight
savings. Each of these 'correct' some kind of drift. However, the Unix Epoch
format doesn't encode leap seconds, which is one type of correction.</p>
<p>Enter <a href="https://en.wikipedia.org/wiki/ISO_8601">ISO8601</a>. Among several nice
properties but for starters, humans can read it! The timestamp,</p>
<pre><code>&quot;2005-01-01T00:00:00&quot;
</code></pre>
<p>is equivalent to the Unix Epoch,</p>
<pre><code>1104537600
</code></pre>
<p>It's far easier to quickly determine if an ISO8601 is suffering corruption than
eyeballing integers. It's also much easier to tell what ballpark of dates an
ISO8601 is in. If you have a bunch of ISO8601 timestamps, you can sort them with
default strings comparison (lexicographic) and they will naturally be in
ascending order. I love this feature about them because it means I don't need to
rely on a library to order a bunch of well-formed ISO8601s. Opposed to our
fixed-precision Unix Epoch integers, ISO8601 allows for variable granularity.
You <em>can</em> get finer granularity for time on Unix systems but I won't go too far
into that here. You can run <code>man 2 gettimeofday</code> and <code>man 2 clock_gettime</code> for a
slightly deeper understanding of some options on Linux.</p>
<p>Back to our lawn chairs someplace in Sunny England, time zones are expressed
officially as strings describing two parts separated by a forward slash, e.g.
<code>Australia/Sydney</code> or <code>America/Los_Angeles</code>. If you have any formatting you need
to do for a client reading data, you need to encode time zones. However, it is
OK to not deal with time zones if you are dealing with an &quot;absolute time&quot; for a
given data set that is fixed to a place. You then have a direct link between a
set of timestamps and time zone.</p>
<p>ISO8601 has an optional time zone specifier. RFC3339 enforces that the timezone
be specified but for the case of UTC you don't need to specify the specific
offset as it is implicit. Time zones tend to be exposed to many odd political
changes. Offsets assume a timezone will <em>always</em> be a particular amount, but
this isn't quite true. As recent as 2011, Samoa changed their time zone for
trade reasons. Originally, <code>Pacific/Apia</code> had an offset of UTC-11 (note the
minus) but it changed for trade reasons and went to UTC+13 (note the plus).
That's a big jump! Thus, the timestamp:</p>
<pre><code>2013-01-02T12:00:00Z-11:00
</code></pre>
<p>is invalid for Somoa. However, if you didn't specify the offset as part of the
stored data, you could get away with looking up the time zone for <code>Pacific/Apia</code>
indexed by some granularity, say, year. This way you can record both offsets
before and after 2011. We could encode the timestamp simply as</p>
<pre><code>2013-01-01T01:00:00Z // UTC
</code></pre>
<p>and the lookup for the year 2013 would reveal that <code>Pacific/Apia</code> is <code>+13:00</code>
meaning we can now shift this date over properly for Samoans. In fact, you don't
even need to store the specific index as most time zone databases that third
party libraries provide already extensively document this information.</p>
<p>Its important to keep your timestamps in a canonical timezone. In the case of
Unix Epoch, by definition the seconds from midnight January 1st 1970 needs to be
in UTC, similar to the default timezone for ISO8601. Picking a canonical time
zone, specifically UTC, will save you a lot of time from painful sleuthing as
two dates without timezone information <em>could</em> be from different timezones.</p>
<p>Chat applications have to pay particular care to this. If someone is sending
messages from San Francisco but another person is replying from Beijing, the
time difference is an important part of the UI. How many hours are we off? When
did they really read my message? Did they send it before or after me? Causality
is its own can of worms for distributed systems, hence this is a bit of a
hand-wavey argument that is ignoring some really critical (and nasty) aspects of
time, but having most things stored as a single time zone and stashing client
time zone preferences or figuring out what their device location is and using
the time zone from that can save a <em>lot</em> of grief.</p>
<p>As a recap here's the basics:</p>
<ol>
<li><strong>Pick one format and stick to it</strong></li>
<li><strong>Always store your timestamps in a single, canonical time zone</strong></li>
<li><strong>Store time zone preferences for clients as a string rather than the
offset</strong></li>
</ol>
<p>And that's a short primer. Time can get a lot more nuanced, such as focusing on
monotonically increasing time for servers and thinking through concerns like
storage space, but most applications won't need to care too much about these
things. A little upfront focus on consistency will save you a lot of shed tears.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>The Production Environment's New Clothes</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/the-production-environments-new-clothes.html</link>
      <guid>https://justanotherdot.com/posts/the-production-environments-new-clothes.html</guid>
      <pubDate>Fri, 10 Jan 2020 19:08:56 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Staging environments are a distraction. Massive hours have been poured into
making them coherent with production all to little effect. When staging
environments become unbearable developers start resorting to alternative
environments that can be spun up at will or are equally long-lived as staging
environments are. These production clones feel safe to developers and product
managers because they they aren't shown to customers. One uncomfortable fact
that developers and product managers struggle with is that <strong>production doesn't
mean seen.</strong></p>
<p><a href="https://www.justanotherdot.com/posts/move-fast-and-tuck-code-into-the-shadows.html">I've written about this
before</a>
but received some confused responses and I think I've realised why people feel
uncomfortable about this concept. Feature flag aren't just for testing shades of
blue. Feature flag services at as curtains over new functionality until you are
ready for the big reveal. There are third party services out there but you can
write your own feature flagging system to hide away details although there are
some limitations with doing it yourself. I have long been a proponent of small
pull requests; small changes give large boosts of energy, helping progress and
leading to the eventual discovery that you've built a mountain when it has felt
like a short jog. Developers who feel safe pushing changes start pushing a lot
of changes, hence, I think having a great feature flagging system is pivotal to
making the small pull requests approach feasible in a team.</p>
<p>It's understandable why there is a reluctance to have one environment. There is
a natural pain associated with pushing bad code and frantically trying to fix
it. Tucking things into the shadows means you are growing and building while no
one else really notices. Then, one day they come around and notice the
flourishing garden and sculptures you've built that they couldn't see before.</p>
<p>A basic feature flagging system is a key-value store for named tags, the key,
and booleans, the value. Non-existent tags are always false to avoid strange
behaviour. The steady state of the system is when all flags are off. Flags
should persist across the whole of the architecture to reduce mismatch and
bloat, which means a flag should be visible to all parts of the larger system or
product. Flags should be persisted to long term to be robust in the case of
failures.</p>
<p>Fancier feature flagging systems support things like traffic routing and mutual
exclusion. As noted before, a user may be randomly assigned to a split in an
<a href="https://en.wikipedia.org/wiki/A/B_testing">A/B test</a> and that particular flag
they were assigned may be incompatible with other flags. This isn't needed out
of the box unless your platform is already messy or you are suffering from too
much load.</p>
<p>Buggy code or migrations can poison a production database. If you are not
already taking regular snapshots of your database, fix that! Trying to prescribe
solutions for various use cases could easily fill other articles, but I will say
that despite it seeming scary that you are mixing feature-flagged code and
steady-state code that both touch the same shared state, with some forethought
it is far easier to curate one pool of data. If you can get back to a good known
state, you can work towards a granularity of restoration that suits your
products needs. A fantastic book on operations around databases that goes in
much greater depth is <a href="https://www.goodreads.com/en/book/show/36523657-database-reliability-engineering">Database Reliability
Engineering</a>.</p>
<p>Tying this all together, you should treat features as immutable migrations. An
immutable migration is one that doesn't happen in place, such that if I have
state A and want to be in state B, I first create state B and transition over. A
mutable migration is the one most people are familiar with, changing a piece of
pre-existing code, testing it locally and in a staging environment or similar,
perhaps even prod, and hoping for the best. Another way to put it, there is a
time where state A and B exist at the same time with immutable migrations, but
with mutable migrations the migration happens as a single commit.</p>
<p>With immutable migrations and feature flags, you can push the code progressively
to prod and test at-will. I'm a big fan of pushing code to production that
doesn't isn't being used <em>yet</em>. Doing this a lot and using namespacing on a
lexical level, e.g. with function or module names. When I wrote about this
before I mentioned the idea of breathing room and immutable migrations give you
just that. In fact, they ought to be your default form of migration unless you
are certain doing an in-place change is going to make things quicker and be
relatively pain-free.</p>
<p>Less is more; have one environment you put all your effort and love into. Hide
things from your customers until you are confident of your release. Make
immutable migrations the default instead of risky (albeit faster) in-place
migrations. Put some thought in what you need to do to protect your shared
state. With this your deployments will get more fearless and frequent as well as
your changes smaller and easier to reason about. <strong>Production doesn't mean
seen.</strong></p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Soft Skill Hygiene</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/soft-skill-hygiene.html</link>
      <guid>https://justanotherdot.com/posts/soft-skill-hygiene.html</guid>
      <pubDate>Tue, 07 Jan 2020 18:57:10 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Eyes glaze over at the words &quot;soft skills&quot; for developers of both the &quot;ship it&quot;
and technical purists camp. Unfortunately, humans aren't emotionally empty
robots and team work is generally required to build anything of sufficient
complexity. Trust helps build innovative and productive teams. <a href="https://www.goodreads.com/book/show/33517721-the-culture-code">Trust is built
up from cultivating safety and vulnerability</a>
and we can achieve these characteristics through effective communication.</p>
<p>Listening comes first. People trust when they feel heard. Listening takes
patience and being patience is a skill that takes effort to improve. When we
listen, we can bubble with questions, agreements, and disagreements.
Disagreements may cause us to stop listening. Especially disruptive are
disagreements about expressed emotions. This is when respect comes into the
picture.</p>
<p><strong>Respectful listening means emotional validation.</strong> Although you may not think
that the other party's emotions are real that does not change the fact that the
other party feels them. It is disrespectful to hold the stance that you know a
person's feelings better than themselves. Validating someone else's emotions
means you trust the other party. A lack of trust tends to form from the worry
that other people are manipulating us. To properly validate other people's
emotions we need to take the leap of faith that the other party is being honest
with us. People look at others who share as having great depths of courage to
draw from, but it is the act of sharing that creates courage. It's the same with
trust; in order to trust others we also need to foster trust. I won't deny that
there are situations where someone may be manipulative and if you find you are
surrounded by this type of behaviour, get out! Signs of manipulation tend to be
oversharing of information (the subtle approach) or out-shouting peers (the less
subtle approach).</p>
<p>A conversation has two directions. We can weaken our discourse by being
aggressive or not even participating at all. When we don't participate that's
known as submissive or passive communication. Both passive and aggressive
communication can erode relationships. Refraining from sharing information does
not encourage others to share. Aggressively attacking shared information creates
cold speech. People fall into the aggressive mode of communication by likening
it to boldness and assuming that effective communication is <em>bold</em>
communication. Those with aggressive communication then cause others to refrain
from sharing.</p>
<p>Assertive communication is middle ground. Instead of chipping away at a
collective sense of safety and willingness to share, it helps strengthen
relationships. From a time management perspective it may make sense to say &quot;no&quot;
to as many things as possible; your time is a precious resource and wasting it
with needless tasks is a waste. But we don't always have to frame a &quot;no&quot; with
the word &quot;no&quot;. One variation of this technique I've found incredibly helpful is
the &quot;yes and ...&quot; approach. When you say &quot;yes but ...&quot; you inadvertently invite
debate, but when you say &quot;yes and ...&quot; you <em>validate</em> the other person's option
and provide your thoughts in addition.</p>
<p>Assertive communication is also respectful. As such, avoid using accusatory
language. Often when we feel something there is a tendency to state an
accusation rather than a reflection of how we feel, such as &quot;I feel nervous
about this option&quot; as opposed to &quot;you are always trying picking lousy options&quot;.
Note, also, the use of the word &quot;always&quot;. Using exaggerated language tends to
intensify debate. How do you tell someone they need to switch gears after a lot
of wasted effort on irrelevant details? Reminding someone of the facts will have
a far greater impact that the ensuing isolation created from making a judgement
on the person's ability to act.</p>
<p>Also, speaking with intent tends to encourage healthy discussion without
stopping healthy activity. This is one of the most empowering things I can
recommend. Stating &quot;I intend to ...&quot; allows others to raise any concerns but
also makes it clear that this is something you truly are going to do unless
there are serious complications with it. Paradoxically, asking for permission
tends to foster a lack of action <em>and</em> discussion.</p>
<p>Lastly, things that may seem useless but have big impact are making eye contact
(you can even possibly get away with <a href="https://www.sciencedaily.com/releases/2019/02/190205102532.htm">looking in the general
area</a>),
<a href="https://www.goodreads.com/book/show/25066556-presence?from_search=true&amp;qid=wpWrhGt3hv&amp;rank=6">posture</a>,
and
<a href="https://www.tandfonline.com/doi/abs/10.1080/00224545.1982.9713408">smiling</a>.
And that's it, really. Validate, share, be intentional, don't be an asshole even
if you're technically right, and you will go far in developing trusting and
cohesive teams than if you plugged your ears and pretend everything comes down
to luck.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>The One Dimensional Programmer</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/the-one-dimensional-programmer.html</link>
      <guid>https://justanotherdot.com/posts/the-one-dimensional-programmer.html</guid>
      <pubDate>Sun, 29 Dec 2019 20:00:26 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Technical skill alone is not going to advance your career as a programmer. In
the last two years I've received questions asking what I felt would be the
golden ticket to career advancement. The question is usually peppered with
specific examples, things such as &quot;do I need to learn language X?&quot; or &quot;perhaps I
should focus more on data structures, algorithms, or even infrastructural
knowledge?&quot;.</p>
<p>Yes, we, as programmers, need to keep afloat of many differing technical skills.
Yes, it is daunting and unclear what will best advance a career, especially if
what you are currently doing as a professional is already murky. &quot;Full Stack&quot; is
a rather bogus term that seems to sugar coat the ideas of &quot;roundedness&quot; and
&quot;balance&quot; in a programmer's skill set. The ability to parachute into unknown
territory and still manage to become a local is a remarkable skill, but it is
not found entirely by refining computer related expertise for if you do you
become a one-dimensional programmer.</p>
<p><em>The seed of this line of thought was inspired by Patrick McKenzie's article
<a href="https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/">Don't Call Yourself A Programmer, And Other Career
Advice</a>
which is well worth a read, but I am going to expand on the topic with a few
areas I don't think Patrick explores that I've felt have aided me.</em></p>
<p>Do you understand the ins-and-outs of business? I promise you it's not as
intense as learning the ins-and-outs of error-correcting codes, the minutiae of
details regarding LSM- or B-trees, or the specifics of the
fast-fourier-transform algorithm. Knowing the mechanics of business helps you
better weigh options when working directly on whatever it is you are programming
to be sold. A great book for this is <a href="https://www.goodreads.com/book/show/9512985-the-personal-mba">The Personal
MBA</a>.</p>
<p>Do you understand other people? You may not care to manage people but reading
about leadership and management will endow you with newfound abilities to better
work with peers and managers alike. Learning more about management and
leadership also allows you to see what kinds of management styles are out there
and whether or not you should be content with how you are being managed. My
favorite leadership book of last year was <a href="https://www.goodreads.com/book/show/16158601-turn-the-ship-around">Turn The Ship
Around!</a>
albeit not the only fantastic book on leadership and management I've read in the
last few years. Bonus points if you pick up a few top-tier parenting books. I
find they often teach me a lot about how to better interact with other people in
addition to my own children. The first I ever read that stuck with me was <a href="https://www.goodreads.com/book/show/769016.How_to_Talk_So_Kids_Will_Listen_Listen_So_Kids_Will_Talk?from_search=true&amp;qid=A20YKgAad8&amp;rank=1">How
To Talk So Kids Will Listen, And How To Listen So Kids Will Talk</a>.</p>
<p>Do you get how to write prose in your native tongue? Writing is ingrained in
what we do as programmers, but we need to be honest that we are still employees
that have to write emails, send messages on chat platforms, prop up
documentation, and so forth, all in a language not fit for a computer. Learning
how to write well drastically improves your ability to communicate effectively
with a time tested asynchronous format. Probably one of the best &quot;practical&quot;
books with concise tips is <a href="https://www.goodreads.com/book/show/41769546-100-ways-to-improve-your-writing-updated?from_search=true&amp;qid=0bszRxf7vW&amp;rank=3">100 Ways to
Improve Your Writing</a>.</p>
<p>If tasked with giving a talk could you whip up slides and enthrall an audience
in the allotted time without fuss? We practice public speaking each time we
open our mouths to another human being yet many of us don't consider that
&quot;public speaking&quot;. Enhancing your ability to communicate with spoken word and
body language drastically improves your capacity to convince others of a course
of action, improve relations with your peers, and rally management to give you a
promotion. One of my favorite and no-nonsense books on the subject is
<a href="https://www.goodreads.com/book/show/32784222-demystifying-public-speaking">Demystifying Public Speaking</a>.</p>
<p>Could you, left to your own devices, dream up a number of non-computer related
topics you'd want to explore? If the things you are reading only fit into the
categories noted above, it might be worth purposefully pursuing ideas that are
external to your field. Everything you explore need not be non-fiction, either!
Here's a sample of topics from my own current explorations:</p>
<ul>
<li><a href="https://www.goodreads.com/book/show/35297608-the-second-kind-of-impossible?from_search=true&amp;qid=nXScUtfJXZ&amp;rank=1">A new form of matter</a></li>
<li><a href="https://www.goodreads.com/book/show/39667068-acid-for-the-children?ac=1&amp;from_search=true&amp;qid=iYB5JCa0eO&amp;rank=1">A biography on the bassist Flea</a></li>
<li><a href="https://www.goodreads.com/book/show/36739320-because-internet?from_search=true&amp;qid=c5tPDh71fD&amp;rank=1">How English has evolved in the age of the Internet</a></li>
<li><a href="https://www.goodreads.com/book/show/28256439-the-hidden-life-of-trees?from_search=true&amp;qid=QvC55VC7MR&amp;rank=1">How trees communicate with one-another</a></li>
</ul>
<p>The more you gaze into the abyss, the less you are actually <em>in</em> an abyss; if
you are in &quot;box-mode&quot; all the time with your chosen field, the light on your
candle from within the cave will eventually grow darker and darker as it starves
of oxygen, but use the same candle to look in different places for light
switches and you'll start forming pools of light to help you better see the
world around you. <strong>Exploring different topics is how we discover disparate
ideas and connecting disparate ideas in unique and useful ways is is how we
innovate.</strong> Stop being a one-dimensional programmer and get out of your box from
time to time.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Running Build Bots On Premise</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/running-build-bots-on-premise.html</link>
      <guid>https://justanotherdot.com/posts/running-build-bots-on-premise.html</guid>
      <pubDate>Sun, 22 Dec 2019 14:13:05 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Late November I did a <a href="https://www.youtube.com/watch?v=DL_hODqnUy0&amp;list=PLG8S6YrJRoYI3CIUqvGX4NBSaMWZxe9in">video
series</a>
discussing continuous integration and automation strategies for projects. I used
<a href="https://github.com/features/actions">GitHub Actions</a> as they aided me in
demonstrating configuration of pipelines without setting up supporting
infrastructure. If you are a developer making things having a fast response time
for feedback is crucial and continuous integration helps drastically.</p>
<p>When you use a SaaS offering for CI you are stuck using whatever tiers and
upgrades are on offer. For the last six months, however, I've not used a SaaS
offering for my infrastructure and instead have chosen to run computers in my
home. I use buildkite to pick my own infrastructure. I did the numbers for
renting my ideal EC2 instances on AWS and figured I could pay the same amount of
money to buy a machine or two to do my bidding that would still be relevant four
to five years later. Buildkite has an offering for an elastic stack build agent
that can scale to zero when idle but I the stack configuration was too bloated
to my liking. Nonetheless, having the ability to opt into whatever
infrastructure you please has some cool consequences and I doubt this will be my
last post on the subject!</p>
<p>Regardless of running compute locally or in the cloud, one can choose if they
want to pay the overhead of virtualization or let things build on bare metal,
which makes sense for slower machines. In the case of local compute this is a
&quot;true&quot; bare metal unless you are paying a cloud provider the money to not rent
in a co-tenant server. It does help to <em>build</em> things in a virtualized
environment with the excuse that it is a &quot;clean room&quot; but if you want to do a
compile check or run some tests you probably don't care about dirt.</p>
<p>Initially I bought three raspberry pis; two B+'s and one Zero. The intent was to
run docker on them but I had forgot the host needs to be the same architecture
as the image you intend to build on and I often use x86_64 images. There was
nothing stopping me from converting these little boxes to running the languages
directly for tests and basic checks. I have yet to see any architecture specific
failures with the languages I tend to build for. These agents don't produce
artifacts as I don't need ARM releases.</p>
<p>Later I took a box I use for streaming video, a <a href="https://everymac.com/systems/apple/mac_mini/specs/mac-mini-core-i7-2.7-mid-2011-specs.html">2011 Mac
mini</a>
I upgraded to 16GB of memory, and equipped it with a few buildkite agents and
docker. I have since reduced the box to running a sole agent. This build bot has
been the most frustrating because the box isn't only doing CI related things.
It's easy for docker to randomly die or get OOMed as the browsers can take up a
fair portion of CPU and memory when streaming video, often ~20-30% CPU load, and
it makes no sense for me to constrain the docker daemon unnecessarily.
Eventually I split configurations into two types: those that use docker or those
that don't.</p>
<p>I also own a rather beefy Intel ATX tower that sometimes participates as a build
bot. I recently dissected an older tower to contribute whatever parts I could
collect to build another ATX box for full-time builds to ease pressure off the
mac mini on release builds. No matter what the machine is, I try to use it do
any kind of automation, CI related or not. I was curious if anyone else was
crazed enough like me to do this. I poised a question on twitter a bit
indirectly:</p>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Those paid
professionally to code, how often do you dump money into buying
computers?</p>&mdash; Ryan James Spencer (@_justanotherdot) <a
href="https://twitter.com/_justanotherdot/status/1208218000626634753?ref_src=twsrc%5Etfw">December
21, 2019</a></blockquote> <script async
src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>My intent was to find out how often people buy various machines and actually put
them to use for purposes beyond what they use directly. I got several awesome
responses, primarily that often people buy new machines every 4-7yrs and, no,
this isn't really a common thing, at least for the people following me and keen
enough to have respond.</p>
<p>That said, a few cool machines were mentioned:</p>
<ul>
<li><a href="https://www.intel.com.au/content/www/au/en/products/boards-kits/nuc.html">NUC</a>
is a small form-factor device sold by Intel. There are equivalent ones
such as from <a href="https://system76.com/desktops/meerkat">System76</a> and if you care
about open firmware it's well worth supporting them!</li>
<li><a href="https://fit-iot.com/web/product/mintbox3-pro/">Mintbox3</a> -pro and -basic
both seem really cool and are
competitively priced in comparison to building your own machine. They are also
fanless if noise is a concern!</li>
<li>You wouldn't run this as a node in the cluster itself, but I had never heard
of the <a href="https://www.amazon.com.au/GPD-Portable-Ultrabook-Notebook-m3-8100Y/dp/B07W8MW2ZR">GDP portable
ultrabooks</a>
that seem like they'd be useful for quickly SSH'ing into a box without having
to carry around a full-sized laptop.</li>
</ul>
<p>Inevitably there are other computers I'd love to own &quot;just cus&quot;:</p>
<ul>
<li><a href="https://www.pine64.org/rockpro64/">Rockpro64</a> which Daniel Lemire
occasionally throw into his benchmarks</li>
<li><a href="https://www.sifive.com/boards/hifive-unleashed">Hi-Five unleashed</a></li>
<li><a href="https://system76.com/desktops/thelio-massive-b1/configure">System76 Thelio Massive</a></li>
</ul>
<p>You don't need a super computer to build and test software. Unless you are
looking for a laptop or need really bespoke hardware you can <em>generally</em> build a
desktop machine that'll run laps around most of its earlier variants. Building
your own also gives you a degree of customisation although, to be fair, it is
partly on par with cloud compute options: if you want to upgrade your file
system storage to a higher IOPS device, for example, you can abstractly do that
with a cloud provider, although you get a much finer degree of resolution with
your own computers.</p>
<p>Now that renting compute from cloud providers is commonplace, I suspect most
people would favor the ease of cattle-based systems administration and simply
slay any misbehaving servers. I find doing local systems administrations to be a
bit educational and cathartic in the sense of being a master of what you have
and working within limitations.</p>
<p>In terms of availability it's ok! There is always the risk that my children flip
a power switch or something goes wrong with my internet connection or power.
This sort of thing is already solved if you have, say, an AWS EC2 spot instance
in an autoscaling group where the terminating box will swiftly be replaced.
Because of this risk I occasionally supplement with cloud compute temporarily.</p>
<p>There are a few lingering things such as:</p>
<ol>
<li>
<p>External access into the specific network that has the bots. Something like
<a href="https://smith.st/">smith.st</a> and <a href="https://www.wireguard.com/">wireguard</a>
could supplant this if configured correctly. I remember seeing Brad
Fitzpatrick <a href="https://twitter.com/bradfitz/status/1206058552357355520?s=20">asking about ways to do a TLS based
termination</a>
into his home network awhile back.</p>
</li>
<li>
<p>Doing smarter things with scaling agents in and out as ewll as scaling to
zero, regardless of location. I had one crazy thought which was to have
agents scale out if local bots have pending work but haven't picked
anything up in X amount of time, say an hour tops. The newly spun up agent
could sit around for an hour attempting to pick up work and then kill
itself when idle, too.</p>
</li>
</ol>
<p>If you or someone you know runs local compute at home I'd love to get in touch
and see what usages are in practice out there. I'm always curious to see how
people are using on premise computing rather than switching entirely over to
cloud compute.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Patterns Of Knowledge Acquisition</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/patterns-for-knowledge-acquisition.html</link>
      <guid>https://justanotherdot.com/posts/patterns-for-knowledge-acquisition.html</guid>
      <pubDate>Thu, 12 Dec 2019 14:30:40 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Having written another <a href="https://www.justanotherdot.com/posts/reading-review-2019.html">yearly review of
reading</a> I have
been collecting thoughts around how I think about learning in general. Although
this list is horribly incomplete, I've identified a few core patterns I
tend to fall into when learning.</p>
<h2>Exposure</h2>
<p>In order to study something you need to know it exists. This stage of learning
consists of putting yourself into positions where you will best pick up new and
interesting ideas, words, and concepts without worrying about their finer
details.</p>
<p>Exposure is partly social and partly personal. People attend schools, go to
meetups, and join social media and forums. Other times they read blogs,
magazines, and book, watch videos, and listen to podcasts. The world is teeming
with sources of fresh content for us to discover and that is exactly the
problem; you can and will collect more information than you could imaginably
consume in your lifetime. This is why I won't spend too long discussing exposure
and will straight onto the next idea.</p>
<h2>Filtration</h2>
<p>Some quick <a href="https://www.justanotherdot.com/posts/fools-gold-time-estimates.html">back of the envelope
calculations</a>;
The &quot;average reader&quot; reads at a rate of 250 words per minute. The &quot;average page&quot;
is about 250 words which means the &quot;average reader&quot; ought to be able to consume
about a page per minute, assuming constant rate of reading. If you were a
perpetual motion machine and didn't need to eat or sleep, you could read 1440
pages in a day, which means 525,600 pages read in a year. The &quot;average book&quot; is
roughly 300 pages, which means approximately 1,752 books is the theoretical
upper limit for reading in a year at this non-stop, machine-like pace.</p>
<p>In reality we need to account for sleeping, eating, social activity, and general
motivation and energy. If you are lucky enough to dedicate 1-2 hours a day to
reading that means you could theoretically have an upper bound of 60 books
(calculating conservatively) per year.</p>
<p>This doesn't even take into account other media. Most adults, even without kids,
are lucky to have 1-2 hours in a work day to dedicate towards reading, watching
videos, or working on side-projects. Admittedly some people are night-owls and
may have higher-than-average time to dedicate to these endeavours, but skimping
on sleep is probably not the best idea.</p>
<p>If your definition of &quot;done&quot; for books, videos, and audio is only &quot;done&quot; if
every word is read, minute watched, and syllable heard then you are not reaching
for your potential for what you can learn. All information is composed of a
ratio of signal to noise. A one-hour video on fast fourier transforms with about
thirty minutes of anectdotes about the speakers' cats has a half ratio of signal
to noise. A book that has one message and spends the entirety repeating it to
draw out 300 pages is predominantly fluff. A riveting retelling of someone's
epic story of perseverance peppered with deep philosophical gems could largely
be signal.</p>
<p>You filter by applying a predicate to the material in question. People tend to
focus on what the predicate is but having processes for quickly trying things is
its own form of filter. Consuming a lot of material has helped me better
determine what I want to read and what I'd rather not spend my time on. If
you've read several books on leadership from a variety of popular authors, you
probably don't need to keep exploring every new title that comes out. If you are
passionately devoted to the collatz conjecture you might read every imaginable
piece of information you can find. Despite what passion you have, there is
always some level of diminishing returns.</p>
<p>It also helps to consider priorities. If you weren't going to wake up tomorrow,
what would you prefer to do? For me, studying, practice, and side projects go
down the ladder dramatically. I focus a lot more on being a better husband and
father. That said, it's just not possible for me to be in that mode all of the
time; my kids go to bed and my partner has things she wants to focus on so I
find myself with time to spend on the things that came lower in priority after
this practice.</p>
<h2>Redundancy</h2>
<p>Our brains are accustomed to freeing up space whenever possible so this is why
we must test ourselves on new knowledge until it finds it's way into
the more long-term storage we possess. You've opened up a lot of opportunities
and narrowed that list right back down to the things you want to spend time
with or know will truly help for you to work through. For myself, the best way
to help reinforce knowledge is through having multiple formats or even variants
on a concept or idea available for my perusal. If I've an interest I will
naturally keep picking things up, re-exploring particular articles, reading
certain things.</p>
<p>Going over material in multiple passes is a way to combine exposure, filtration,
<em>and</em> redundancy all in one go. The first few passes will store away the
top-level details, provide coarse definitions, and also help eliminate whole
sections that don't need examination. I will also own various formats for a
single title or groups of titles. Having an ebook is great when you're on the
go. Having a physical book is great for pacing and absorption when you're
relaxing at home. Having videos or audio can be played while working, or even
when reading is a bit too taxing (say after a very long day or week of work).</p>
<p>In my experience this last year my own framework consists of usually picking
books up as audiobooks first. If the top level view of the book is worth it,
I'll pick up the kindle and physical copies. With those I'll peruse various
specific chunks. When I noted that reading word-for-word is a barrier to your
learning potential, linearity is another such barrier, and redundancy helps
fight that all while providing retention. One of the reasons why testing
ourselves on knowledge works so well for retention is because it helps identify
the areas you are still unclear on.</p>
<h2>Applying This Framework</h2>
<p>Hopefully this has helped provide some insight into some principles that might
help with your own learning adventures or given some insight into how I look at
the problem of cramming knowledge into my head. I find I get a lot of value out
of making the exposure and filtration stages as fast as possible that by the
time I get to the redundancy stage it's much more high-signal-to-noise. It's far
more invigorating to work through material that is high signal <em>for you</em>.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>The Perils of Test Taxonomy</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/the-perils-of-test-taxonomy.html</link>
      <guid>https://justanotherdot.com/posts/the-perils-of-test-taxonomy.html</guid>
      <pubDate>Sun, 08 Dec 2019 14:53:57 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>You are wasting your time by classifying tests. Instead of discerning what
defines a test we'll hone in on tests to avoid. If a test is:</p>
<ul>
<li>slow</li>
<li>flaky</li>
<li>or subject to churn as new features are added</li>
</ul>
<p>then delete the offending test right now.</p>
<p>For testing to work your test suites can't be grounds for noise pollution. Nor
can they be a museum for specimens fit for dissection. Decide on what you want
to guarantee and work to achieve that guarantee <em>within contraint</em>. <strong>Tests
themselves are un-tested chunks of code.</strong> Tests that exhibit any of the
characteristics listed above lose local reasoning and are, therefore, hard for a
human to verify.</p>
<p>Slow and flaky tests mean you can't form a feedback loop with them. It means
people will stop running the test suites to drive development. I often will
chalk up work in CI for build bots to test and also test things locally at the
same time, racing the two to get feedback as soon as possible. Tags and simple
test names provide a handle to hone in on specific areas of functionality that
can be verified as new features are added. Fast tests also mean people will add
more tests and while a test <em>suite</em> might continue to increase in time needed to
finish, it is arguably a point to break test suites up into new test suites and,
possibly, separate libraries and programs that have their own test suites.
Decomposition shows its beautiful face once again.</p>
<p>A non-deterministic (i.e. flaky) test may seem to <em>sometimes</em> provide a
guarantee but the reality is much bleaker: a non-deterministic test tests
nothing. I am not talking about tests that fail because of the occasional
third-party service going down or network issue. I know you will be accordingly
<a href="https://xkcd.com/303/">play-fighting with swords</a> if that happens. What I am
referring to is the situation where tests are <em>known</em> to occasionally but the
reason is unclear. Is it configuration with a database? A third party library?
Some state setup or internals of the subject of the test? Flaky tests are white
noise. Devs start to ignore them and must waste time determining what is at
fault if they are to ascertain if the test failure is because of something they
should truly be concerned about or &quot;just because&quot;.</p>
<p>It is also a waste of time when a new feature is birthed into the system only to
lead a dev on a surgery process of fixing an array of tests that now fail. This
is distinct from intentional changes: a test might need fixing because you are
intentionally migrating away from some older behaviour into a new one and doing
so in-place. But tests should have isolation: bringing in new functionality
shouldn't <em>necessarily</em> mean overlap on older functionality and, therefore,
older tests.</p>
<p>It's helpful to delete tests and see if you would passionately defend against
their deletion in the process. If there is no passionate defense you will not
likely miss them when they are gone. A giant wall of tests is also a giant wall
of maintenance burden and there is only so much energy a group of persons can
apply to maintaining something they don't care about whatsoever.</p>
<p>Tests and types provide a degree of confidence, one that allows us to assuredly
tell others something is <em>more likely</em> to be correct, such that is to say it is
aligned with some specification or set of requirements. <strong>Lacing your codebase
with questions that can be quickly answered with a clear yes or no helps aid
confidence.</strong> Debating if something is <em>truly</em> a unit test or integration test
or whatever test is the equivalent of the art communities clich  of <em>&quot;but is it
art?&quot;</em>; humorous but not useful. Along with foundations such as quality release
and deployment engineering, operations, visibility into running systems, and so
forth, pushing things out to production becomes trivial with time. I obviously
and hand-waving away from the concern of scale here. Scale drastically impacts
trust and confidence, but many organisations are still paving a path forward and
charting new territory in this space to still make shipping code something sane.
Whatever you take from the above, the most important aspect about any kind of
testing is to make sure you are asking yourself one primary question when
writing tests: <a href="https://www.justanotherdot.com/posts/the-lowly-assert.html"><strong>What will you
assert?</strong></a></p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Reading Review 2019</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/reading-review-2019.html</link>
      <guid>https://justanotherdot.com/posts/reading-review-2019.html</guid>
      <pubDate>Tue, 03 Dec 2019 19:53:17 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>This year came up at roughly sixty books &quot;consumed&quot;. I've pared the list here
down to about forty. I say &quot;consumed&quot; because I decided to give audio books a
go so while I would normally read about thirty books I've managed to double
that amount by listening to things while I work.</p>
<p>Things of note:</p>
<ul>
<li>
<p>It may seem obvious (or not?) that there is a tremendous amount of noise out
there but I'd like to reiterate that there is ridiculous amount of fluff out
there in what we choose and are asked to read.</p>
</li>
<li>
<p>The best books were too complex and deep to truly grok in a single pass,
but still lucid enough to catch on core points in that first pass. I call
this quality &quot;replayability&quot;.</p>
</li>
<li>
<p>Because of the number of titles to put thoughts against here I've opted to
describe from what I remember as quickly as possible and either be direct
about truly loving the book or not.</p>
</li>
<li>
<p>The worst books were shallow and forgettable.</p>
</li>
<li>
<p>Overcoming the discomfort of skimming and skipping through books has had a
remarkable impact on helping me tackle material I'm requested to ingest.</p>
</li>
<li>
<p>I found a lot of value in taking notes during or after reading. I heard
once that spending a brief period (specifically thirty seconds, but that
feels <em>too</em> short) of time to summarize recently received information, no
matter how complex, drastically improves retention.</p>
</li>
<li>
<p>When I found a book truly worth its weight, I would buy a physical copy to
review sections.</p>
</li>
<li>
<p>Of notable mention are Naval Ravikant's tweet storm and podcasts on <a href="https://twitter.com/naval/status/1002103360646823936?lang=en">How to Get
Rich (without getting lucky)</a>.</p>
</li>
<li>
<p>Two particularly inspiring non-technical blog posts were <a href="https://jsomers.net/blog/speed-matters">Speed
Matters</a> and <a href="https://jsomers.net/blog/more-people-should-write">More People Should
Write</a>. I also felt a
kinship for Alexis King's process described in <a href="https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/">Parse, Don't
Validate</a>.</p>
</li>
<li>
<p>I found it useful to read contrarian takes on subjects so that I'm not stuck
in my own bubble of thought.</p>
</li>
</ul>
<p>Onto some short blurbs on what I've read. These are no replacements for properly
reading the texts, but they may give you an idea of some core concepts and
provide some interest for diving into some (or avoiding others). As noted, some
descriptions may be shallow because the text in question is either too deep or
too shallow. I may do a top pick article to help clarify in the future.</p>
<hr />
<h5><a href="https://www.goodreads.com/book/show/38502098-a-people-s-history-of-computing-in-the-united-states">A People's History of Computing In The United States</a></h5>
<p>A fabulous recount about the history of time sharing computing systems in the
united states. I found the exploration of the social and economic contexts of
how these large-scale systems rose up fascinating. Easily goes in the
collection of great narrative historical stories of computing along with Soul
of a New Machine.</p>
<h5><a href="https://www.goodreads.com/book/show/48518642-unix">Unix: A History and a Memoir</a></h5>
<p>For the *nix fans out there this is a wonderful telling of the people involved
in the makings of Unix at Bell Labs. Brian Kernighan has written several books
that are always fun to get through: The Awk Programming Language, The C
Programming Language, The Go Programming Language, and so on. Learning that
Ken Thompson wrote the prototype of what would become Unix in three weeks
absolutely blew my mind.</p>
<h5><a href="https://www.goodreads.com/book/show/7776209-the-rational-optimist">The Rational Optimist</a></h5>
<p>The thesis of this book is that although things seem bleak in our current
state of human affairs, especially in regards to the knock-on effects of
capitalism, the degradation of the environment, and rampant political
fracturing, we are actually in a far better place than we were before now.
Ridley proposes that bartering is what makes us distinct from other animals
and that our ability to form markets and labour has allowed us to accelerate
advancement of our day-to-day lives.</p>
<h5><a href="https://www.goodreads.com/book/show/28815.Influence">Influence: The Psychology of Persuasion</a></h5>
<p>There's about six-ish things that Caildini focuses on as pillars of influence
on humans. By taking various roles and exploring each concept in relation to
the presumed job, Caildini explores things like scarcity, consistency,
attractiveness, providing reasons to requests, etc. Caldaini's original
framing of the book was to help provide tips so people could better understand
how to combat the effects of influence but it seems like it has become a
reference as a means of understanding a subset of persuasion on others.</p>
<h5><a href="https://www.goodreads.com/book/show/50221.God_s_Debris?from_search=true&amp;qid=4zOFwRZO5W&amp;rank=1">God's Debris: A Thought Experiment</a></h5>
<p>Thought experiment where a parcel carrier has a series of discussions with
God. Deep (and quick) enough for a read.</p>
<h5><a href="https://www.goodreads.com/book/show/40983156-platform?from_search=true&amp;qid=LAkkm07sMX&amp;rank=1">Platform: The Art and Science of Personal Branding </a></h5>
<p>Johnson's argument is that you are only truly an expert in a field if you hold
a reputation for it. A reputation is only built by putting work into gaining
an audience (platform). She outlines several ideas and approaches for doing
this digitally.</p>
<h5><a href="https://www.goodreads.com/book/show/11346463-beyond-religion?from_search=true&amp;qid=jheoqrhh92&amp;rank=1">Beyond Religion: Ethics for a Whole World</a></h5>
<p>The Dalai Lama examines various topics of life from a consciously secular
standpoint.</p>
<h5><a href="https://www.goodreads.com/book/show/35239798-the-courage-to-be-disliked?from_search=true&amp;qid=jmj2ZmFqaG&amp;rank=2">The Courage To Be Disliked</a></h5>
<p>A discourse about Adlerian psychology expressed as a young-man/old-man
dialogue which is trite. I found the various concepts (especially that of
people inventing their dramas) to be particularly intriguing. In the story
they explore the concept that other people have desires that they expect of us
but we ought to ignore them and instead focus on our freedom to react to
events however we truly prefer.</p>
<h5><a href="https://www.goodreads.com/book/show/641604.Purple_Cow?from_search=true&amp;qid=o7w51MStqc&amp;rank=1">Purple Cow: Transform Your Business by Being Remarkable</a></h5>
<p>Remarkable things sell. If you don't have a remarkable thing, you ought to
find one to sell. If you have a remarkable thing, don't pretend the effect
will last forever.</p>
<h5><a href="https://www.goodreads.com/book/show/13593553-to-sell-is-human?from_search=true&amp;qid=lr2xkw3ANr&amp;rank=1">To Sell Is Human: The Surprising Truth About Moving Others</a></h5>
<p>No matter your career selling is a part of it. You must convince people with
resources to part with them, usually in exchange for something else. This
thesis is not dissimilar from The Rational Optimist.</p>
<h5><a href="https://www.goodreads.com/book/show/34623128-the-autobiography-of-gucci-mane?from_search=true&amp;qid=urDgzb1Wai&amp;rank=1">The Autobiography of Gucci Mane</a></h5>
<p>This was highly ranked in recommendations for marketing but I'm not sure why.
Gucci Mane explains his upbringing, his entry into rap, the continual
inclusion of criminal activity and drugs (especially 'lean'), all while
achieving stellar success. The book finishes with him being fully incarcerated
and going through a period of withdrawal where he realizes he wants to
properly abandon drugs and turn his life around.</p>
<h5><a href="https://www.goodreads.com/book/show/773858.Born_Standing_Up?from_search=true&amp;qid=llM4Y5MV2a&amp;rank=1">Born Standing Up: A Comic's Life</a></h5>
<p>Incredible autobiography about Steve Martin's adventure through standup and
eventual explosion of fame (and his disgust of it thanks to his
dissatisfaction of the isolation it caused). It's interesting to note his
exploration of his standup style and career as a serious business endeavour
rather than coming off as part of his 'art'.</p>
<h5><a href="https://www.goodreads.com/book/show/31625067-hacking-growth?from_search=true&amp;qid=UGo93qIfEu&amp;rank=1">Hacking Growth: How Today's Fastest-Growing Companies Drive Breakout Success</a></h5>
<p>A cut-and-dry prescription approach to &quot;growth hacking&quot; and the book that
claims to have been authored by its inventors. Business intelligence is
definitely far older. and I wound up finding the book a chore to get through.</p>
<h5><a href="https://www.goodreads.com/book/show/47883410-the-mom-test?from_search=true&amp;qid=qeUkkrkDUz&amp;rank=1">The Mom Test: How to talk to customers &amp; learn if your business is a good idea when everyone is lying to you</a></h5>
<p>People will lie to you to feel good about themselves when asked questions
about your product. Your Mom does the same when you ask her, too. Your goal is
to get past the fanciful future uses that people love to labour on about and
focus on the actual pain they've experienced when dealing with a particular
problem or competitors product. You want to know how you can help ail these
pain points.</p>
<h5><a href="https://www.goodreads.com/book/show/40549476-this-is-marketing?from_search=true&amp;qid=P2VSbnc6yx&amp;rank=1">This is Marketing: You Can't Be Seen Until You Learn To See</a></h5>
<p>Godin argues that marketing is actually good for us; marketing directs us to
products that change our lives for the (arguably) better position and helps
normalize this behaviour.</p>
<h5><a href="https://www.goodreads.com/book/show/23848190-extreme-ownership?from_search=true&amp;qid=9p68jMJuxQ&amp;rank=1">Extreme Ownership: How U.S. Navy SEALs Lead and Win</a></h5>
<p>If you have direct reports and they fail, it's always back on you to teach
them (unless they truly are inept). It's a long book with many drawn-out
combat stories filling in the bulk.</p>
<h5><a href="https://www.goodreads.com/book/show/26156469-never-split-the-difference?from_search=true&amp;qid=gCfmxLBGid&amp;rank=1">Never Split the Difference: Negotiating As If Your Life Depended On It</a></h5>
<p>Many fantastic tidbits of negotiation techniques. Some of these are drawn from
other sources but it's how Voss connects the concepts to practical usage I
found particularly helpful.</p>
<h5><a href="https://www.goodreads.com/book/show/18077875-essentialism?from_search=true&amp;qid=kGC6L4RhhR&amp;rank=3">Essentialism: The Disciplined Pursuit of Less</a></h5>
<p>Lots of great little points on the &quot;less is more&quot; rhetoric.</p>
<h5><a href="https://www.goodreads.com/book/show/11878168-anything-you-want?from_search=true&amp;qid=IsDZruDbD6&amp;rank=1">Anything You Want</a></h5>
<p>Tells the story of Darek Sivers, the fella who unintentionally built CDBaby
and eventually sold the company at $12m. This was quick and had lots of great
point, like the higher leverage obtained by keeping teams small.</p>
<h5><a href="https://www.goodreads.com/book/show/34536488-principles?from_search=true&amp;qid=Sa02e6suZb&amp;rank=1">Principles: Life and Work</a></h5>
<p>Divided into two sections, principles discusses life and work principles, the
latter being far larger but the former being the most applicable for the
general public in my opinion. You can watch and read most of his material
without buying his book online as his emphasis isn't making money off the book
but sharing his knowledge (or so he claims). I've found it to be a fantastic
trove of knowledge that seems to come up in several other books I've read
without being Yet Another Business or Self-Help book and without being Get
Rich Quick themed.</p>
<h5><a href="https://www.goodreads.com/book/show/242472.The_Black_Swan?ac=1&amp;from_search=true&amp;qid=eH8HC2oJoi&amp;rank=1">The Black Swan: The Impact of the Highly Improbable </a></h5>
<p>I did not know about Nassim Taleb until this year when a mentor of mine
mentioned he was also reading him. Taleb, a former quantitative analyst,
explores the concept of the Black Swan, a highly improbable, but not
impossible, event, under the auspices that any attempt to claim that
predictions are rock-solid is a farce. The classic example he gives early in
the book is about a turkey who seems to be living the grand life, only to be
later killed (the black swan event). One connected idea I found particularly
intriguing is that of randomness being really about the observer of the random
variable: the turkey may not know about the black swan event but the farmer
who owns the turkey knows about this date for month.</p>
<h5><a href="https://www.goodreads.com/book/show/33517721-the-culture-code?from_search=true&amp;qid=jLO3Cob5xd&amp;rank=1">The Culture Code: The Secrets of Highly Successful Groups </a></h5>
<p>People are productive when they feel safe and, therefore, can be vulnerable.
They are also more creative and innovative. This is fundamentally Maslow's
hierarchy of needs but he also discusses the emphasis of sharing goals in
tandem with sharing vulnerability. One of the better books outlining why you
want to structure a business culture with these characteristics.</p>
<h5><a href="https://www.goodreads.com/book/show/6732019-rework?from_search=true&amp;qid=lERy4jotVP&amp;rank=1">Rework</a></h5>
<p>Your work isn't everything and ought not to control you. A well-rested and
clear-headed employee stays longer at a company and is wildly more productive
than the run-down equivalent. I liked the idea of &quot;JOMO&quot; (Joy of Missing Out)
being pushed in comparison to the usual sense of &quot;FOMO&quot; people experience. I
usually like Jason Fried and DHH books because they are full of lots
&quot;common-sense&quot; knowledge that are still helpful to be reminded of.</p>
<h5><a href="https://www.goodreads.com/book/show/25817524-alibaba?ac=1&amp;from_search=true&amp;qid=498oXbPB8f&amp;rank=1">Alibaba: The House That Jack Ma Built</a></h5>
<p>A rather bland telling of Jack Ma's growing of his various business interests
and, later, Alibaba. His translation work and early interest in the internet
helped eventually leading to his starting of Alibaba. There were many
&quot;everything store&quot; styled shops and Jack's early translation company did far
more than translation services, selling whatever they could.</p>
<h5><a href="https://www.goodreads.com/book/show/35167685-surely-you-re-joking-mr-feynman?ac=1&amp;from_search=true&amp;qid=F94Xrq62EN&amp;rank=1">&quot;Surely You're Joking, Mr. Feynman!&quot;: Adventures of a Curious Character</a></h5>
<p>Feynman is a mixed bag. He is quick witted and smart but is also a creep. His
autobiography paints a picture of a happy-go-lucky, curious-minded,
exploration-driven individual who loves to prank, be a smart alec, and isn't
shy to discuss his interest in women as well as visitations to strip clubs
where he would draw the strippers and work on physics problems. That said, it
is interesting to look at how Feynman is always deducing from other facts or
principles which you can see in the way the text is written (also notable in
his lectures).</p>
<h5><a href="https://www.goodreads.com/book/show/42734244-no-hard-feelings?from_search=true&amp;qid=qFp7eARyCT&amp;rank=10">No Hard Feelings: The Secret Power of Embracing Emotions at Work</a></h5>
<p>An exploration into how to accept that emotions are always apart of our lives
and decisions, including at work, and how to use that knowledge to best
effect. Also a good reminder that our work is not everything.</p>
<h5><a href="https://www.goodreads.com/book/show/687278.When_Things_Fall_Apart?ac=1&amp;from_search=true&amp;qid=w15Uw6ZCvZ&amp;rank=1">When Things Fall Apart: Heart Advice for Difficult Times</a></h5>
<p>A discussion from a Buddhist monk about how chaos is inevitable and how we
must, no matter how stable we think life is, continually invite &quot;chaos in with
a cup of tea&quot; if we are truly to handle what life has to throw at us.</p>
<h5><a href="https://www.goodreads.com/book/show/16158601-turn-the-ship-around?ac=1&amp;from_search=true&amp;qid=okBtnacd7S&amp;rank=1">Turn the Ship Around!: A True Story of Turning Followers into Leaders</a></h5>
<p>A naval captain tells how he managed to change from a top-down organisational
structure into something with more autonomy amongst the ranks, helping turn
one of the worst ranked teams into one of the best. The &quot;I intend to&quot; language
is gold, alone, but there are other techniques explained throughout the book
as it covers the discovery of these in relation to particular organisational
problems they were facing. For example, to deal with better handling
operational concerns on the submarine, they begin practicing deliberate action
where they vocalise what they are about to do, gesture at the subject that
will be acted upon, and, after a short pause, perform the task.</p>
<h5><a href="https://www.goodreads.com/book/show/44770129-ultralearning?from_search=true&amp;qid=6FlLLX6FpL&amp;rank=1">Ultralearning: Master Hard Skills, Outsmart the Competition, and Accelerate Your Career</a></h5>
<p>Discusses a form of learning where progress and speed are the focus;
compressing learning into short bursts at a time to positive effect. I have
mixed feelings about this book after having come out of therapy this last year
because I am into this processes but I felt the emphasis of an always-on
approach isn't healthy for long-term learning as well as general psychological
health.</p>
<h5><a href="https://www.goodreads.com/book/show/29513878-inner-engineering?ac=1&amp;from_search=true&amp;qid=7psLjNmm1N&amp;rank=1">Inner Engineering: A Yogi's Guide to Joy</a></h5>
<p>Particularly memorable parts of the book include reminding oneself of their
mortality to help prioritise what truly matters and that taking responsibility
is about taking charge of our ability to respond to life and events around us.</p>
<h5><a href="https://www.goodreads.com/book/show/40121378-atomic-habits?ac=1&amp;from_search=true&amp;qid=579XxYAfHC&amp;rank=1">Atomic Habits: An Easy &amp; Proven Way to Build Good Habits &amp; Break Bad Ones</a></h5>
<p>Although nothing <em>new</em> is prescribed here, I applaud Clear with compiling a
simple compendium of core concepts that fuel habit formation. All the
worksheets and activities I ignore but the four points are well worth the
extra bit of reading to cement the ideas.</p>
<h5><a href="https://www.goodreads.com/book/show/71730.Nonviolent_Communication?ac=1&amp;from_search=true&amp;qid=Ai25kkFMVC&amp;rank=1">Nonviolent Communication: A Language of Life </a></h5>
<p>This one is considered a classic in that it is commonly referenced as being a
big part of negotiation and interpersonal relationships discourse.
Rosenberg's foundations are that failure to recognise needs, of our own and
of others, is the crux of interpersonal conflict.</p>
<h5><a href="https://www.goodreads.com/book/show/187633.Art_and_Fear?from_search=true&amp;qid=SLSNWiUVy3&amp;rank=1">Art and Fear: Observations on the Perils (and Rewards) of Artmaking</a></h5>
<p>This one is great as it applies to areas of work outside of creating artwork.
I found this incredibly useful in terms of recognising that quantity is much
more valuable for the effort of learning (experimentation) than is focusing on
quality upfront. Other people's magic is not your own so don't go attempting
to copy in hopes that you'll achieve the same results. In the same train of
thought, only compare your development to your own history.</p>
<h5><a href="https://www.goodreads.com/book/show/34466963-why-we-sleep">Why We Sleep: Unlocking the Power of Sleep and Dreams</a></h5>
<p>Most of us know sleep deprivation is problematic but this book goes deeper in
how debilitating it can truly be, as well as how little sleep deprivation is
required before achieving ill effects.</p>
<h5><a href="https://www.goodreads.com/book/show/41795733-range?ac=1&amp;from_search=true&amp;qid=MgKQ7yawGG&amp;rank=3">Range: Why Generalists Triumph in a Specialized World</a></h5>
<p>Being an expert usually is less effective than being a jack of all trades.
Why? Because experts go down deep holes that start to lose innovation as they
make less and less cross-disciplinary connections.</p>
<h5><a href="https://www.goodreads.com/book/show/13588356-daring-greatly?from_search=true&amp;qid=DdogRhA3wb&amp;rank=3">Daring Greatly: How the Courage to Be Vulnerable Transforms the Way We Live, Love, Parent, and Lead</a></h5>
<p>Being courageous means sharing. We tend to think its the other way; that
sharing <em>takes</em> courage, but in reality if you share, you are being
courageous. Brown calls sharing so much information that your intent is to
manipulate others &quot;oversharing&quot;.</p>
<h5><a href="https://www.goodreads.com/book/show/17859574-how-to-fail-at-almost-everything-and-still-win-big?from_search=true&amp;qid=3TboDOwJdp&amp;rank=1">How to Fail at Almost Everything and Still Win Big: Kind of the Story of My Life</a></h5>
<p>Systems over goals. Energy drives success which drives passion, not the other
way around. A varied collection of ideas and memoirs of how Scott Adams built
various aspects of his career and had lots of little failures testing out
ideas and going through a life as a cubicle jockey.</p>
<h5><a href="https://www.goodreads.com/book/show/40796176-infinite-powers?from_search=true&amp;qid=lZHrEo7PEB&amp;rank=1">Infinite Powers: How Calculus Reveals the Secrets of the Universe</a></h5>
<p>Absolutely wonderful exploration of the history and internals of calculus.
Strogatz is the author of Sync, Non-linear Dynamics and Chaos, The Joy of X,
and others. He has a knack for breathing life into mathematical subjects. I
found his historical bits just as exciting as exciting as the clarity of his
explanations for the inner workings of calculus.</p>
<h5><a href="http://www.101thingsilearned.com/">101 things I learned from (urban planning|architecture|advertising|engineering) school</a></h5>
<p>I have several of these '101 things' books. They are a breeze to get through
(some of the points are just quotes, or usually short blurbs, less than two,
on average about one, paragraphs each) and often about 2-4% of those points
are absolute gold. One that is off the top of my head from recently finishing
the advertising version of the series is the notion that you should emphasis
getting your message across as many people as possible if it applies to a
broad reach (say, toilet paper) while a specific niche demographic is best hit
with higher frequency.</p>
<h5><a href="http://fabiensanglard.net/gebbdoom/">Game Engine Blackbook (Wolf 3D|DOOM)</a></h5>
<p>These are fabulous books and if you have any nostalgia for the games they
cover whatsoever, and you program, you should pick them up without a moments
hesitation. They cover a portion of history regarding product development,
hardware, and follow naturally into solid analysis of the internal tech of the
rendering and game engines.</p>
<h5><a href="https://www.goodreads.com/book/show/51291.How_to_Lie_with_Statistics?from_search=true&amp;qid=5RNxdWm9Ro&amp;rank=1">How To Lie With Statistics</a></h5>
<p>This is a truly dated book that has an odd style of speech that rambles at
great length so it can require some serious concentration to get at the core
of what he is driving at for most chapters. It is also exceptionally light so
not much is lost attempting to get through it, I suppose. The main theme of
the book is where people, organisations, teams, researchers, surveyors, and so
on, manipulate and confuse statistical data.</p>
<h5><a href="https://www.goodreads.com/book/show/28815322-the-danish-way-of-parenting?ac=1&amp;from_search=true&amp;qid=ZtM8X1oDqS&amp;rank=1">The Danish Way of Parenting: What the Happiest People in the World Know About Raising Confident, Capable Kids</a></h5>
<p>Nothing exceptional here that a quick glance through the headlines and a few
paragraphs wouldn't suffice with.</p>
<h5><a href="https://www.goodreads.com/book/show/23418.The_Architecture_of_Happiness?ac=1&amp;from_search=true&amp;qid=gcTS4eEKxc&amp;rank=1">The Architecture of Happiness</a></h5>
<p>This was one I read a bit more slowly than the rest. Alain De Boton is an
intriguing author in how he explores a myriad of different topics in truly
unique ways. I had previously read his book on Proust and how someone so bed
ridden could write so well about human pyschology. In this text he explores
how we tend to look at buildings aesthetically and jabs at modernist notions
of functionality and science being at the core of architecture. It inspired me
so much to write <a href="https://www.justanotherdot.com/posts/make-a-home.html">Make a
Home</a> which is still
one of my favourite articles.</p>
<h5><a href="https://www.goodreads.com/book/show/43726517-hello-world?ac=1&amp;from_search=true&amp;qid=0SNAVOVt36&amp;rank=1">Hello World: Being Human in the Age of Algorithms</a></h5>
<p>Fry explores how machine learning amplifies our biases. She argues that we can
actively expose and rectify these biases and use machine learning to
supplement human judgement rather than replacing it entirely.</p>
<h5><a href="https://www.goodreads.com/book/show/32919530-a-mind-at-play?ac=1&amp;from_search=true&amp;qid=k64DMsqzeg&amp;rank=1">A Mind at Play: How Claude Shannon Invented the Information Age</a></h5>
<p>I liked learning about Claude Shannon but this was tricky to get through as
the writing was a bit bland. Claude is the founding father of information
theory (the notion that different forms of data can be expressed with binary
data). Shannon worked at Bell Labs for a good portion of his life, liked to
juggle, ride a unicycle, and do mathematical puzzles. Apparently he had a
knack for statistics and probability, too, to the point which he obsessively
analysed gambling odds for roulette and had a knack for markets and building
precursory computing machines.</p>
<h5><a href="https://www.goodreads.com/book/show/44647144-database-internals?ac=1&amp;from_search=true&amp;qid=yB3M5IE3Og&amp;rank=1">Database Internals: A deep-dive into how distributed data systems work</a></h5>
<p>Technical books are hard to review because what may work for one person may
not work for another. Sometimes you need something as a heavy reference that
you'll be rifling through often and without any clear ordering, and other
times you may be looking for exactly a tutorial that starts and ends with a
clear path (like a university course). &quot;Database Internals&quot; has a <em>lot</em> of
knowledge <em>and</em> concise explanations of database concepts so it straddles the
line between reference book and tutorial, but in a way I think is appealing to
more voracious students on the subject. If you're looking for a simpler
explanation of internals of databases with less meat or details there is the
<a href="https://www.youtube.com/channel/UCHnBsf2rH-K7pn09rb3qvkA/playlists">CMU Database
course</a></p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>A Release Does Not Make a Deploy</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/a-release-does-not-make-a-deploy.html</link>
      <guid>https://justanotherdot.com/posts/a-release-does-not-make-a-deploy.html</guid>
      <pubDate>Sun, 24 Nov 2019 19:21:53 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Is the vision in your head of your pipelines that of lean, graceful atheletes?
Do branch builds simply test your changes swiftly and anything that hits master
builds artifacts finished with the flourish of a ephemeral &quot;deployment&quot;?</p>
<p>Your pipelines are overweight slobs, unwilling to truly do real work.</p>
<p>Conventional wisdom dictates that deployments occur at the ends of pipelines by
running a simple task, say <code>kubectl apply</code> or similar, with the produced
artifact mentioned. This act is transient and for many pipelines means rolling
back is an act of rerunning the whole pipeline, an individual step in the
pipeline, or even reverse-engineering the action in the deployment step and
performing it manually, given the level of desperation.</p>
<p><strong>Build artifacts aren't deployments.</strong> By turning deployments from &quot;transient
action&quot; into their own artifact you can scrobble across deployments with little
fuss. A deployment artifact can be anything that describes the act of deploying.
This might be a script, a set of versions packaged together, or even a
specification like a kubernetes manifest. <strong>Once you have release artifacts <em>and</em>
deployment artifacts start the exercise regime for your pipelines by building
and publishing all the things</strong>.</p>
<p>Won't all this extra work cost more money and time? The reality is that
amortizing the cost of storing your artifacts and building whenever you get a
chance helps provide options so you don't have to do extra work when it is the
most untimely to do so. What costs more? Having a terrible
mean-time-to-resolution (MTRR) and frequent outages or paying for more build
bots and storage space? If you haven't learned the cost of burning the trust of
your end users, then you have an important lesson to learn.</p>
<p>Scrobbling deployments not only helps reduce the blast radius of botched code
hitting the pool of production by increasing your MTRR but it also gives you the
opportunity for functionality such as preview deployments. Some approaches may
provide previews in different deployment environments entirely whereas others
allow service or resource &quot;naming&quot; (e.g. unique URLs or distinct IP addresses)
to route traffic accordingly. Some blend the two together. This last approach is
often how services such as <a href="https://zeit.co/">zeit</a> and
<a href="https://linc.sh/">linc.sh</a> do their previews for branch builds. It depends on
how much reproducibility you care about to get a sanity check before deploying
to production.</p>
<p>The one wrench in all of this is the matter of shared state; sometimes the
complication of going backwards or forwards from a certain deployment involves
running or reversing migrations, reinstating or removing coupled infrastructural
changes, or even having third party services paid and available. There are
islands of deployments that may become totally inaccessible due to the above and
the best advice I can provide in the briefest period of time is that all of
these can be (somewhat) circumvented by ensuring nothing exists that isn't code.
To address the noted issues (which is incomplete, mind you):</p>
<ul>
<li>Having a process that ensures all migratory actions on a database are verified
to revert properly and that snapshots are regularly taken at frequent
intervals</li>
<li>All infrastructure is code so rolling back infrastructural changes isn't a
matter of someone GUI-poking or frantically performing manual changes</li>
<li>Providing configuration and testing that ensures a system behaves as it needs
to behave without the reliance on third-party software and services</li>
</ul>
<p><strong><a href="https://charity.wtf/2019/10/28/deploys-its-not-actually-about-fridays/">Fear not the Friday
deploy</a>
when you have options at hand; fear the duct-tape and popsicle-stick
infrastructure that makes Friday deploys a nightmare.</strong></p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>The Simplest Programming Language I Know</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/the-simplest-programming-language-i-know.html</link>
      <guid>https://justanotherdot.com/posts/the-simplest-programming-language-i-know.html</guid>
      <pubDate>Wed, 20 Nov 2019 20:35:16 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>I'm going to teach you the simplest programming language I know.</p>
<p>Everything starts with functions:</p>
<pre><code>(\x -&gt; x)
</code></pre>
<p><code>x</code> is the input argument. There may be more than one by adding comma separated
values, e.g. <code>x, y, z</code>, and so on. The body comes after the arrow (<code>-&gt;</code>).</p>
<p><code>x</code> is a variable. We can call functions like this:</p>
<pre><code>(\x -&gt; x) 3
</code></pre>
<p>This says &quot;substitute the value of <code>3</code> everywhere you see <code>x</code> in the body of the
function&quot;, like this:</p>
<pre><code>1. (\x -&gt; x) 3
2. (\x = 3 -&gt; x)
3. (3)
4. 3
</code></pre>
<p>Here's another example with more than one argument:</p>
<pre><code>1. (\x, y -&gt; x + y) 3 4
2. (\x = 3, y = 4 -&gt; x + y)
3. (3 + 4)
4. 7
</code></pre>
<p>Calling a function is called &quot;function application&quot; and when all arguments are
substituted with actual value we are left with the result. When we assign values
to variable names we call it &quot;binding&quot;:</p>
<pre><code>1. f = (\x -&gt; x)
2. f 3
3. 3
</code></pre>
<p>Sometimes when we talk about function application. It can be bit-by-bit:</p>
<pre><code>1. (\x, y -&gt; x + y) 3 4
2. (\x = 3, y -&gt; x + y) 4
3. (\y -&gt; 3 + y) 4
4. (\y = 4 -&gt; 3 + y) 4
5. (3 + 4)
6. 7
</code></pre>
<p>Functions are values. We call the above &quot;partial application&quot; because we get
functions back when we apply one argument at a time. This format for function
application is called &quot;currying&quot; where a function takes one argument at a time.</p>
<p>This programming language has many types but has no way to check this before
running the program. Hence we can wind up with weird expressions such as adding
the number <code>3</code> and <code>true</code> together. This programming language is called the
<a href="https://en.wikipedia.org/wiki/Lambda_calculus">&quot;lambda calculus&quot;</a> and when you
add a basic form of types you get the <a href="https://en.wikipedia.org/wiki/Simply_typed_lambda_calculus">&quot;simply typed lambda
calculus&quot;</a>.</p>
<p>And now you know one basis of functional programming and a model of computation.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Habit: A Tale of Two Water Bottles</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/habit-a-tale-of-two-water-bottles.html</link>
      <guid>https://justanotherdot.com/posts/habit-a-tale-of-two-water-bottles.html</guid>
      <pubDate>Mon, 18 Nov 2019 19:48:12 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>I've the same one-litre water bottle at work as I do at home. I always drink
water at work, and I usually drink about 2L a day. When I work from home,
however, I barely hydrate.</p>
<p><a href="https://www.goodreads.com/book/show/40121378-atomic-habits">Atomic Habit</a> has
four basic rules stipulated for habit formation.</p>
<ol>
<li>Make it obvious</li>
<li>Make it attractive</li>
<li>Make it easy</li>
<li>Make it satisfying</li>
</ol>
<p>If you want to kick a habit, you reverse each of these four rules.</p>
<p>Access can affect ease, but easiness isn't just access. Before I owned a
camelback I had twist-lid water bottle. This isn't as easy as the standard
camelback because you always have to unscrew the lid if you want to take a swig.</p>
<p>At home, my water bottle is endlessly lifted by the resident little people. When
I do find my water bottle, it tends to be a greasy, dirty mess. Camelback came
out with these new plastic valves and my children have happened to chew them to
plastic mush. Whenever I get a chance to drink water, it is room temperature or
warmer.</p>
<p>Contrast this to my water bottle at work: it is always at my desk or near my
person, it is appealing because I don't have to use any cups and interact with
the dishwasher. It's also nice I don't have to contribute to the washing. It is
satisfying because I can always fill the bottle with refreshing, cold water from
the zip tap.</p>
<p>I see attractiveness about prospective satisfaction versus enjoyment during the
process, but you could also argue fuzziness about the terms &quot;obvious&quot; and &quot;easy&quot;.
Despite what you may think about the book, these principles are helpful at
forming habits (and breaking bad ones) and I've tried to apply them to other
things in my life.</p>
<p>I read a lot. I've <a href="https://www.justanotherdot.com/posts/pushing-the-boulder.html">talked
before</a> about
some formats I use for reading. I've learned to overcome the discomfort of not
reading all books from cover-to-cover, but I still enjoy reading front-to-back
with certain titles.</p>
<p>A clear, plastic chair is positioned next the shoe cupboard near the shower
room. I sit there when my kids shower before they are put to bed. The shoe
cupboard has a stack of Communications of the ACM magazines on its top. It was a
straightforward habit to form: attractive (reading always is for me), satisfying
(they are written on subjects I like reading), easy (it's a part of my daily
routine), and obvious (the top of the cupboard is only a little below shoulder
height. That ticks all four principles of habit formation.</p>
<p>Within time I found other places to put books. A fresh collection of paperbacks
arrived last month along with a title I haven't finished. &quot;DOOM&quot; by Fabien
Sanglaard went to the nook where my keys, wallet, and similar live. &quot;Unix: A
History and a Memoire&quot; by Brian Kernighan went next to mantle in the living
room. &quot;How to Lie with Statistics&quot; sits near the clear chair next to the shoe
cupboard. I am similar to <a href="https://www.youtube.com/watch?v=3qHkcs3kG44">Naval
Ravikant</a> in that I enjoy exploring
several books simultaneously. Progress is now far easier to make on each of
these books in tandem. Having progress on several different titles let's me
connect disparate ideas and sometimes certain titles discuss different sides of
an argument.</p>
<p>Habit formation has high practicality because its range of application is high.
A modern opinion is that we don't even build products for people to rationally
consume; heavy habit forming interfaces are more likely to be the products that
&quot;delight users&quot;.</p>
<p>Part of this leads back into code. People sometimes refer to the &quot;pit of
despair&quot; as the state where an ecosystem or user interface leads people to do
the wrong thing. The &quot;pit of the success&quot; is the facetiously named inverse of
the effect; doing the right thing is trivial. Not only are user interfaces and
ecosystems prime examples of habit formation for their end users, but the
processes used in how they are built are subject to habit formation, too. <strong>Want
you or your team to code or operate in a particular manner? Make it addictive.</strong>
And please, don't try to manipulate others into every imaginable whim. The
autonomy of people is their most valuable asset to a technical team.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Teleporting At The Speed Of Thought</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/teleporting-at-the-speed-of-thought.html</link>
      <guid>https://justanotherdot.com/posts/teleporting-at-the-speed-of-thought.html</guid>
      <pubDate>Fri, 15 Nov 2019 19:25:52 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Adept text editor users fly around and manipulate text as if by <em>teleportation</em>.
For me, this is a principle I hold dear when considering my editing experience.
<strong>Teleportation is chiefly driven by thought and is effortless by
construction</strong>. This is actually not something inherent to teleportaiton.
Instead of hopping in a car and driving around the neighbourhood to find where
you want to go, you tend to make a decision about your destination ahead of
time. However, driving expects a certain amount of effort to reach a destination
whereas teleportation requires little effort if at all. Teleportation doesn't
just mean <em>jumping</em> someplace but also transporting text somewhere, whether it
be someplace else in a buffer or into textual purgatory.</p>
<p>Some call this &quot;code golf&quot; but using that term implies falling into the trap of
constantly optimizing when the aim is to <a href="https://www.justanotherdot.com/posts/how-fast-can-you-take-your-time-kid.html">carve up the text in front of
you</a>.
As such, optimizing for teleportation comes from finding ways to facilitate your
thinking, rather than endless reduction for the sake of reduction.</p>
<p>As teleportation is driven by thought occasionally some
<a href="https://twitter.com/gregmcintyre/status/1194811646234873856">&quot;precognition&quot;</a> is
required. I <a href="https://twitter.com/_justanotherdot/status/1194732136948875264">recently gave an
example</a> where I
and former colleagues would abuse vim's &quot;paragraphs&quot; to jump up and down between
chunks of text by leaving gaps of newlines between them and hitting <code>Shift-{</code> or
<code>Shift-}</code> respectively. I also use syntactical constructs to <a href="https://www.justanotherdot.com/posts/dumping-grounds-for-good-and-bad.html">form
barriers</a>
where chunks of text might go to die if they aren't ultimately used or I might
further abuse whitespace to do <a href="https://www.justanotherdot.com/posts/stdout-is-forever.html">temporary debug
statements</a>. As I
write this article my editor is cutting newlines at eighty characters to make
sculpting up sentences and paragraphs easier.</p>
<p>This brings us to an important point; teleportation is editor agnostic. All
editor users alike, by experience and refinement, have been taught and taught
their editors how to zip around as if they are lightning incarnate.</p>
<p>As such, we have, as a larger community, cultivated a melting pot of ideas that
continually enhance teleportation as a practice. Sublime, VSCode, and others
have popularized the idea of the fuzzy-find palette for discovering files, text
matches in a buffer, git commits for a project, and so on. Things like <code>fzf</code> and
plugins for it now make this accessible to editors that don't have built-in
support. I particularly love fuzzy-find because it favours an aspect of
teleportation I call <em>course correction</em>, so long as the &quot;palette&quot; in question
provides a collection of results. From the results we can change our mind about
the direction we want to head. We can even simply go to some other option
without having to delete and type different results so long as the option is
present (you can do this in <code>fzf</code> with <code>Ctrl-P</code> and <code>Ctrl-N</code>).</p>
<p>Next time you trudge your way across your editor by keyboard or mouse, think
about how you could be teleporting, instead. Spend all those lost minutes on
stuff you want to spend them on. This principle is flexible enough to support
all sorts of optimisations and hopefully I've piqued your interest to explore
building your own.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>An Infinite Barrage of Mountains to Climb</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/an-infinite-barrage-of-mountains-to-climb.html</link>
      <guid>https://justanotherdot.com/posts/an-infinite-barrage-of-mountains-to-climb.html</guid>
      <pubDate>Wed, 13 Nov 2019 19:14:36 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>This Tuesday I went to my last therapy session for the year. In that session I
finalized a relapse prevention program for my obsessive compulsive disorder and
recapped strategies I learned to handle various stressors in my life.</p>
<p>Im one of those exuberant but actually shy people. I love reading and
programming because Id rather be in an internet-equipped mountain cabin away
from the rest of civilization than on a boat in the Caribbean partying. I spend
a great deal of time honing skills through study and experimentation. The
studying has, and sometimes still, makes me anxious and exhausted.</p>
<p>A <em>lot</em> of people experience this; they learn new thing after new thing and when
the mountain seems climbed and truly conquered they look up again only to reveal
a new mountain waiting for them to ascend. If only they climb that next one will
they truly be done. It is a lie. There is never an end to the mountains.</p>
<p>This hurdle of seemingly endless mountains is partly why people feel constant
imposter syndrome. I do. I also feel imposter syndrome when I am full of
self-criticism by attaching my self worth to my productivity. <a href="https://www.google.com/search?q=thought+challenging">Thought
challenging</a> is a
convenient way to question the validity and usefulness of the thoughts we might
encounter that attempt to undermine us. If the thoughts still plague us despite
challenging them, it can also help to try <a href="https://www.google.com/search?q=thought+defusion">thought
defusion</a> where one displaces
the importance of a thought, or thoughts, to something less dominant by various
means. For example I sometimes imagine someone whom I would not trust their
advice as saying the plaguing thoughts to me. This makes it easy to ignore the
thought then. I know it's there, but like a hand on my lap instead of a hand in
front of my face, I barely notice it's presence.</p>
<p>Education matters and in a technical field it is unavoidable. If you dont want
to stagnate you need to keep pushing to improve your skills and knowledge.
Pushing towards discomfort is good! It is the essence of growth to push until we
are uncomfortable. But <em>continually</em> pushing towards things until the bucket of
energy is dry withers away at who we are. We can become not only paranoid from
the rampant thoughts of imposter syndrome but also burned out from our desire to
improve. Rest is a crucial part of the process. Get uncomfortable for a bit,
take a breather, repeat.</p>
<p>Full disclaimer: I am not a medical professional of any kind. All I can do is
try to share some things I've learned that were prescribed and work for me.
Writing this article is more for reminder than it is for sharing. I give no
warranty as to the use of anything said in the entirety of this article. If you
are able to attend therapy and think it might benefit you in any way, shape, or
form, by all means you should try to attend. Getting personalised support is
best. With that said, How do I learn and stay healthy these days? Here's some
things I've picked up in my time wandering around:</p>
<ol>
<li>
<p><strong>You are not your work.</strong> Your work is its own thing. If you are your work you
can not have a critical, and therefore healthy, stance towards it.</p>
</li>
<li>
<p><strong>If you don't feel dumb you aren't learning and everyone who is learning
feels dumb.</strong> You need to pursue this feeling all the while reminding
yourself that everyone feels this and it does not signify that they, or you,
are a dumb person. As they say, it's not about being right but knowing the
truth. People who are always right don't go through this process and don't
actually obtain any deep understanding or learning.</p>
</li>
<li>
<p><strong>Compare yourself to yourself.</strong> Your history is yours alone and it isn't
logical to try to cookie-cutter other people's tales onto your own. Track
your improvements not by comparing yourself to others but by comparing
yourself to your past.</p>
</li>
<li>
<p><strong>Life itself is not work.</strong> Some people might argue that it's OK to dump all
your time into studying or hacking on side projects or whatever but the
reality is we need different entertainment for our brains and we need to give
it rest. Simply &quot;taking a holiday&quot; from your studying or work where you do
literally nothing is a fantastic way to replenish your excitement for the
things you are passionate about.</p>
</li>
<li>
<p><strong>Excitement is healthy and an absence of it is a warning flag.</strong> It helps
clarify what you want to concentrate your efforts on. Yes, sometimes things
will be boring when you learn about a topic but that doesn't mean you have to
read the entirety of Donald Knuths <em>The Art of Computer Programming</em> to make
a program (although it certainly might help). If you can make the task at
hand fun you will probably replenish your store of energy all the while
<a href="https://www.psychologytoday.com/files/attachments/4141/the-neuroscience-joyful-education-judy-willis-md.pdf">retaining information more
effectively</a>.
Doesn't this contradict my argument that we need to get to the state of
discomfort to grow? Not quite.</p>
</li>
<li>
<p><strong>Questions can be fun.</strong> Having a healthy sense to question everything is
what makes people smart. We want to tirelessly get at the truth but the
process of getting there need not be a slog through a muggy swamp on a hot
summer afternoon. You may have had that giddy moment exclaiming &quot;Aha! It
works! But <em>why</em>?!&quot; and whiled away another stream of hours on the problem,
and resulting problems, at hand.</p>
</li>
<li>
<p><strong>Flexibility is a key to happiness.</strong> Rigidity towards expectations on
ourselves and others can lead to a lot of misery. Accepting that things don't
always go to plan and that life is messy goes a long way.</p>
</li>
</ol>
<p>There's always another mountain and it <em>is</em> daunting but hopefully something
I've said here will help make overcoming it, and the chatter of self doubt that
tends to comes with it, easier.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Nothing of Value Will be Lost</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/nothing-of-value-will-be-lost.html</link>
      <guid>https://justanotherdot.com/posts/nothing-of-value-will-be-lost.html</guid>
      <pubDate>Sun, 10 Nov 2019 18:49:53 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p><strong>Drop your backlog. Burn all of your tickets. Eject your issues into the sun.
Nothing of value will be lost.</strong> Teams and maintainers alike cling to reminders
of work as if they are the same as the result of the work itself. Backlog
grooming sessions pass and only thin slabs of the gelatinous mass disappear into
the abyss all the while delaying developers from focusing on actual work.</p>
<p>Design and debate need to occur for a project to progress and when those things
happen it's good to record the results. As these records accumulate they age
because parts take priority over others. Ok, maybe you don't want to drop
<em>everything</em> but you definitely want to drop items older than a certain age. I'm
fond of choosing a natural period of time where you, the human, can easily
enumerate key points that have happened. Longer periods of time produce smaller,
less detailed lists. Periods of time that are too small might experience churn
on the issue tracker as items disappear and return repeatedly.</p>
<p>This process might sound crazed. How dare we close valid issues tied to real
people on an open source project or abandon fixes and feature work that could
drive up revenue and delight users purely because of age? Finding what to work
on is not the hard part, despite what you may think. Prioritising, hashing out
ideas, and setting goals has value but <a href="https://en.wikipedia.org/wiki/Sturgeon%27s_law">ninety percent of everything is
crap</a> and issues sitting in the
dark, ignored and unloved, are alike.</p>
<p>Those using todo lists will know the value of scrapping them at the end of a day
or week. Copying a few things over from prior days or periods of time can be
beneficial but usually the gain is marginal. Adopt a process that reflects the
fact that things change rapidly. <strong>Work that needs doing is from problems and
pain points that are being frequently encountered.</strong> It's work that's at the tip
of the tongue. This is the reason we care about 99th percentiles and avoid
one-off optimisations and bug fixes. What if the bug fix is data being
spuriously deleted? I can guarantee that issue won't stagnate and if it does I
think there are deeper issues that need handling. In the same way <a href="https://stackoverflow.com/a/153565/2748415">Kent Beck
told people on Stack Overflow</a> that
he gets &quot;paid for code that works, not for tests&quot;, one also won't (shouldn't?)
get paid writing or pruning issues.</p>
<p>Neglect the fool's gold of issue trackers. <a href="https://www.goodreads.com/book/show/1633.Getting_Things_Done">Your brain isn't a storage
device</a>; enable
your mind to process what it ought to be processing by using these glorified
todo lists to offload information.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>A Love Letter to Composition</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/a-love-letter-to-composition.html</link>
      <guid>https://justanotherdot.com/posts/a-love-letter-to-composition.html</guid>
      <pubDate>Thu, 07 Nov 2019 06:07:08 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Using composition gives you superpowers. It is by far the most practical
experimentation tool I know.</p>
<p>The <a href="http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Function.html#v:.">dot (.)
operator</a>
is my favorite infix operator in Haskell. Statically typed languages help ensure
that <a href="https://en.wikipedia.org/wiki/Function_composition">function composition</a>
is structurally sound before anything is run. Composition of two functions means
the type of the output of the first function must equal the type of the input of
the next function. Many languages now have a pipe operator which is the
composition operator in reverse. Some even use pipe or dot to write flow of
execution top-to-bottom or bottom-to-top, given how you can stack the calls.</p>
<p>This isn't just an article about the usefulness and specifics around function
composition itself. Composition as a concept forms a basis of for problem
solving and systems of proof. By decomposing a system or problem into parts we
can scrutinize and, thus, verify them for use in constructing the same or
potentially different solutions, proofs, and so on. Having solid building blocks
means we can play around with different arrangements. Playing around with these
building blocks and assumptions is how
<a href="https://www.goodreads.com/book/show/192221.How_to_Solve_It">mathematics</a> and
<a href="https://www.justanotherdot.com/posts/may-you-be-the-author-of-two-to-the-n-programs.html">experimentation</a>
works at its core.</p>
<p>Composition also forms part of the basis of a fascinating branch of mathematics
known as <a href="https://github.com/hmemcpy/milewski-ctfp-pdf">category theory</a>.
Envision a type of mathematics that encodes any arbitrary concept as a
graph-like diagram to explore general structures and relationships. Having a
<a href="https://rs.io/why-category-theory-matters/">mechanism for encoding general
topics</a> empowers you with the
ability to play with structure and assumptions and study the structure and
implications of those arrangements. Caveat emptor; I am not saying composition
<em>requires</em> category theory to be useful! In fact, having too complicated a
system defeats the purpose of having a
<a href="https://www.justanotherdot.com/posts/lightweight-is-beautiful.html">lightweight</a>
guide.</p>
<p>Architecturally, the common phrase that &quot;systems are the sum of their parts&quot; is
a farce. If systems were some linear combination then removing individual
elements would merely reduce the size of the system, but removal can mean total
system failure, no change whatsoever, and possibly improvement in the system as
a whole!</p>
<p>It is rare to find a mental tool so broadly applicable and yet so uncomplicated
in nature. I'll reiterate strongly here; you don't necessarily need to be
pedantic about the shape of things to reap these benefits. Nor do you need to
understand category theory to its <a href="http://eugeniacheng.com/wp-content/uploads/2017/02/cheng-lauda-guidebook.pdf">highest levels of
complexity</a>
to piece together solutions. In my mind the <em>broad</em> steps are always the same:</p>
<ol>
<li><strong>Take, or produce, components</strong></li>
<li><strong>Scrutinize the components</strong> as you may be able to
i. break things down further (1)
ii. see how things connect
iii. or verify the parts are sound</li>
<li><strong>Experiment with arrangements of components</strong></li>
</ol>
<p>I see composition as a framework for experimentation with no added consequence
of increased complexity from the use of the framework itself. Experimentation
allows us to explore new connections. Exploring new connections means finding
solutions to problems in any domain. Discoveries are the bedrock of learning.
Rapid experimentation increases rate of knowledge acquisitions as well as
improved retention of knowledge. This is why composition is a superpower.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>The Lowly Assert: Roundtrips</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/the-lowly-assert-roundtrips.html</link>
      <guid>https://justanotherdot.com/posts/the-lowly-assert-roundtrips.html</guid>
      <pubDate>Sat, 02 Nov 2019 20:37:16 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Data &quot;roundtrips&quot; when it goes from one value, to another, and back to the same
value without any data loss, gain, or corruption. If you write code, you have
probably roundtripped JSON, YAML, TOML, or some other serialization format in
your time. You have also probably written versions of functions that do a
similar 'cycle' of some data. Any time you care about data being the same after
it's gone through the ringer, you want to write a roundtrip test.</p>
<p>Pretend we have a system where data comes in as JSON. We slurp up that JSON into
a type using <code>serde</code> (rust's idiomatic, type-driven serialization +
deserialization library). That data might later go onto being a type unrelated
to JSON, so we might write some <code>From</code> instances. This will be our adaptive
layer so we can keep the shape of the JSON and our core types distinct. I
mention this approach briefly in my post <a href="https://www.justanotherdot.com/posts/safely-shape-code-with-curtains.html">&quot;Safely Shape Code with
Curtains&quot;</a>.
The <code>From</code> instance would normally be trivial, but we don't want the JSON layer
and the core types to look the same, do we? That would make the point of the
JSON types moot:</p>
<pre><code>struct JsonType {
  names: Option&lt;Vec&lt;String&gt;&gt;,
  ids: Vec&lt;i64&gt;,
}

struct CoreType {
  names: Vec&lt;String&gt;,
  ids: Vec&lt;i64&gt;,
}

impl From&lt;JsonType&gt; for CoreType {
  fn from(x: JsonType) -&gt; Self {
    Self {
      names: x.names.unwrap_or(vec![]),
      ids: x.ids,
    }
  }
}

impl From&lt;CoreType&gt; for JsonType {
  fn from(x: CoreType) -&gt; Self {
    Self {
      names: Some(x.unwrap())
      ids: x.ids,
    }
  }
}
</code></pre>
<p>We could test each direction in isolation, but that would mask the actual
mistake here. Can you spot it? The roundtrip test in a property based testing
context would find the failure quite quickly. I'll do it by hand here to
demonstrate the mistake:</p>
<pre><code>let beg = JsonType {
  names: None,
  ids: vec![1,2,3],
};
let roundtrip_fwd: CoreType = expected.into();
let end: JsonType = roundtrip_fwd.into();
assert_eq!(beg, end);
</code></pre>
<p>When the data comes back to the JSON layer, unless we tell <code>serde</code> that empty
vectors are always <code>None</code>s for this field, we've now lost information. Clients
might care a lot that their POST of some JSON for creating an entity in this
make-believe system is non-symmetric. Developers might be going between the core
and the JSON types regularly, and they may even be using the JSON types to write
to disk, too, which would mean what was passed up from the client is now not the
same as what is stored.</p>
<p>We can extrapolate this sort of information loss or corruption to other
conversions. If you author an automatic code formatter, say <code>prettier</code>, <code>gofmt</code>,
<code>mix fmt</code>, <code>rustfmt</code>, and so on, you'd want to make sure that any time you save
a file and the formatter runs that your code is still the same code,
semantically, as it was before saving the file. Although things might possibly
look the same by eye, it could be another program entirely when run.</p>
<h3>Food for thought</h3>
<p>A quick refresher on functions.</p>
<ul>
<li>Functions can be seen as <strong>mappings</strong> from one type of value to another</li>
<li>All possible values that can go into our mapping are known as the <strong>domain</strong> of
a function</li>
<li>The set of all possible values our mapping can produce is called the <strong>codomain</strong></li>
<li>The set of all values the mapping realistically produces is called the
<strong>range</strong> or <strong>image</strong></li>
</ul>
<p>Ok, onto the concepts with fancy names:</p>
<ul>
<li>
<p>An <strong>injective</strong> mapping is when a mapping goes from values in the domain to
<em>unique</em> values in the codomain.</p>
</li>
<li>
<p>A <strong>surjective</strong> mapping is when a mapping goes from values in the domain to
<em>every</em> value in the codomain, even if some mappings overlap.</p>
</li>
<li>
<p>A <strong>bijective</strong> mapping is <strong>simultaneously injective and surjective</strong> which
means every value in the domain maps to every value in the codomain exactly
once.</p>
</li>
</ul>
<p>Why does this matter?</p>
<p>Bijective mappings give you an inverse function for free. If you are a value in
the codomain and you know the mapping is bijective, then you can be sure that
there must be one, and only one, value where you came from in the domain.
One could <a href="https://math.stackexchange.com/a/165440/156419">prove bijections</a>
using classical means but we don't need to for production usage. Instead, it
suffices to simply show the action going forwards and backwards.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>The Lowly Assert: Idempotence</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/the-lowly-assert-idempotence.html</link>
      <guid>https://justanotherdot.com/posts/the-lowly-assert-idempotence.html</guid>
      <pubDate>Wed, 30 Oct 2019 20:28:07 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Charging someone twice is bad for business; it burns trust with customers and it
involves a lot of unnecessary churn. Payment providers go to <a href="https://stripe.com/au/blog/idempotency">great
efforts</a> to support <em>idempotent</em>
endpoints. When you do something more than a given number of times, and every
time after that, things don't change. In the case of a payment it would be once
and only once, no matter how many times the request was submitted after that.</p>
<p>An
<a href="https://www.justanotherdot.com/posts/the-lowly-assert-involution.html">involutive</a>
function is idempotent modulo a <em>certain</em> number of applications. Involutive:
Driving a car around a square block means after four turns you're back on the
same corner you began on. Idempotent: A volume knob that reaches maximum volume
but still keeps turning. The assertion of idempotence looks suspiciously like
involution, but the concepts aren't quite the same:</p>
<pre><code>-- Involutive

f(x)       != x
f(f(x))    == x
f(f(f(x))) != x

-- Idempotent

g(x)       == x
g(g(x))    == x
g(g(g(x))) == x
</code></pre>
<p>If the function <code>f</code> was a one-hundred and eighty degree turn around a point then
the next part of the series would be another equality and would alternate back
and forth for every other function application. In the case of <code>g</code>, we do
something once, twice, or n-many times and nothing seems to change. Per the
volume example, there might be <em>some</em> changes initially, but <code>g</code> becomes
idempotent at or after a particular value.</p>
<p><a href="https://en.wikipedia.org/wiki/Idempotence">Idempotence</a> can relate to values,
but it can also relate to side effects, such as the payment example we've given
above. A &quot;thunk&quot; is a function that performs a calculation once and then stores
(&quot;memoizes&quot;) that result to return on all future calls: in this case a thunk is
idempotent in its computation: it's lazy <em>and</em> cached.</p>
<p>Things don't always <em>need</em> to be idempotent but can be chosen to be idempotent
for stylistic reasons. One API may force users to use explicit <code>insert</code> and
<code>update</code> calls, managing the housekeeping of keys itself, whereas a different,
but equally effective, API could allow a single endpoint that &quot;saves&quot; the
provided data, inserting at first, overwriting when the data is different, and
idempotent when the data is the same, forcing the tracking of keys on the
client. Both of these are valid options but have different trade offs for
particular applications!</p>
<p>When you think of idempotence, think about the mental model of things &quot;clamping&quot;
into place for a particular subset, or all, of our domain (inputs). And while
you're at it, make sure no one ever gets charged again for smashing the refresh
button for a slowly loading payment submission page!</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>The Lowly Assert: Involution</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/the-lowly-assert-involution.html</link>
      <guid>https://justanotherdot.com/posts/the-lowly-assert-involution.html</guid>
      <pubDate>Tue, 29 Oct 2019 05:43:10 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>As part of <a href="https://www.justanotherdot.com/posts/the-lowly-assert.html">The Lowly
Assert</a> series I
wanted to go over some mathematical patterns. Filling your arsenal of known
properties helps with recognizing common ways functions, systems, etc. are, and
should continue, to behave.</p>
<p>Occasionally you'll write functions that flip-flop: when you call the function
multiple times in a row, chunks seem to cancel out. Mathematics calls these
functions <a href="https://en.wikipedia.org/wiki/Involution_(mathematics)">&quot;involutive&quot;</a>. Negating a number or a boolean twice gets you back
to the original value. Involution is handy to recognize because it's a simple
assertion:</p>
<pre><code>x == f(f(x))
</code></pre>
<p>The classic property based testing example of this is the
<code>reverse(reverse(some_list))</code> you'll see in endless tutorials and getting
started guides on the subject. When you reverse a list you expect to simply flip
the contents one end to the other, but this may not be immediately applicable to
day-to-day affairs. Here's one: a function that opens a dialogue box has two
states, open and closed, and is commonly tested for involutivity; if you didn't
have the toggling action you'd see no feedback after clicking!</p>
<p>But involution doesn't have to be about functions applied exactly twice.
Rotating around a point back to an original direction can be done with various
divisions: two rotations of pi, four rotations of pi/2, and so on. Precisely,
involution requires that the application be a single function, but we can
sometimes be a bit less rigorous and claim that two or more actions that
eventually cancel out are involutive: removing and adding an item in a
collection or returning someone's money in an exchange.</p>
<p>With this we can hopefully see the application isn't on any end of the scale:
from small to big, XORing bits to whole product flows that might 'restart' the
user in a funnel. Properties like these are worth their weight in gold because
they are useful in almost any type of testing and are definitely a shining
example of The Lowly Assert.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Making Plants Thrive</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/making-plants-thrive.html</link>
      <guid>https://justanotherdot.com/posts/making-plants-thrive.html</guid>
      <pubDate>Wed, 23 Oct 2019 19:38:18 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>It's often lamented that software projects become dead plants in an unloved
garden: we excitedly keep buying new plants but we don't put in the time to see
them thrive.</p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Anyone else&#39;s GitHub account literally just a graveyard of good intentions? </p>&mdash; CaroOooOoOolyn  (@carolstran) <a href="https://twitter.com/carolstran/status/1184938790533681152?ref_src=twsrc%5Etfw">October 17, 2019</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>The appeal of building something new, playing with some fancy dependency or
tool, trying out some new process; if only we could resist the temptation. But
we shouldn't resist the temptation because this is the sign of healthy
experimentation! <strong>It's far better to experiment in your spare time than to use
your career as an excuse to try out the next shiny thing.</strong></p>
<p>I'm a huge fan of &quot;laboratories&quot; where questions you have regarding code are
answered by creating code and committing them to a central repository. Making
them multi-language helps by reducing friction for testing things out. A
graveyard of good intentions becomes a collection of prior discoveries.</p>
<p>This doesn't change the fact that we feel guilty that we can't keep the plant
alive. It takes a little discipline, and maybe for some, a bit of prior
knowledge, but it's not too hard to get things into place. In the same way we
reduced friction by making a project multi-language, introducing automation to
reduce toil is the best way for us to combat bitrot; if we can come back to
projects knowing full-well they build, we are much more willing to continue to
&quot;water the plants&quot;. Making a project thrive comes in a few major parts:</p>
<ol>
<li>Testing and building the code before it reaches trunk/master</li>
<li>Artifacts (library, binary, etc.) are created and published</li>
<li>Said artifacts may be deployed to a server to run</li>
</ol>
<p>Many other automations can be done too: linting, dependency updates, scheduled
builds, et. al. Scheduled builds are cool (and underrated) because they
continuously show projects are building and tests are passing. You now have
extra capacity from all the built artifacts to handle services going down or
security updates having been released. <strong>If you automate away the toil, you can
treat a project less as a chore (by focusing less on the accidental complexity)
and more as a labor of love (by focusing on the inherent complexity of the
problem you are trying to solve).</strong></p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Dumping Grounds for Good and Bad</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/dumping-grounds-for-good-and-bad.html</link>
      <guid>https://justanotherdot.com/posts/dumping-grounds-for-good-and-bad.html</guid>
      <pubDate>Mon, 21 Oct 2019 19:04:52 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>A former colleague and friend once referred to modules that grow without any
clear organisation as &quot;The Dumping Grounds&quot;. You probably know this module: it
often is named &quot;utils&quot; and acts as a kitchen sink for anything you are unsure
where to put. It might come in a different name, and there might be several of
them when the last dumping grounds were abandoned. When that happens, it's only
a matter of time until the majority of modules all become dumping grounds.</p>
<p>I do this thing when I'm coding or writing articles sometimes that I <em>also</em> call
&quot;The Dumping Grounds&quot;. It's similar because it's a pit of random junk I think
might be useful but may also just be crap. I have a rule about this space:
whatever is left in there by the time I'm done with the main chunk of work gets
thrown out. No disputes.</p>
<p>I might do this with things like whitespace or certain patterns of characters,
when writing these articles. For example, I'll tend to put a triple-hyphen or
triple-underscore to mark where the dumping ground begins and it (generally)
ends at the end of the file.</p>
<p>With the clear discrepancy of the dumping grounds, you can pick and choose what
you want from it, knowing full well it will get deleted. Other times, like in
code, it can be a bit more subtle.</p>
<p>When people work, there tends to be a bit of mess accumulated in particular
areas of the final piece. If the whole thing is a mess it can be hard to think,
but if the mess is distinct it can be a guiding force. Parts of a sculpture
might clearly be finished and other parts are in the rough. When I code, there
is usually a combination of tactically using whitespace, comments, and sometimes
syntactic/type constructs to keep chunks of mess easily identifiable, and, most
importantly, deletable.</p>
<p>If you <strong>treat dumping grounds as the landfills they are and try to keep them
out of your results</strong> then you'll get closer to the target you want. By using
this form of recognizable mess attached with a rule you can do just that, but
remember that mess is inevitable and that's ok! This approach isn't saying &quot;it
can <em>all</em> be a bit messy <em>just for this one piece</em>&quot;. What it is saying is &quot;this
is what I want and this is the mess I'm using to get there which <em>I will not
keep</em>&quot;.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Safely Shape Code With Curtains</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/safely-shape-code-with-curtains.html</link>
      <guid>https://justanotherdot.com/posts/safely-shape-code-with-curtains.html</guid>
      <pubDate>Sat, 19 Oct 2019 21:29:55 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Once upon a time I studied photography at an art school. It was there that I
learned the importance of separation between tones in an image. If the
separation, tone or color, between objects in my images wasn't quite right I'd
have to redo all my work in order to get a grade. <a href="https://en.wikipedia.org/wiki/Gestalt_psychology">Separation is how we often
define our mental maps of the
world.</a> For this article, I'll
call anything that is distinct from other things an &quot;entity&quot;.</p>
<p>Entities have edges. They may have eddies of communication or arrows of
connection through these edges. Edges may be incidental, e.g. defined by people
you don't know or from natural consequences, or they may be intentional, i.e.
the result of deliberate planning and execution. Entities have non-zero surface
area, otherwise they wouldn't exist, but that doesn't mean they cannot be
relatively invisible.</p>
<p>Clarifying (edges) means simpler mental maps. Simpler mental maps means easier
to reason about systems and programs. Simpler systems and programs means
increased velocity for progress and experimentation. Each of these examples
could be their own posts, but for now it suffices to say that examples of this
type of organization (clarification) are,</p>
<ol>
<li>
<p>Serialization to the wire (network), disk, and internal datatype definitions
<em>individually</em> go into their respective modules</p>
</li>
<li>
<p>Core logic that performs calculations versus reading from disk, e.g.
application level versus storage engine logic, are separated</p>
</li>
<li>
<p>Munging layers, or what some call an adapter, that transform data to the
shape you so desire are not tied into (1). This is bidirectional; it's
equally fair to have the adapting layer work on outbound and inbound
interfaces.</p>
</li>
</ol>
<p>Most of this might feel a bit obvious: things have edges and that's how
we tell they are distinct, but how does this relate to coding?</p>
<p>It's common to think that programming <em>has</em> to be a balancing act between
progress (by accepting breakage) and stability (by leaving things alone). I've
talked a bit before about <a href="https://www.justanotherdot.com/posts/may-you-be-the-author-of-two-to-the-n-programs.html">how vital constant experimentation
is</a>,
but this balancing act is not the <em>only</em> way to go about things. Yes, things
break when they have production data running through their digital veins and
having instrumentation to gain visibility into your running code in production
is crucial to combat this statistic of failure, but let's consider another
approach to the development side of correctness.</p>
<p>Although it may seem strange for me to use the term <em>artificial</em> when all the
boundaries discussed here seem planned by ourselves or by others, I use the term
&quot;curtain&quot; here to denote <em>artificial</em> delineations we establish to avoid working
in <em>slices</em>. A sliced approach to development means we attempt to get all
working functionality, from front to back, one slice at a time. In the following
diagram the red boxes are slices of features whereas non-sliced functionality is
stable:</p>
<figure>
  <img
    src="/assets/images/sliced-development-example.png"
    alt="a diagram depicting 'sliced' development"
    title="An example of 'sliced' development">
  </img>
</figure>
<p>We can define &quot;curtains&quot; (again: artificial edges for the purposes of
development) to retain stability in all areas &quot;exterior&quot; to the curtain.
&quot;Exterior&quot; may very well be &quot;interior&quot; code! Setting up curtains can be done
with <a href="https://www.justanotherdot.com/posts/move-fast-and-tuck-code-into-the-shadows.html">feature-flags, parallel
implementations</a>
or even creating new surfaces where interaction will be performed and migrating
after the fact when everything seems settled. As long as the &quot;exterior&quot; to the
curtain go on its life as if nothing is wrong, a curtain serves its purpose. Per
the example above it might look like this:</p>
<figure>
  <img
    src="/assets/images/curtained-development-example.png"
    alt="a diagram depicting 'curtained' development"
    title="An example of 'curtained' development"
  </img>
</figure>
<p>In this diagram, you could be setting up the curtain to keep the core of the
application stable or the client and interfaces the client talks to stable. A
curtain based approach by no means requires having a layered architecture or
thinking in that manner. The fact that a curtain is malleable and artificial
means we can define its boundaries, but a curtain becomes a slice when it
overlaps too many real edges in a system. Why is this any better than a sliced
approach?</p>
<p><strong>Curtains buy you breathing room.</strong></p>
<p>There is always an implicit countdown when you keep things stable but don't make
progress. &quot;Where is the business value they are adding?&quot; squawks the manager. If
you are making a lot of progress but breaking things the countdown timer is time
to completion but in the face of churn, top-down pressure, peer-pressure, and so
on. <strong>Breathing room gives you space to think. Space to think means you can buy
yourself breathing room. This helps build healthy systems with reduced
complexity and healthy systems means higher rates of progress and
experimentation.</strong></p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Fool's Gold: Time Estimates</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/fools-gold-time-estimates.html</link>
      <guid>https://justanotherdot.com/posts/fools-gold-time-estimates.html</guid>
      <pubDate>Tue, 15 Oct 2019 19:02:35 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>It would be fantastic if we knew the future. With that knowledge we could plan
with the utmost precision. But we are not clairvoyant. We actively exercise a
process of guesses we dress up in the fancier name of &quot;estimates&quot;. Enrico Fermi
would feel these guesses are fine so long as you are <a href="https://en.wikipedia.org/wiki/Back-of-the-envelope_calculation">within an order of
magnitude</a>. This
form of educated guess is also known as a &quot;back of the envelope&quot; calculation and
most random guesses are not doing anything near this <a href="https://www.wired.com/story/how-to-get-better-at-back-of-the-envelope-calculations/">level of
rigor</a>.
Back of the envelope calculations take rough approximations, simplified
assumptions, and various tidbits of top-of-the-mind knowledge to calculate a
<a href="https://en.wiktionary.org/wiki/ballpark_figure">ballpark figure</a>.</p>
<p>Put yourself in the shoes of a manager of a team and imagine asking each person
in this team &quot;how long do you think this task will take to finish?&quot; This could
well be <em>any</em> type of task. Estimations may sometimes vary wildly and sometimes
group around a certain value. Any kind of grouping is a coincidence. Asking the
same person about an estimate even the next day may yield different results. How
could you help improve the accuracy of these estimations with such fluctuating
results?</p>
<p>One option is to decide on all the work you expect upfront. If you know how work
is subdivided <em>exactly</em> you'll know, transitively, how long the total task will
take, right? Wrong.</p>
<p>Instead you'll starve people of autonomy around how they can tackle a goal.
Starving autonomy means people stop thinking and now you'll have to work even
harder to keep everyone productive. It also makes people unhappy, whether they
realize it or not, and you'll probably wind up with a great deal of turnover
because of it.</p>
<p>What about using time taken from similarly sized tasks? If it took someone a
certain number of time to complete a task with a rough &quot;t-shirt size&quot; then it
ought to take another, or the same, person roughly the same, right? Wrong.</p>
<p>Even if you had the same person doing the same task there is the possibility
that some spontaneous act can change timings drastically. People get sick. Their
dependents and partners get sick. Trains get delayed and vehicles break down.
The human brain decides to watch a video for an hour instead of fifteen minutes.
A meeting that was scheduled for an two hours only takes one.</p>
<p>We tend to attach degrees of confidence to our guesses but never seem to discuss
those confidence levels openly. We also tend to wrongly consider <a href="https://blog.codinghorror.com/how-good-an-estimator-are-you-part-ii/">tapered
ranges</a> as
the more accurate guess. We feel pressured to pick the most likely range and
make it a promise. <strong>Resist this temptation and try making this range of
possibilities explicit.</strong></p>
<p>Many people focus on what kind of confidence they back on a single range, but
our confidence may differ between slices of respective intervals of time. <strong>Try
to consider that your confidence in your guesses is not a normal distribution
centered around a single range; Confidence may be distributed in any number of
ways.</strong> There may be a high probability that the job gets finished if we focus
on it at the beginning and the end of the year, but a low probability otherwise.
If we have the time to work on this task on the fortnight's the probability goes
up, but the likelihood of completion dips on the weeks in-between.</p>
<p>Does a low probability mean impossibility? No. Nor does a high probability imply
absolute certainty. A range of probabilities discusses the full spectrum of what
might be feasible. It is better to know you think a project might take only a
months work of time all the way up to six months than it is to merely work under
the assumption that the single month would do.</p>
<p><strong>Make back of the envelope calculations by decomposing problems into
constituent parts.</strong>. The refinement of the accuracy of these parts refines the
overall estimation. This isn't to say breaking down a random guess into several
random guesses will improve accuracy. In fact, with the random-guessing approach
you will probably be reluctant to go below a certain lower-bound, which means
that a decomposed guess might far exceed the original guess. Back of the
envelope calculations try to tie you to real facts, although possibly
simplified, without believing the hype that you can estimate down to the minute
based on prior similar scenarios (see above). Machine learning won't save you.
The great thing about back of the envelope calculations is that they work
equally well for both high- and
<a href="http://highscalability.com/blog/2011/1/26/google-pro-tip-use-back-of-the-envelope-calculations-to-choo.html">low-level</a>
concerns.</p>
<p><strong>Pretending estimates given on work are guarantees is fool's gold.</strong> Push back
on demands for promises when you know you are only making a guess. We might get
better at making guesses with time by practice and research but a guess is still
a guess, educated or not.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>How Fast Can You Take Your Time, Kid?</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/how-fast-can-you-take-your-time-kid.html</link>
      <guid>https://justanotherdot.com/posts/how-fast-can-you-take-your-time-kid.html</guid>
      <pubDate>Wed, 09 Oct 2019 20:38:58 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>There is nothing wrong with chopping wood and carrying water. Hard work
certainly pays off. Hackers are notorious for <a href="http://threevirtues.com/">revelling in
laziness</a> but laziness has a stigma of the lazy party
not <em>being enough</em>. <a href="https://en.wikipedia.org/wiki/Laziness">Wikipedia</a> states,</p>
<blockquote>
<p>[laziness] may reflect a lack of self-esteem, a lack of positive recognition by
others, a lack of discipline stemming from low self-confidence, or a lack of
interest in the activity or belief in its efficacy.</p>
</blockquote>
<p>I'm not sure I think laziness is the right virtue for what hackers claim it
stands for. I'm not sure I think laziness is right for me.</p>
<p>Taoism has this idea called Wu Wei <a href="https://en.wikipedia.org/wiki/Wu_wei">&quot;a concept literally meaning &quot;inexertion&quot; or
&quot;inaction&quot;&quot;</a>. Wu Wei implies that going
against one's nature is an act of exertion. A tree has Wu Wei as it grows; there
is no thinking or straining towards the new shape but simply an act of <em>being</em>,
of following it's instincts towards the light and water.</p>
<p>William S. Burroughs wrote an essay called 'Do Easy' and Gus van Sant <a href="https://www.youtube.com/watch?v=eoOUBETTyMI">recorded
a video about it under the same
name</a>. The Discipline of Do Easy
embodies much, in my eyes, that is Wu Wei.</p>
<p>There is sometimes an illusion of progress through lots of pull-requests,
updated dependencies, rushing to complete features, and so on. Discomfort and
pain are nature's way of telling us that we are growing. It is the same when
your brain hurts when you study as it is when you exercise at the gym; growth is
a constant cycle of compression and decompression. How do we pair this cycle
with the idea of Wu Wei and Do Easy?</p>
<p><a href="http://www.bopsecrets.org/gateway/passages/chuang-tzu.htm">The Parable of Cook
Ting</a> is my favorite
Taoist fable. In it, an emperor eats a meal that touches him deeply; someone who
cooks a meal like <em>that</em> must know a thing or two about life! And off he goes to
beg the chef to share his secrets. The cook replies:</p>
<blockquote>
<p>What I care about is the Way, which goes beyond skill. When I first began
cutting up oxen, all I could see was the ox itself. After three years I no
longer saw the whole ox. And now  now I go at it by spirit and dont look
with my eyes. Perception and understanding have come to a stop and spirit
moves where it wants. I go along with the natural makeup, strike in the big
hollows, guide the knife through the big openings, and following things as
they are. So I never touch the smallest ligament or tendon, much less a main
joint.</p>
</blockquote>
<p>he goes on to talk about his tool of the trade,</p>
<blockquote>
<p>A good cook changes his knife once a year  because he cuts. A mediocre cook
changes his knife once a month  because he hacks. Ive had this knife of mine
for nineteen years and Ive cut up thousands of oxen with it, and yet the
blade is as good as though it had just come from the grindstone. There are
spaces between the joints, and the blade of the knife has really no thickness.
If you insert what has no thickness into such spaces, then theres plenty of
room  more than enough for the blade to play about it. Thats why after
nineteen years the blade of my knife is still as good as when it first came
from the grindstone. However, whenever I come to a complicated place, I size
up the difficulties, tell myself to watch out and be careful, keep my eyes on
what Im doing, work very slowly, and move the knife with the greatest
subtlety, until  flop! the whole thing comes apart like a clod of earth
crumbling to the ground. I stand there holding the knife and look all around
me, completely satisfied and reluctant to move on, and then I wipe off the
knife and put it away.</p>
</blockquote>
<p><strong>It isn't to say that discomfort or pain won't come. Overexerting yourself when
a task needs far less effort is wasted effort.</strong> It damages you and your tools.
You and your mind are the knife. You are the chef. Many times we jump to hacking
away tirelessly when a no-code solution is right there in front of us. When code
is required finding the toil and automating it away alleviates wasted effort
from repetition you don't need to make.</p>
<p><strong>Work in a way so you never need a grindstone.</strong> Growth is no different. Exercising
without any rest means there is no time for your body to recover and build new
muscles. Sleeping on a subject you've been studying allows your subconscious to
forge new connections which is the essence of learning. <strong>There are healthy ways
to grow as there are healthy ways to work. Don't be the machine.</strong></p>
<p><strong>Keep your eyes on what you're doing, be patient, and move with the greatest
subtlety until the whole thing crumbles before you.</strong></p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>The Lowly Assert</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/the-lowly-assert.html</link>
      <guid>https://justanotherdot.com/posts/the-lowly-assert.html</guid>
      <pubDate>Mon, 07 Oct 2019 21:43:52 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>There is one thing that ties all forms of testing together; <strong>assertions</strong>. The
lowly assert humbly serves whether it's as types, panics, automated tests, or
any other glorious form. Regardless of how it manifests itself, it allows us to
declare things about our systems or program and automatically check them.</p>
<p>But when people test they don't tend to think about what they are asserting.
I've met a great number of people who are taught testing as a mechanical
practice, one that is simply followed because of the social expectation that a
tested system is a 'correct' system. But what is correctness?</p>
<p>Correctness is not merely the absence of bugs. <strong>Correctness is the assurance
that a system is doing as is intended.</strong> This can be business logic or even
sterile concerns like if a function returns the right value given the right
inputs (forms of unit tests). It can be about output or generated content
looking the way it's supposed to look (snapshot tests). It can be about multiple
systems behaving when coupled (integration tests) or about whole flows of usage
(end-to-end tests or possibly contract tests). The things we are testing <em>for</em>
and the ways to test for them is vast.</p>
<p>It helps to think about blocks of computation as black boxes: inputs go in and
outputs come out. Assertions that need to be upheld,</p>
<ul>
<li>while things are happening inside of the box are called <strong>invariants</strong></li>
<li>before the box starts work are called <strong>preconditions</strong></li>
<li>after the box has finished work are called <strong>postconditions</strong></li>
</ul>
<p>There are also a number of general properties the box can uphold:
<a href="https://en.wikipedia.org/wiki/Involution_(mathematics)">involutivity</a>,
<a href="https://en.wikipedia.org/wiki/Idempotence">idempotence</a>,
<a href="https://en.wikipedia.org/wiki/Partial_function#Total_function">totality</a>, etc.
The specifics of each of these isn't important but the idea is that there are
reusable patterns for guarantees we can wish from our systems and programs.</p>
<p>This article is the start of many to describe how the varying forms of
assertions lines up with their respective forms of testing. There are even
meta-principles at play about asserting facts about systems that we should make
elicit in the hopes they better our testing in general. These explorations
aren't going to be exhaustive but I am hoping they help expand your mind in the
things you can ask your code enforce.</p>
<p>A quick journey and recap, if you will.</p>
<p>When you write a program, you might use a typed programming language. In this
case you can use types to encode facts about your problem domain and structure
of data. <a href="https://blog.janestreet.com/effective-ml-revisited/">With types we can help make illegal states
unrepresentable</a>.</p>
<p>Later, you are writing a program and you want to know it acts the way you are
expecting it to act. Compilation non-withstanding you start to run the program
and check the results manually. <a href="https://landing.google.com/sre/sre-book/chapters/automation-at-google/">But this sort of tedium is easily
automated</a>.
<strong>Toil should infuriate you!</strong> With this sentiment in mind you start writing a
program to run your program in different circumstances, hence automated testing
is born. Now that you have this tool in place, you can run tests on small things
all the way up to big things. When the assertions in question fail, the tests
fail.</p>
<p>When a system misbehaves, you might want to know immediately while you are
coding and what faster way to know than to have your program halt when an
assertion is not met. Perhaps a failure is even one which requires a process to
abort while running in production (a fatal error). The difference between these
two is the subject of recoverable versus unrecoverable errors, which I won't
indulge in here, but it suffices to say catching mistakes and misunderstandings
sooner is always better than later by <a href="https://www.cs.tufts.edu/%7Enr/cs257/archive/jon-bentley/correct-programs.pdf">attaching these sorts of assertions to
forms of
panics</a></p>
<p>Now your test suite tests both small and large. As these tests get more
complicated, assertions can be about <em>models</em> of these systems; as state
machines or even where the inputs are generated randomly. <a href="https://www.youtube.com/watch?v=hXnS_Xjwk2Y">Property based
testing</a> starts joining your
repertoire for this reason. For verifying raw memory access you consider
<a href="https://en.wikipedia.org/wiki/Fuzzing">fuzzing</a>. Perhaps the end-to-end tests
are brittle and always breaking which might lead you into <a href="https://docs.pact.io/">contract
testing</a> two systems to ensure that the pre- and
post-conditions (read: the contract) are being met. Maybe there are extremely
complicated concerns such as concurrency and you write a
<a href="https://en.wikipedia.org/wiki/Formal_specification">specification</a> in something
like TLA+ which can verify the model it describes as part of the tooling.
Specify the system or program abstractly and test that, instead.</p>
<p>Like anything, there are diminishing returns. Finding assertions everywhere
doesn't mean proving your TODO-list single page application with a theorem
prover or dependant types is worth the time, although if those processes were
more lightweight it <em>would</em> probably be worth it! <strong>Think of assertions as bets
that pay off when code is introduced that violates them.</strong></p>
<p>Systems come in all sizes but despite their mixed formats they are all guided by
principles. <strong>Instead of thinking the path to correctness is forged by
mindlessly coding and churning out fixes, try to think about the properties you
want upheld, instead, and work to encode those in every possible assertion you
can leverage within reason.</strong></p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>How I Git</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/how-i-git.html</link>
      <guid>https://justanotherdot.com/posts/how-i-git.html</guid>
      <pubDate>Mon, 07 Oct 2019 20:02:46 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>I thought it might be worth having a look at two things <code>git</code> allows I've abused
to remove some warts and toil from my day-to-day flow.</p>
<p>One thing <code>git</code> does is alias support. Anything under the <code>[alias]</code> key in ones
<code>$HOME/.gitconfig</code> is treated as a valid subcommand. This is fine for quick
things, like <code>r</code> as <code>rebase</code> or <code>a</code> for <code>add</code>, but you can also alias one-line
scripts, for example, here's a snippet from my <code>.gitconfig</code>.</p>
<pre><code>  it = &quot;!f() { git fp &amp;&amp; git r origin/master; }; f&quot;
</code></pre>
<p>This demonstrates defining an ad hoc shell function named <code>f</code> and calling it
immediately. What's notable about this is that it is <em>also</em> calling a <code>git</code>
alias. <code>git fp</code> in this case is an alias for <code>git fetch --prune</code> and <code>r</code> we've
already mentioned is <code>rebase</code>, so this, verbosely, is,</p>
<pre><code>$ git fetch --prune &amp;&amp; git rebase origin/master
</code></pre>
<p>Another thing <code>git</code> let's you do is invoke arbitrary scripts that are named in
the format <code>git-name</code>. If the script is on the path, you can call <code>git name</code> and
the script, <code>git-name</code>, will run. My old process for pushing to a branch I had
authored was a bit verbose,</p>
<pre><code># on first push
$ git push -u origin/master current-branch

# afterwards ...
$ git fetch --prune

# and, after hacking, changes both behind + ahead on branch (rewritten history)
$ git push --force-with-lease

# or, if simply, without any `--force*` flag
$ git push
</code></pre>
<p>I wrote a script that does all of this, automatically, called
<a href="https://github.com/justanotherdot/gits/blob/master/scripts/git-p"><code>git-p</code></a>,
which lets me call <code>git p</code>. It's doesn't work for all corner cases, and could be
extended to, but this fits ninety-nine percent of my use case. This worked well
for awhile, but I needed to build on it. I eventually wrote an alias called <code>git up</code>,</p>
<pre><code>  up = &quot;!f() { git it &amp;&amp; git p; }; f&quot;
</code></pre>
<p>The point of <code>up</code> is to ensure my changes are always rebased on master before I
push. This is pretty handy but I've recently added yet another alias called
<code>raise</code> (also aliased as <code>pr</code>),</p>
<pre><code>  raise = &quot;!f() { git up 2&gt;&amp;1 | awk '/http/ { print $2 }' | xargs open; }; f&quot;
</code></pre>
<p>This scrapes out the remote output with the PR creation link that GitHub
provides after a branch is first pushed to the remote repository and funnels it
into <code>open</code>. MacOS X has <code>open</code> as the default way to open mime-type related
files to respective 'default' applications. On linux, where I use the gnome
windows manager, I have the shell alias,</p>
<pre><code>$ which open
open: aliased to xdg-open
</code></pre>
<p>to try to bridge the gap, which just goes to show aliases and scripts that use
this same format can be really handy for hiding away toil! I don't know if it's
ideal for all CLI tooling but I think this approach is certainly an interesting
approach to let people slip in their own functionality and 'rewire' an interface
to better suit their needs.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Actually Using Git Worktrees</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/actually-using-worktrees.html</link>
      <guid>https://justanotherdot.com/posts/actually-using-worktrees.html</guid>
      <pubDate>Sat, 05 Oct 2019 13:48:54 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Let's say you are expected to do code review and you are also expected to code.
When you do either a certain set of changes is in place. Switching because you
are blocking someone means you <em>have</em> to do a dance with stashing changes,
checking out a branch, perhaps cleaning temporary files, restarting tooling,
etc. Bar changing your codebase, workflow, and job requirements, here's an
approach that uses <code>git</code> <a href="https://git-scm.com/docs/git-worktree"><code>worktrees</code></a> to
ease the cost of these context-switches.</p>
<p><code>git</code> uses <code>worktree</code>s to track changes in a repository. <code>git</code> gives us the
ability to make more than one <code>worktree</code> at a time that are checked out to
potentially different sets of changes. This means we can effectively split up
our codebase into review and development environments:</p>
<pre><code>$ git worktree add ../foo-review --checkout master # where `foo` is the name of your project
$ cd ../foo-review
$ git clean -fddx
$ git checkout branch-name
</code></pre>
<p>You can tuck the change-directory code into a script if there's a slew of other
steps needed to get into a good-known state. If you are using GitHub, here's an
added bonus for checking out pull requests by number rather than by branch name:</p>
<pre><code>[alias]
  &lt;snip&gt;
  copr = &quot;!f() { git fetch origin pull/$1/head &amp;&amp; git checkout pr/$1; }; f&quot;
  &lt;snip&gt;
</code></pre>
<p><em>N.B. There are alternative ways of <a href="https://gist.github.com/piscisaureus/3342247">fetching all remote pull requests from
GitHub</a> which might be preferable
to the above alias.</em></p>
<p>GitHub assigns this special remote tracking branch to your PR, but it's
read-only so if you want to contribute changes you will need to know the name of
the original branch.</p>
<p>With this setup the context-switch dance is reduced. The workflow could be like
this:</p>
<ol>
<li>Someone asks for a review or perhaps you're done and want to get back to work</li>
<li>Calling <code>work</code> might get you back into your development environment where you
left off</li>
<li><code>review branch-name</code> will go the other direction preparing the pull-request
for inspection</li>
</ol>
<p>Git aliases are a neat way to remap the surface area of <code>git</code>. I actually think
this is a utility for configuration I don't see more CLI tooling using that
probably could to great effect. In the context of <code>git</code> it allows me to get
around some particular ergonomic warts. Also, I don't do this workflow anymore
as I leverage pull-requests largely for communicating changes more than
gate-keeping these days, but I understand not all circumstances are the same.
Worktrees could be used to keep a reference implementation around for quickly
inspecting without having to switch branches, for example. Little things like
this that help reduce toil are worth their weight in platinum so it pays to keep
your eye open to automation opportunities!</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Fool's Gold: Code Coverage</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/fools-gold-code-coverage.html</link>
      <guid>https://justanotherdot.com/posts/fools-gold-code-coverage.html</guid>
      <pubDate>Wed, 02 Oct 2019 06:41:51 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>If you are unfamiliar with code coverage, the idea is simple: you write
accompanying tests to code and a code coverage tool produces reports of lines
covered by tests and the percentage of that coverage to all lines of code. The
hope is that a higher coverage with tests means you'll have a 'correct' system.
I have even heard of some establishments initiating quotas on required coverage
per lines of new code being introduced. &quot;If it doesn't have tests it doesn't
exist&quot; is the usual argument for this requirement; code without tests is
potentially problematic code, but tests are also <em>untested chunks of code</em> in
our codebase. For example, consider this bit of React code:</p>
<pre><code>test('Breadcrumb renders', () =&gt; {
  expect(() =&gt; {
    &lt;Breadcrumb/&gt;
  }).not.toThrow();
});
</code></pre>
<p>What is this testing exactly? Literally any other test, even one without the
<code>toThrow</code> expectation, would mark this as a failure on an exception being
thrown. This will light up code coverage though. People learn to cheat the
system, or please the percentage going up, and focus less on the guarantees that
tests are providing them. <strong>This does not help us deliver better products to end
users.</strong></p>
<p><a href="https://twitter.com/KentBeck/status/812703192437981184">Code coverage percentage is a useless
metric</a>. There is no way
to know what percentage of code written is code your end users actually care
about when that percentage is derived from synthetic traffic. You may write a
continent of code, but only a thousandth of that code may actually be hit by
users. If you are using code coverage to tell you that you have greater than
zero percent code coverage than you have a code organization issue or there is
the possibility that many or all of your tests are false positives.</p>
<p>Here's a different approach: instrument your application to track invocations of
code paths. You can do with this tracing, structured logging, profiling replayed
traffic, etc. The technique employed doesn't matter but what does is determining
what is valuable and what is dead. Regardless of collecting metrics, you will
always need to consider this <a href="https://kentcdodds.com/blog/how-to-know-what-to-test">from a human
perspective</a>.</p>
<p>Detractors may argue that code that doesn't immediately show usage should not be
hastily deleted. They are partly right. If things are early on at your company,
doing eyeball statistics may be fair but eyeball statistics is not real
statistics. Practicing some basic statistical understanding is always in order
for any kind of analysis. It may take time to reach a statistically significant
result and whether one is reached should, more often than not, drive your
decisions. As noted we need to exercise judgement despite what the numbers may
tell us. Perhaps the piece of code in question is a critical piece of error
handling that is rarely executed, for example, or maybe the code is serving a
particularly infrequent, but high-paying, user base.</p>
<p>I'd like to stress that I am <strong>not</strong> saying that testing is a pointless errand.
What I am saying is that <strong>code coverage is fool's gold</strong>. Tests take more
effort to create because developers must check that a test is actually testing
what you think it's testing. <a href="https://stackoverflow.com/questions/153234/how-deep-are-your-unit-tests/153565#153565">Testing is a part of one's confidence
level</a>
in what they ship, and when we assert important properties of a system are
upheld you boost that confidence level. <strong>Don't buy into the idea that coverage
is going to lead to a correct system by default.</strong> Be vigilant with you tests
and instrument your application.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Errors Across a Boundary</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/errors-across-a-boundary.html</link>
      <guid>https://justanotherdot.com/posts/errors-across-a-boundary.html</guid>
      <pubDate>Fri, 27 Sep 2019 21:10:01 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>There is a line across our systems we shall call the boundary. On one end of the
boundary are the consumers and on the other side are the providers. This
boundary is what we are accustomed to calling an interface. Interfaces are the
embodiment of the dance needed to cross the boundary. The interface may have
adapters on either side whose purpose is to munge details of the internals into
this known language of communication. This way internals can continue working
without the fuss of the protocol driving their decisions.</p>
<p>Things go wrong. But when they do developers tend to clump everything up as a
single form of error. Errors are about reporting mistakes or complications. A
better name compiler writers have been using for years is 'diagnostics'; they
should help diagnose a particular problem by being part of the symptoms an
ill-behaving service might demonstrate. <strong>As such, when an infraction occurs you
want to know who is the offending party. <em>Are we holding it wrong or are you?</em></strong></p>
<p>Borders on your errors make clarify what the fix is by knowing who should be
performing the correction. This might mean the speech of diagnostics changes. A
person hacking on some code is much more accustomed to cryptic messages from a
compiler than an average person using a web interface to access their bank who
doesn't understand how any of this is rigged up.</p>
<p>Clearly delineate your errors and you'll know better if something is a mistake
or a matter of environment, if it is something a maintainer needs to worry about
or a blunder from usage. There are many styles to error handling but this
approach does not impact which style you end up using. You can use this whether
it is error codes, exceptions, or values. This is a matter of organisation.</p>
<p>Systems architecture itself can largely be seen as a form of organisation.
Conceptual partitions, domain concerns, and our pursuit for pieces that compose
drive this organisation. Independent the layer of granularity the focus on
organisatoin is always the same. <strong>When things go wrong, tell everyone which
side of the fence the mistake or complication came from.</strong></p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Fool's Gold, An Introduction</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/fools-gold.html</link>
      <guid>https://justanotherdot.com/posts/fools-gold.html</guid>
      <pubDate>Sun, 22 Sep 2019 15:37:09 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Developer's are a big target for what I call &quot;fool's gold&quot;. It's the hope that a
piece of tech can solve all of our problems that keeps us going with the bait of
new tech. Solutions tempt despite us knowing better. An experienced software
developer realizes that <em>everything</em> has strengths and weaknesses which we call
&quot;tradeoffs&quot;, but plenty of developer's don't realise this yet or are in denial.
This article is an introduction to the concept that plenty software and services
are sold as panacea but anything sold as panacea should be considered with
caution.</p>
<p>Let us discuss two ends of an argument first. There is the camp of <a href="http://boringtechnology.club/">choosing
boring tech</a> and <a href="https://www.intercom.com/blog/run-less-software/">running less
software</a>. This camp says that
cognitive load and operational costs are distractions for teams whose primary
focus ought to be the product they are building that makes them profit. By
running less software you are curbing the desire to have a bijective mapping
between problems to solutions where the relations are each their own distinct
solutions. Think about it this way, if you have N many devs and M many distinct
solutions for your problems, you have three particular cases to consider</p>
<ol>
<li><code>N &gt; M</code>: devs can't be experts except for some subset of the total pool of
technology. Ditto (and more importantly) maintenance and operations. More
than one dev has to be allocated per tech to make this work (pigeon hole
principle).</li>
<li><code>N = M</code>: every dev can own a particular piece of tech and grow with. Devs may
get bored and want to congregate on other pieces of tech. If this happens you
wind up with <code>N &gt; M</code>, effectively.</li>
<li><code>N &lt; M</code>: Devs can congregate around pieces of tech without much fuss. They
have freedom to pick what they like most (within a certain degree depending
on the delta <code>M-N</code>). Maintenance and operations is bearable as the whole team
can participate and not have to spin plates.</li>
</ol>
<p>Then there is the camp of constant agitation. A company goes under if it's not
constantly pushing to optimise for end users and reducing costs. <a href="https://www.goodreads.com/book/show/28592994-simplify">Some even
argue you can only pick one of these two optimisations</a>. Enterprises claim to
avoid this complication because their golden goose is sitting pretty, but the
reality is that any revenue generating organisation has to constantly push
themselves into the future to compete. Technology is an enabler, it allows teams
to move faster by automating away toil, easing collaboration friction, and a
productive team means they can, hopefully, deliver user experiences that delight
or at a cost that is beats the competition.</p>
<p>All of this shuffling around comes at the cost of churn and bloat. Companies try
to sooth this issue by either by hiring more devs and/or performing lots of
migrations. <a href="https://en.wikipedia.org/wiki/Software_rot">Software rots</a>, which
can mean different things to different people, but I see it as the eventual
ineffectiveness of a piece of software as improvements are found in competing
solutions. That is to say, even though your software may not actually be getting
slower, it will definitely feel slower in the context of all neighboring
solutions getting faster. This is but one example yet other things like security
exploits, support for a particular version of a language or library, and so on
all work to disempower your application or system.</p>
<p>The reality is that we cannot simply pick one camp to be part of as professional
developers. We are paid to help companies continue to live and be better than
they were before we joined, all within the confines of the ethics and legalities
we are bound to. <strong>We cannot sit still but we can't move too much!</strong> Some have
suggested things like a <a href="https://www.shimweasel.com/2018/08/25/novelty-budgets">novelty
budget</a> to support
keeping the platform largely stable while pursuing new ways of handling
constantly arising issues.</p>
<p>This article isn't meant to attack particular companies or pieces of tech or
practices despite those practices that carelessly hold on to the past or
endlessly throw it out for the new. The core intent is to encourage critical
thinking and consideration of tradeoffs when problem solving. Weigh your
options! You cannot make decisions purely by reading and watching, nor can you
make a choice by trying everything as there simply isn't the time. Certain devs
learn to do cheap experiments at work or at home but this can have the pitfall
of comparing a toy project a success that may not handle the scale of an
industrial grade application. This sort of scrutiny is part of the weighing
process.</p>
<p>If anyone tells you they're going to make you rich, they're getting rich off of
you. <strong>Take marketing with a grain of salt and throw out the fool's gold!</strong></p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Pushing the Boulder</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/pushing-the-boulder.html</link>
      <guid>https://justanotherdot.com/posts/pushing-the-boulder.html</guid>
      <pubDate>Thu, 19 Sep 2019 20:15:00 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Imagine you have a giant boulder in front of you. This is the task you want to
undertake. You know you need to push it to get it moving but you also recognise
that the inertia you'll need to overcome at first is substantial. You
unfortunately think that pushing the boulder will <em>always</em> take this much force.
The truth is, if you can get the boulder moving, keeping it in motion only takes
many small, infrequent pushes. The idea behind pushing a boulder is the same as
<a href="https://jsomers.net/blog/speed-matters">fast systems incurring usage</a>. Want to
improve your coding? Code. Want to read more? Read. <strong>Action begets action</strong>.</p>
<p>When you try to acquire knowledge there is always a pool of unknown-unknowns
whose size is, itself, infinite. We are constantly refining things from the
unknown-unknown pool into known-unknowns while we learn. One way to acquire
knowledge is to read. I recently joked on twitter about speed reading:</p>
<blockquote class="twitter-tweet">
  <p lang="en" dir="ltr">
    Heres how you speed read: flip through a book and tell people youve read it.
  </p>
    &mdash; Ryan James Spencer (@_justanotherdot)
  <a href="https://twitter.com/_justanotherdot/status/1170118831219474433?ref_src=twsrc%5Etfw">
    September 6, 2019
  </a>
</blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>But in all fairness, this is a sensible approach. Some relate knowledge
acquisition as panning for gold. I think that's a misguided analogy because
panning for gold is <em>slow</em>. Yes, we want to find the gold and we're not quite
sure where it is, but no modern mining outfit would pan for gold these days.
They would use large machines that could tear, demolish, crush, rip, sift, sort,
detect, and on and on in orders of magnitude time more quickly than someone
holding a pan to a river.</p>
<p>There is a technique involving multiple passes of reading. I learned this first
when I got into <a href="https://www.elsevier.com/connect/infographic-how-to-read-a-scientific-paper">research
papers</a>.
It's also the basic idea behind <a href="https://www.goodreads.com/book/show/567610.How_to_Read_a_Book">How to Read a
Book</a>. You read a
first pass involving the abstract/introduction, the conclusion, and then you
skim, noticing headlines, captions, diagrams, and all the other top-level items.
You follow suit with other passes increasing in detail if you haven't already
dropped interest in the material. Basically, actions get prioritised by cost,
the lower cost stuff coming first. <strong>Don't pan for gold, mine for it with
machines.</strong>.</p>
<p>Take a book you want to get through. Try to just flip through it. Once you're
done skimming, try to concentrate on the primary points you've just become aware
of; your known-unknowns. In your future passes, try to hone in on the things you
care about more. Reading books out of order is actually fine for a lot of
material if the first pass didn't tell you enough of what you need to know. What
this does is change your definition of done.</p>
<p>There is always signal-to-noise and it's largely why there are diminishing
returns which is both true for what we produce as well as what we consume.
Ruthlessly closing browser tabs to reduce distraction, keeping your output high
and frequent, reading books in multiple pass, and on and on. Do things to put
you in an uncomfortable state. Make tons of little changes and skim content
frantically going back for more when you need it instead of sitting around
dreaming or scheming. Be a giant machine. Tinker like a maniac. Push the
boulder.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Lightweight is Beautiful</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/lightweight-is-beautiful.html</link>
      <guid>https://justanotherdot.com/posts/lightweight-is-beautiful.html</guid>
      <pubDate>Sun, 08 Sep 2019 20:03:00 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>We are all guilty of having done the &quot;edit a little bit, go to another terminal,
hit the up-arrow a number of times, fire off the found command&quot; dance over and
over again at some point in our careers. It's such an easy automation to remove
these steps! IDEs give this to you because they know best about when a buffer or
a file has been saved or modified. Indeed, people go crazy for IDEs because they
provide information directly in the editor.</p>
<p>Even though things like VSCode and the Language Server Protocol have done a
tremendous amount of work in reducing complexity around both the setup and
maintenance of an IDE environment since days of yore, there are still times when
the array of plugins and external tooling 'go wrong'. Bugs or even the nefarious
'opinionated' feature can cripple a dev's workflow. Fixing these issues isn't
necessarily time poorly spent but it's hard to shrug off because the integration
is so tight-knitnow that you depend so heavily on the plugin, switching to
something different is slow. Here's an approach I think is a bit more
<a href="https://www.goodreads.com/book/show/13530973-antifragile">antifragile</a>, to use
a term coined by author Nassim Taleb. An antifragile approach is distinct from a
fragile approach because</p>
<ul>
<li>a fragile approach will break when encountering an unexpected event and</li>
<li>a robust approach does not change when encountering an unexpected event but</li>
<li>an antifragile approach gets better as it encounters unexpected events</li>
</ul>
<p>I'm a bit spartan when it comes to coding. I do this largely because I've had a
lot of tooling mistreat me and this has taught me that the weight of a tool or
process is a matter of its cost. <strong>Lightweight is beautiful</strong>. By lightweight we
mean cheap to replace not 'small' and 'simple'. Sometimes you do need beastly
machines because you can't bore a hole into the earth to make a tunnel with a
few workers armed with spoons. <strong>Lightweight functionality is preferable to
mindless adherence to a given tool or process.</strong> In other words, it's
antifragile to be prone to lightweight .</p>
<p>So here is the setup; two terminals or windows or whatever you like to use. In
one is your source code and in the other is your tests, linting, typechecking,
you name it. Either they are side-by-side or perhaps there is a dead-simple way
for you to swap between them. You can have several of these going at once and in
fact I recommend it. If they are resilient to files changing from version
control that's even better. <strong>It's important they stay <em>relevant</em> and by that I
mean obvious and up-to-date.</strong> When we talked about
<a href="https://www.justanotherdot.com/posts/stdout_is_forever.html">debugging</a>, this
is the very loop I was referring to. With this in place you can progressively
slap in debugging statements and changes while watching the results come seeping
out.</p>
<p>There are plenty of testing frameworks and tools that support automatically
running tests or commands on file save. <code>jest</code>, <code>PyTest</code>, <code>cargo watch</code>, <code>go watcher</code>, <code>mix watch</code>, you name it. This sets up an automatic link between the
file(s) being edited and the suite of tests to run. Just alleviating the step
where you need to context switch is the small win here and is not the point.</p>
<p>With this approach, if anything like a plugin or even a specific command in the
pipeline you setup goes awry, you can cheaply swap it out for an alternative.
<strong>This is the best kind of feedback loop as it favours tinkering and
experimentation.</strong> Lately because I mostly write Rust at work, I tend to use
<code>cargo watch</code> but one incredibly handy, language agnostic tool is
<a href="http://eradman.com/entrproject/"><code>entr</code></a> which is useful when I foray into the
unknown or uncommon. Let's say I find that I need to run a particular pipeline,
I can do that by running,</p>
<p><code>rg -l . | entr -cs 'cmd1; cmd2; cmd3'</code></p>
<p>Now if <code>cmd2</code> is being a pain, I can take it out of the pipeline quickly or even
choose to replace it. Perhaps it's a new project and you are furiously adding
files, you could set up a governing loop that watches all files and tears down
the loop if that changes some known set.</p>
<p><code>while true; do ls src/* | entr -d cmd; done</code></p>
<p>Most people never even think of doing a <code>git bisect</code> because of the pain of
steering the interaction with the bisect and running the tests to confirm the
first failure in the regression suite. This isn't just the cost of swapping
between terminals. Sometimes it can be tests that are flaky and come up as false
positives or maybe a test suite is slow to run but there is no way to neatly run
a subsection without commenting out code. With this approach, however, we can
focus on the steering and watch what happens in the other window. If flaky or
slow tests show up, we can comment them out and move on (<code>git clean -fdxx</code> is
handy for these sort of tempermental changes if you tack on it on the back of
the pipeline you construct).</p>
<p>If a great style guide favours <a href="https://www.justanotherdot.com/posts/a_plea_for_style_guides.html">deletability and ease of
modification</a>,
this approach is stressing for <strong>replaceability</strong> for producing tinker-friendly,
antifragile feedback loops. If you lower friction you'll always beget action,
and <a href="http://jsomers.net/blog/speed-matters">fast systems incur usage</a>.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Stdout is Forever</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/stdout-is-forever.html</link>
      <guid>https://justanotherdot.com/posts/stdout-is-forever.html</guid>
      <pubDate>Wed, 04 Sep 2019 15:49:00 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Debuggers are worth their weight in gold but stdout is the diamond in the rough.
All the tools we have to pinpoint problems such as REPLs, automatic tracing,
stacktraces, and even printing to stdout wind up being about two things:
<strong>poking</strong> and <strong>prodding</strong>.</p>
<h2>A useful macro or two</h2>
<p>Rust has the <code>dbg!</code> macro and I love it. It's short enough to type and it shows
you what file you are in, line you are on, and how the code looks plus its
value after evaluation. e.g. <code>dbg!(dbg!(12) == dbg!(1 + 11))</code> will print</p>
<pre><code>[src/main.rs:2] 12 = 12
[src/main.rs:2] 1 + 11 = 12
[src/main.rs:2] dbg!(12) == dbg!(1 + 11) = true
</code></pre>
<p>Two important quirks with this are,</p>
<ol>
<li>No arguments passed means you just get the file and line number</li>
<li>The code still behaves the way it used to except now you have tracing</li>
</ol>
<p>This gives us just enough information to be lethal. This is possible because
this expands at compile time and can be replicated in other languages that have
macro support. This is a source transformation and we can't easily use a
function because our line number will always be the line number of the function,
not the calling site. As such, one option is to write it as some repeated action
in your editor of choice. Imagine you have the following go code in front of
you,</p>
<pre><code>func AddOne(x Int) Int {
  return x + 1
}
</code></pre>
<p>and you want to lay down some tracing so you highlight the <code>x + 1</code> and hit a
keyboard shortcut which transforms the code into the following,</p>
<pre><code>func AddOne(x Int) Int {
  fmt.Printf(&quot;[src/main.go:8] x + 1: %#v&quot;, x + 1)
  return x + 1
}
</code></pre>
<p>We could have also used the
<a href="https://golang.org/pkg/runtime/#Caller"><code>runtime.Caller</code></a> function to get
filename and line number but we can get that spliced in via our editor to avoid
an import. If you are curious what the <code>runtime.Caller</code> code looks like here it
is (and, yes, I'm ignoring error handling here since this is intentionally
throwaway code):</p>
<pre><code>func AddOne(x Int) Int {
  _, file, line, _ := runtime.Caller(0)
  fmt.Printf(&quot;[%v:%v] x + 1: %#v\n&quot;, file, line, x+1)
  return x + 1
}
</code></pre>
<p>The advantage with the above is now we can take our print lines and move them
around at will and we won't have to tweak the filename/lineno combo.</p>
<h2>Poking</h2>
<p>Sometimes the fastest way to get at a problem is by writing test cases that flex
assertions about the functionality in question. Other times that's not as fast
because the logic might rely on other systems, e.g. integration tests. In those
cases, if you have stacktrace support you might find it useful to panic/throw if
particular assertions aren't met. When that fails you are probably interfacing
with code that is covering up exceptions or panics, say a piece of library code
that takes your code as a callback. You could try stubbing in your own forked
version of the code (scripting languages tend to make this easy) or you could
turn to building your own stacktrace. You iteratively apply print statements in
the following fashion,</p>
<pre><code>fn foo() {
  dbg!() # beginning
  &lt;snip&gt;
  dbg!() # middle
  &lt;snip&gt;
  dbg!() # end
}
</code></pre>
<p>With <code>dbg!</code> this is really easy because I don't have to think
about what to pass to the printing function since <code>dbg!()</code> simply
emits the filename and line number. In languages that may not have this I've
done <code>printf(X)</code> where X = &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, and so on.</p>
<p>With this format in place you can use binary search to figure out where you need
to apply more printing statements on each subsequent run. If, however, your
tests or program take a long while to run it can pay to do upfront work but
perhaps limiting yourself to an arbitrary depth to avoid spending too much time
on tracing that won't pay off.</p>
<h2>Prodding</h2>
<p>You can load your <a href="https://jvns.ca/blog/2018/04/28/debugging-a-segfault-on-linux/">core
dumps</a> into
<code>gdb</code> and explore the call stack after a segfault among all sorts of other cool
things that debuggers allow you to do, or you can rig up systems to
automatically provide tracing, such as in <a href="http://erlang.org/doc/man/dbg.html">erlang or
elixir</a> but hopefully this article has shown
that stdout gives you powerful debugging functionality since we already have
access to executing the program and manipulating its source. We can print
assertions to see if they hold up or mess around with alternative solutions that
may work if the problem is clear. Stdout isn't always the fastest but it's
<em>lightweight</em> which makes it invaluable as it can circumvent a lot of
preparatory work. You can pair this approach into a feedback loop, too, to
reduce duplicated work such as running the tests or program over and over again.
In a future article I'll discuss ways to do this in a range of languages and
environments but at least we've set the tone for some thinking about how to
improve what we spit out while you hack to give you a better understanding of
what's going on under the hood.</p>
<h4>Acknowledgements</h4>
<p><em>The name of this post is inspired from <a href="https://twitter.com/bodil/status/878563460233277440?s=20">Bodil
Stokke</a> when
responding to what &quot;What are everyone's fave debugging tools for languages you
write code in?&quot;</em></p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>A Love Letter to Principles</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/a-love-letter-to-principles.html</link>
      <guid>https://justanotherdot.com/posts/a-love-letter-to-principles.html</guid>
      <pubDate>Sun, 01 Sep 2019 18:43:00 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Programmers make assertions all the time with a wide range of utilities: tests,
types, written prose, and so on. Assertions are how we establish some ideal of
the system at any particular scope. Maybe there is a requirement that all
services in an ecosystem do not rely on each-other's internal implementation
details or that exceptions should not be thrown in library code. Perhaps a team
decides that despite correctness being of the utmost importance, it doesn't give
anyone the right to be an asshole.</p>
<p>Ray Dalio <a href="https://www.goodreads.com/book/show/34536488-principles">wrote a whole book on the matter of
principles</a> and feels
they are at the center for decision making and iterative improvement,</p>
<blockquote>
<p>Principles are fundamental truths that serve as the foundations for behavior
that gets you what you want out of life. They can be applied again and again
in similar situations to help you achieve your goals.</p>
</blockquote>
<p>My likening of principles to assertions is superficial. Assertions are, in my
mind, simply the application of principles. We <em>assert</em> that an invariant is
upheld during each iteration of a loop, that some postcondition is still met
after execution of a function, that a system is composable and modular from
applying principles sat around the locus of flexibility. In some cases these are
machine-checked, in others they rely on humans to verify. Regardless of checking
they are still present.</p>
<p>When you have autonomy in a team it is key that you take initiative to achieve
excellence. The problem with initiative is precisely an issue of what to work
on. Principles provide a 'north star' metric that enables you to say &quot;is the
error handling in this code dividing concerns between internal versus external
concerns?&quot; or possibly &quot;do people feel supported and empowered to make the
changes they need ot make across the broader company?&quot; <strong>With principles we can
scrutinize, but also work towards, some ideal. Hence our application of these
ideals is the work we undertake.</strong></p>
<p>One could easily take principles from elsewhere but that would leave us with
little to no understanding of how to form our own principles that best suit our
needs and desires. What is the trick? The process I'm about to describe is
probably not the only way to go about carving up principles but it's one that
has worked for me and others.</p>
<p><a href="https://www.justanotherdot.com/posts/a_love_letter_to_feedback_loops.html">Feedback
loops</a>
are how we take risks and reflect. Experiencing this cycle for long enough means
we start noticing
<a href="https://www.justanotherdot.com/posts/a_love_letter_to_patterns.html">patterns</a>
that can take the form of principles. A principle is really just a pattern that
can describe some ideal clearly. You make failures (by way of decisions), you
learn from failures (by way of reflection), you get principles.</p>
<p>I've been thoroughly enjoying <a href="https://www.goodreads.com/book/show/16158601-turn-the-ship-around">Turn that Ship
Around!</a> and
one of the mentioned mechanisms towards getting a &quot;leader-leader&quot; culture is
changing the focus from avoiding errors to achieving excellence. In this same
manner I think the best principles are formed. When I talked about <a href="https://www.justanotherdot.com/posts/make_a_home.html">treating
your codebase as a home you want to
build</a>, this 'idealised
life' that a home represents is the same as these principles I've talked about
here. In that sense, from a programmer's perspective, excellence is really just
the code and the culture we wish to embody.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>A Love Letter to Patterns</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/a-love-letter-to-patterns.html</link>
      <guid>https://justanotherdot.com/posts/a-love-letter-to-patterns.html</guid>
      <pubDate>Fri, 30 Aug 2019 21:47:00 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Patterns are how we tend to carve up the world around us. Like <a href="https://www.justanotherdot.com/posts/a_love_letter_to_feedback_loops.html">feedback
loops</a>,
they are everywhere once we start noticing them. Roger Antonsen <a href="https://www.ted.com/talks/roger_antonsen_math_is_the_hidden_secret_to_understanding_the_world">feels that
mathematics is all about discovering
patterns</a>.
When the pattern is discovered, we come up with a language to describe that
pattern and give us a handle on playing with it. When we have both of those we
can start tinkering and playing with assumptions.</p>
<p>Patterns are usually globbed together with abstractions. Abstractions are
usually misunderstood. What people tend to call abstractions are actually
indirections. Abstractions are actually the rough structure or form of an idea
or concept. The abstraction of a program is a specification for the program
itself. I don't think patterns and abstractions are the same.</p>
<p>So how are they useful in your day to day? You may or may not realise you do
what I'm about to describe but I'm fairly certain most of us do this regardless
of us being conscious of it. Becoming more conscious of this process makes it
more powerful, so let's shed some light.</p>
<p>When you are working, there is generally a discovery of patterns. You build a
trust framework around these patterns; if a pattern is useful, you keep using
it. Perhaps a pattern betrays you. Maybe you sit and dabble with it to make it
work again at the same capacity it used to serve you. If you're ruthless enough,
you ditch the pattern entirely and move onto new ones.</p>
<p>Consider a scenario where you are rigging up some code that needs to walk across
a directory and perform an action on every file. You see a third party library
is more ergonomic than the standard library so you use it, instead. If you're
conscious about this as a pattern, you'll trust it and reuse it tirelessly until
it stabs you in the back. It <em>doesn't</em> pay for you to go fiddle around with the
standard library functionality or some other third party library because you'll
be wasting time. This is also why trying to 'save' a forsaken pattern can come
with a high cost. It <em>does</em> pay to generally treat patterns as throwaway in the
spirit of speed. There's tons of these every day, in every language, and even
beyond coding, so you will not run out if you decide a pattern isn't delivering.</p>
<p>As patterns age and you spend some time thinking about them you'll find you can
increasingly discover ways to generalise them further. Patterns are amazing
because they let you turn all the boilerplate into habits which means you'll
have the mental room to solve other problems with deliberate attention.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>A Love Letter to Feedback Loops</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/a-love-letter-to-feedback-loops.html</link>
      <guid>https://justanotherdot.com/posts/a-love-letter-to-feedback-loops.html</guid>
      <pubDate>Thu, 29 Aug 2019 21:28:00 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Feedback loops are everywhere and they're <strong>awesome</strong>. In essence, whenever
there is some system with inputs, outputs, and some readjustment based on the
outputs of the system, that's a feedback loop. The analysis of the output 'feeds
back' to the input and the system is now different, and hopefully better,
because of it.</p>
<p>what about refinement of the feedback loops themselves? Truly productive people
not only recognise feedback loops but relentlessly modify them so they reach
their full potential. We tend to call this act of refinement as making the
feedback loop 'tighter', although that might not mean making the delay between
some analysis and the adjustment shorter, <em>per se</em>.</p>
<p>For example, you might code and run something like <code>cargo watch</code>, <code>jest</code>,
<a href="http://entrproject.org/"><code>entr</code></a>, et. al. to avoid having to switch to your
terminal, find the test command, and hit enter. Dropping those steps makes the
loop 'tighter' and means you get feedback (the state of the tests) far sooner
(and automatically).</p>
<p>Or perhaps you are a car manufacturer who gets reports from the dealerships
about sales to help you better gauge how many to make next. If you react too
quickly you might wind up producing a surplus right before a lull in the market.
<a href="https://www.goodreads.com/book/show/3828902-thinking-in-systems">Thinking in Systems: A
Primer</a>
discusses this same case.</p>
<p>Refining a feedback loop is really a matter of finding the sweet spot where it
delivers the most value.</p>
<p>If you're mathematically inclined or curious, there is <a href="https://en.wikipedia.org/wiki/Control_theory">control
theory</a> for designing feedback
loops in mechanical and dynamical systems. This <a href="https://www.youtube.com/watch?v=O8xLxNje30M">AWS
re:invent</a> talk gives a good
practical application of the control theory to software with respect to the
creation of S3.</p>
<p>When it comes to feedback loops for humans, we need to take risks to make
failures to learn. We learn more from our failures than our successes, but we
can't make huge failures all the time. <a href="https://www.goodreads.com/book/show/34536488-principles">Ray Dalio's
Principles</a> describes
the process as reaching for goals (taking risk), experiencing failure
(inevitably), learning from the failures (growth), and then upping the audacity
of said goals. This is pretty cool because it means it's not only OK to
experience failure but it's crucial to achieve what we truly want in life. The
sweet spot is experiencing enough failure so as to allow one to come back with
big dreams.</p>
<p><a href="https://increment.com/testing/i-test-in-production/">Charity Majors reminds
us,</a></p>
<blockquote>
<p>Its better to practice risky things often and in small chunks, with a limited
blast radius, than to avoid risky things altogether.</p>
</blockquote>
<p>You can't think through everything. Sometimes you'll need to tinker; take bold
risks, make mistakes, refine, and repeat.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>A Plea For Style Guides</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/a-plea-for-style-guides.html</link>
      <guid>https://justanotherdot.com/posts/a-plea-for-style-guides.html</guid>
      <pubDate>Wed, 28 Aug 2019 20:16:00 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>You commonly hear two particular attributes that drive style guides, and,
subsequently, automatic formatting tools: 'consistency' and 'readability'. The
argument goes that a developer reads a codebase far more than any other
interaction.</p>
<p>Now, you could always take a codebase that has a style and use <a href="https://github.com/antlr/codebuff">machine learning
to generate a formatter</a> to keep things
'consistent' and 'readable'. This would get around the subjective definition of
readability because it's what the team picked through usage. Some feel that a
community driven style guide is ideal because then the codebase's 'readability'
is 'consistent' with the larger ecosystem, so formatting tools should simply be
blindly adopted.</p>
<p>Unfortunately, they are focusing on the wrong thing.</p>
<p>I have read a lot of code. I care about it as a practice and I like teaching
others how to do it, but I don't think it's the right metric for a style guide.
Bar things like the <a href="https://www.ioccc.org/">obfuscated C contest</a>, minified
markup and javascript, and many other mind-melting formats , most code I see is
actually quite 'readable'. Consistency is no better because you can have a style
that is consistently spaghetti.</p>
<p>In truth, <strong>developers change code far more often than they read and write new
code and they sure as hell should be <em>deleting</em> code with a frantically high
frequency, as well, if they aren't already.</strong></p>
<p>About two years back someone mentioned <a href="https://elm-lang.org/docs/style-guide">the elm style
guide</a> to me. The focus on
ease-of-modification <em>for a human</em> was eye-opening. With this mindset, alignment
was pointless. What good would it do a developer to re-align things after making
a change than to simply let them make the change by itself, communicate it
simply to their peers, and get it into master ASAP?</p>
<p>Then, later, another practice I adopted was adding newlines to assignments/let
bindings, taken from a team of brilliant software engineers. Every time I wrote
an <code>=</code> I would hit enter, allowing the name of the thing and its guts to be
distinct. The contents of the variable could be expanded, shrunk, removed
entirely, turned into an error, whatever. The name could be changed to better
suit constantly shifting needs and not highlight the guts in code review. It was
a handy pair.</p>
<p>I found sometimes having stuff as modifiable or deletable meant you would get
the other for free, similar to what people claim about consistency and
readability. In the end, the specific practices aren't important here. What is
important is that gaining momentum and keeping up against inertia is pivotal
when keeping a project relevant and rot-free. And, if you do the same thing
everywhere, you'll inevitably get a 'consistent' codebase, anyways!</p>
<p>Next time you write a style guide, try to think about the sea of changes that
will need to take place and the stuff that will get old and need to die before
you consider your codebase as another magnum opus.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>May You Be The Author of 2^N Programs</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/may-you-be-the-author-of-two-to-the-n-programs.html</link>
      <guid>https://justanotherdot.com/posts/may-you-be-the-author-of-two-to-the-n-programs.html</guid>
      <pubDate>Mon, 26 Aug 2019 20:00:00 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>The sheer propensity of articles detailing productivity tips for software
developers under the auspices of them becoming better employees is alarming.
What about our mental health? Why not more articles about our productivity from
the point of view of improving our ability to deal with discomfort, burn out,
imposter syndrome, and so on?</p>
<p><strong>Progress is key.</strong></p>
<p><a href="http://jsomers.net/blog/speed-matters">Speed matters</a> because it principally
enables us to make progress with our work and our life. Half-finished projects
weigh on us like mangled fruit on a dying tree. Project deadlines sneer at us
right around the corner and we put unfair stress on ourselves to both reach a
deadline <em>and</em> achieve excellence. <strong>We cannot be happy and, therefore, productive
if we are unable to be flexible. The only way is to accept mess.</strong></p>
<p>The book <a href="https://www.goodreads.com/book/show/187633.Art_and_Fear">Art and Fear</a>
is chiefly about two things:</p>
<ul>
<li>Proliferation and practice are the way to improvement</li>
<li>Successes can only be determined based on one's own history</li>
</ul>
<p>One analogy that is given in the book is a pottery instructor who divides his
class in two. Half of the class will be judged by quantity and the other half by
quality. In the end, it is the quantity group that has the best work through the
simple act of constantly learning from their failures. Reflection and planning
<em>are</em> crucial but the quantity-based group's ability to accept the mess that
comes with failures is what drives their progress. Fantastic! All we need to do
is just constantly crank things out and we'll be masters of our medium in no
time.</p>
<p>Except for some of us mess instills great discomfort.</p>
<p>At the beginning of the year I went to therapy. I was burnt out from work and
other stressors in life. Many sessions later I am diagnosed with Obsessive
Compulsive Disorder, which in some ways was a shock and in others not a
surprise. Eventually, exposure therapy comes up as a tool to help tackle the
anxiety and stress from parts of my affliction. There I was, sitting with my
discomfort, watching it, not trying to solve it nor run away from it, and sure
enough, the discomfort would melt away with time. I started convincing some part
of myself that the discomfort I was dredging up was <em>not</em> based on fact and I
found myself able to do things I had been so slow or entirely unable to do for
ages.</p>
<p><strong>It has dawned on me that sitting with the discomfort of what you produce is part
of learning from the failures.</strong></p>
<p>You <em>can</em> defer some decisions for later and put in rudimentary solutions in the
meantime. You <em>will</em> probably save time by making progress in this manner that
will allow you to revisit those same problems you deferred. Sure, this may not
always be the case for those trapped in <a href="https://cutle.fish/blog/12-signs-youre-working-in-a-feature-factory">feature
factories</a>,
but that's an organisational issue rather than a personal one. You owe it to
your mental health to grow more flexible by accepting mess.</p>
<p>May you the author of 2^N programs.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Move Fast and Tuck Code Into the Shadows</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/move-fast-and-tuck-code-into-the-shadows.html</link>
      <guid>https://justanotherdot.com/posts/move-fast-and-tuck-code-into-the-shadows.html</guid>
      <pubDate>Fri, 23 Aug 2019 21:51:00 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Migrations are a part of life as a dev. They help <a href="https://lethain.com/migrations/">cut down tech
debt</a> but they can be risky. It's always less
risky merging in <em>new</em> and <em>different</em> sets of changes rather than changing code
in-place. This buys you time. <em>You</em> gain the control over the switch granted
switching doesn't adversely affect some shared, mutable store of data.</p>
<p>The <a href="http://sevangelatos.com/john-carmack-on-parallel-implementations/">parallel implementation
approach</a> is
brilliance incarnate; you keep a functional reference implementation and you
copy it as your 'experimental' version whose sole aim is to eventually replace
(and hence become) the new reference. However, Carmack hits a good point,</p>
<blockquote>
<p>It is often tempting to shortcut this by passing in some kind of option flag
to existing code, rather than enabling a full parallel implementation. It is
a grey area, but I have been tending to find the extra path complexity with
the flag approach often leads to messing up both versions as you work, and
you usually compromise both implementations to some degree.</p>
</blockquote>
<p>I am keen to start experimenting more with the Carmack approach, though. Some
things I've already thought about:</p>
<ul>
<li>Having a duplicated directories messes up navigation for a lot of editors and
is unnecessary bloat</li>
<li><code>git flow</code> styled approaches and any vcs-based approach will never work
because it lends into the 'change in place' idea by merging the reference with
the experiment</li>
</ul>
<p>Otherwise, there are many ways to define clear boundaries between the reference
and experimental implementation. The most popular solution out of many is
feature flag services but I recommend switching between whole modules rather
than having a lot of logic caked into modules to check flags. Keeping flags
macro and mutually exclusive is important because it means changes are kept
cohesive and conflict free. One thing people tend to forget about is the
original feature-flag: versioning. In the end it doesn't matter which technique
you employ so long as you can 1. <strong>toggle between changes</strong> and 2. <strong>keep
differences clear</strong>.</p>
<p>You can start something similar to this approach by focusing on leaving written
code in a disconnected state but being aggressive about it finding its way to
master. This is healthy because it will change the incumbent attitude of
&quot;production means done&quot; to &quot;production means refinement&quot;. I like this approach
and do it as often as I can remember to because it means PRs are kept small
(great for code review) and when I finally do want to rig everything up I can
focus squarely on the plumbing, rather than juggling the correctness of the core
implementation <em>and</em> the coupling to the rest of the system.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Make a home</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/make-a-home.html</link>
      <guid>https://justanotherdot.com/posts/make-a-home.html</guid>
      <pubDate>Thu, 22 Aug 2019 20:49:00 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>I'd like to preface this article that analogies are rough comparisons. That is
why, after all, they are analogies. We say that one thing is <em>like</em> another, but
it is not to say they are the same, point-for-point.</p>
<p>The analogies to construction and architecture in software are abundant. We say
that we are 'building' a codebase. We assign people the role of 'architect'. One
camp of people regale <a href="http://www.laputan.org/mud/">The Big Ball of Mud</a>,
esteeming the progress they make as their rationale for constructing a wobblying
shantytown. Another camp sit high in <a href="https://blog.codinghorror.com/ivory-tower-development/">The Ivory
Tower</a>, planning the
sanctuaries that may give their inhabitants stamina as they rest in its glory.</p>
<p>In Architecture of Happiness, Alain de Boton waxes,</p>
<blockquote>
<p>Beneath the pleasure generated by the juxtaposition of order and complexity,
we can identify the subsidiary architectural virtue of <em>balance</em>. Beauty is a
likely outcome whenever architects skillfully mediate between any number of
oppositions, including the old and the new, the natural and the man-made, the
luxurious and the modest, and the masculine and the feminine.</p>
</blockquote>
<p>What analogy sits between these two extremes? Where is the balance between
progress and stamina?</p>
<p>I feel like it's building a home.</p>
<p>Recently, I watched <a href="https://www.youtube.com/watch?v=AxM9FYSs8V4">a man building his own log
cabin</a>, slowly outfitting large
portions while also doing his chores from day to day. You can tell the focus
placed on making it a lovely, warm place people can relax but also the
willingness to accept the mess where it need to be accepted. As Jonathan Blow
eloquently puts it in a <a href="https://www.youtube.com/watch?v=6XAu4EPQRmY">portion of one of his live
streams</a>,</p>
<blockquote>
<p>We are ignoring [a pointer problem] for now and we are making a note that that
problem needs to be solved. You don't [sic] so here's the thing, in a big
project you just don't have to solve every problem at once in fact if you try
you will not get very far at all. You'll just get crushed under the load under
all the things you have to do and of never getting anything done ...</p>
</blockquote>
<p>Jonathan goes on to state how he subdivides problems into ones he wants to
seriously tackle now, and ones where he is putting in a rudimentary solution so
long as it gains him progress. All of this, to me, is the same sort of balance
that comes in the mental idea of having one's own house.</p>
<p>Most likely several things are demanding ones attention for fixing; you might
need to get a wall repaired, perhaps a door is more important since it's
front-facing, and you need to rake out front and put out the trash. Despite all
this effort, you spend many relaxing moments in your home, recharging and
growing with the environment built up around you. Alain de Boton feels homes
represent our ideal lifestyles, and experienced programmers do the very same on
their codebases; they make it home not only for themselves but for others.</p>
<p>Maybe we all ought to make homes so we can grow and feel happy in them, without
sacrificing progress and stamina.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Custom Search Functionality for Coding</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/custom-search-functionality-for-coding.html</link>
      <guid>https://justanotherdot.com/posts/custom-search-functionality-for-coding.html</guid>
      <pubDate>Mon, 19 Aug 2019 16:10:36 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>This may not be revelatory to some, but it's a cool trick I use daily and I
thought I'd write about since it's managed to surprise enough colleagues and
friends when I've used it. Credit where credit is due, I was taught this trick
two years ago by Charles O'Farrell.</p>
<p>Firefox and Chrome both support this functionality but are setup differently.
Let's say you have a github codebase with a particular org (which are also,
confusingly, demarcated as users in github search). You want to find a repo
quickly; you can quickly go to your search bar and hit <code>repos a_project</code> (or in
the case of Chrome, <code>repos&lt;tab&gt; a_project</code>), hammer the enter key and you wind
up at <code>https://github.com/search?q=user%3Aorg+a_project</code>. How?</p>
<p>In both Chrome and Firefox, you can add a custom search engine by right-clicking
on the search 'bar' (form) you'd like to add, except in Firefox the mechanism
works via bookmarks and Chrome has the functionality as it's own thing (seems
like a first class citizen). There <em>are</em> custom search engines for Firefox you
can add (I've noticed I can add them for things like crates.io, docs.rs, amazon,
et. al.) out of the box given a specific version (I'm not sure which) of Firefox
but you'll still need to bookmark approach for most cases. Once you have the
search URL you care about just replace the term you searched for with <code>%s</code> and
all is well, e.g. <code>https://github.com/search?q=user%3Aorg+%s</code>.</p>
<p>Some other examples of uses are:</p>
<ul>
<li><code>code term</code> - similar to the <code>repos</code> keyword above but searches across all
repositories of an org for <code>term</code></li>
<li><code>(docs.rs|crates.rs|younameit) &lt;module&gt;</code> - looks for module documentation,
listing in some large store of knowledge</li>
<li><code>rstd term</code> - search for <code>term</code> in the rust std lib (handy when paired with
something like rust-tags so you can jump to definition inside of std in your
editor)</li>
</ul>
<p>The above are rust centric because it's what I've been in the headspace of but
you could easily set this up for things like hoogle, amazon, shortening things
like youtube to <code>y</code>, <code>hex.pm</code>, and so on. Personally, it's been empowering to
gain a handle on parameterizing search functionality with your address bar.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Reading Review for 2018</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/reading-review-2018.html</link>
      <guid>https://justanotherdot.com/posts/reading-review-2018.html</guid>
      <pubDate>Wed, 12 Dec 2018 20:09:20 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Being a voracious reader, one thing that helps bring the mountain of things I
want to read down to something manageable is being able to read things faster.
Reading <em>faster</em> itself probably hurts comprehension and digestion of core
concepts, but getting digested content from others who have already read the
main body of work can drastically reduce the amount of fluff you'll have to wade
through yourself. If you've ever read a book review that basically told you
everything you needed to know before you've read the book, you'll know what I'm
talking about.</p>
<p>I've personally felt this way a lot towards reviews and have found it
invaluable. As such, I feel it's necessary for me to pay this back. It's not
worthwhile giving rundowns for <em>everything</em> I've read so the purpose of this
article is to focus on the things I've found fascinating. This is by no means a
comprehensive list and you'll probably find the details per body of work a tad
thin as time has waned on since I've read them. However, I do wish to make this
more of a regular habit and, in the end, hopefully I can at least express the
delight I've had getting through some of these wonderful wading pools of words.</p>
<h2><a href="https://www.amazon.com/Coders-Work-Reflections-Craft-Programming/dp/1430219483/ref=sr_1_1?ie=UTF8&amp;qid=1544954623&amp;sr=8-1&amp;keywords=coders+at+work">Coders at Work</a></h2>
<p>This had so many fantastic insights into programming in the large as well as the
small for some of my heroes as well as some people I had never heard of before.
Of particular note was the recurring question Peter Seibel kept bringing up:
&quot;How do you read code?&quot;. In fact, Seibel even did a follow-up blog post on the
subject, but my particular take was the specifics that people actually replied
with. In fact, the subject matter drove me to write an article about reading
code I dubbed <a href="https://justanotherdot.com/posts/Reading_Code_is_Decoding.html">'Reading Code is
Decoding'</a></p>
<p>One other thing I thought fascinating was that one of the leaders of the Haskell
language, Simon Peyton Jones, had feelings towards types as proof systems that
were less intense as I had originally assumed. In fact, SPJ repeatedly mentions
that the idea is about <em>confidence</em> and not about mathematical fact.</p>
<p>Lastly, guys like Brad Fitzpatrick and Jamie Zawinski 'got things done', but
they also had a lot of sensibility towards quality instead of simply being
<a href="https://www.joelonsoftware.com/2009/09/23/the-duct-tape-programmer/">'duct tape
programmers'.</a>
In my mind, the book does a phenomenal job of showing how several people can
think of simplicity from different angles, whether that's avoiding the barbarism
of C++ in the face of Netscape's pre-existing C codebase, avoiding unnecessary
enterprise software in exchange for possibly less-than-ideal open-source
solutions to keep Live Journal up and running, or sussing out obtuse assembly
language for an unknown system by mathematically dissecting hunks of code.</p>
<h2><a href="https://www.amazon.com/Managers-Path-Leaders-Navigating-Growth-ebook/dp/B06XP3GJ7F/ref=sr_1_2?ie=UTF8&amp;qid=1544954644&amp;sr=8-2&amp;keywords=the+manager%27s+path">The Manager's Path</a></h2>
<p>Soft skills are hard, and we'll see in a few other reviews that they are even
harder to write about and absolutely harder to put into practice properly! But
that still doesn't mean people can't try. Things of note:</p>
<ul>
<li>
<p>You will sometimes need to do hard things and tell people hard news, but it's
better you do that than try to pretend everything is amazing. In other words,
It's better to be 'kind' (honest but considerate) than simply 'nice' (always
accommodating)</p>
</li>
<li>
<p>As you may find yourself with more managerial duties, you're ability to bridge
the gap between technical and non-technical members of the business increases;
this can be with metrics and even how you handle explaining or using
alternative jargon</p>
</li>
<li>
<p>A healthy codebase is an active one, but the rate of change needs to be kept
in check with the rate of errors. There is a subtle hint here about developing
a devops culture so that people are aware of how they can best help ship
software and know if they are within a predefined error budget. If you impede
the error budget, it's time to start focusing more on fixing things, which
means having flexible scheduling percentages.</p>
</li>
<li>
<p>Learning is the most vital aspect of a business and orienting it's processes
around it is pivotal in it's success</p>
</li>
<li>
<p>Having technical chops before you wind up in any managerial capacity is
crucial but it's also important to know that things like leadership and
empathy takes just as much effort to refine and perfect</p>
</li>
</ul>
<p>I feel like a good follow up to this was reading John Allspaw's article <a href="https://www.kitchensoap.com/2012/10/25/on-being-a-senior-engineer/"><em>On Being a Senior Engineer</em></a>.
In it, Allspaw hits on several soft skills that 'senior' software engineers
absolutely must uphold on a day to day basis, and I really don't see them being
that different from soft skills that others should be upholding as well as they
increase in seniority.</p>
<h2><a href="http://mcfunley.com/choose-boring-technology">Choose Boring Tech</a>, <a href="https://www.intercom.com/blog/run-less-software/">Run Less Software</a>, and [You Need a Novelty</h2>
<p>Budget](https://www.shimweasel.com/2018/08/25/novelty-budgets)</p>
<p>I mention these three articles in tandem because they were thoughts I had
faintly felt being in various organisations but could not pinpoint with words
quite as well as these three articles do. The core ideas are:</p>
<ul>
<li>
<p>You don't always need to map every problem to an ideal solution, in fact,
doing so is problematic because you will wind up with too much tech to
maintain, and maintenance cost must weight in considering adoption</p>
</li>
<li>
<p>Every new piece of tech you acquire into your stack means more things people
need to know about and the more people need to know means the less they can be
experts.</p>
</li>
<li>
<p>Choosing or building swanky libraries, technology, and services may be
exhilarating but it's also problematic for the above reasons. Having a
'novelty budget' can help prevent 'fancy tech creep' into the codebase and
infrastructure. In fact, it may help to run as many crazy projects 'on the
side' (i.e. outside of work) as possible to help reduce the urge of
introducing shiny-new-things</p>
</li>
</ul>
<p>I kept going back to these articles at least every month or two; they serve as a
basis of what I think is productive coding: write boring code that <a href="https://www.youtube.com/watch?v=4Y0tOi7QWqM">fits in your
head</a>, is heavily tested, focuses
on some clear specification (the proper abstraction), and satisfies &quot;small is
beautiful/less is more&quot;. I can't imagine that being the end of the proper
characteristics and that list keeps morphing as I keep coding, but it seems
sensible enough to mention those characteristics in relation to these posts.</p>
<h2><a href="https://www.amazon.com/Twelve-Steps-Compassionate-Karen-Armstrong-ebook/dp/B003WUYPBA/ref=sr_1_1?ie=UTF8&amp;qid=1544954743&amp;sr=8-1&amp;keywords=12+steps+to+a+compassionate+life">12 Steps to a Compassionate Life</a></h2>
<p>For trust to cultivate between members working together to build impossible
programs and systems you need respect and you can't build respect until you have
empathy for others. You don't need to feel the same thing they feel, per se, but
compassion itself is, in my mind and shaped from the sentiments in the book, the
difficult but extremely rewarding practice of cultivating concern for others,
their suffering and feelings.</p>
<p>In the book, Armstrong equips us with a particular process of better developing
empathy for others via religious, sociological, and psychological references.
Since this is a heavy process-oriented book, I can't simply give a quick tl;dr,
but I do want to recommend this book heavily. It and <a href="https://www.amazon.com/How-Talk-Kids-Will-Listen-ebook/dp/B005GG0MXI/ref=sr_1_4?ie=UTF8&amp;qid=1544953942&amp;sr=8-4&amp;keywords=how+to+talk">How to Talk so Kids Will
Listen and Listen so Kids Will
Talk</a>
are both fantastic resources on this subject, although I've read the latter a
number of years before this post.</p>
<h2><a href="https://blog.acolyer.org/2018/08/20/filter-before-you-parse-faster-analytics-on-raw-data-with-sparser/">Filter Before you Parse</a></h2>
<p>The Morning Paper is probably <em>the</em> best resource for mind blowing information
on the internet for software engineers, and I could ramble off many articles
that absolutely twisted my brain this year. If you don't have a subscription to
the The Morning Paper, you need to go subscribe this instance! Despite it not
being the most mind-bending of articles this year, I wanted to point out this
particular piece and associated paper because it's such a &quot;oh <strong>of course</strong>&quot;
kind of moment.</p>
<p>The gist? Do a fast search on the JSON payload <em>before</em> transforming it into
it's in-memory representation.</p>
<h2><a href="https://lemire.me/blog/2018/05/03/how-fast-can-you-parse-json/">How Fast Can You Parse JSON?</a></h2>
<p>Daniel Lemire is a performance and database nut (and so I'm easily a fan). I
wanted to include this since I had also included the JSON parsing related paper
from The Morning Paper. In this short article, Daniel explores a few industrial
grade parser implementations and tries to get at how many cycles it would take
to parse per byte, eventually coming to the closing line of:</p>
<blockquote>
<p>So you should expect to spend 2 or 3 seconds parsing one gigabyte of JSON data.</p>
</blockquote>
<p>I am personally a fan of &quot;Latency Numbers Every Programmer Should Know&quot; and I
think things like this are actually handy, back pocket facts that ease
estimation, s.t. if you find you're parsing a gigabyte of JSON and it's taking
orders of magnitude more than this, you can probably know there are gains to be
made, and also know that there might be a happy limit for optimisation.</p>
<h2><a href="https://charity.wtf/2018/08/19/shipping-software-should-not-be-scary/">Shipping Software Shouldn't be Scary</a></h2>
<p>I have a number female software engineer role models; Julia Evans, Jessie
Frazelle, and Charity Majors, to name a few. Charity's kick is on empowering
devs to be both coding and operations gurus by empowering them with the
superpower of observability. This article by Charity also goes into some core
things about operational concerns that are &quot;everyone's problems&quot;. The hot take
is that devs should be able to take code from cradle to grave; ideation into
production which entails all the messy debugging and reversals after Things Go
Wrong. The aim is to make everyone a software owner rather than a mere
occasional participant.</p>
<p>It may also get the reward for the best work memes of 2018.</p>
<h2><a href="https://gist.github.com/bcantrill/835837a66bcc21b899f501dd794a7d5f">Bryan Cantril's 'internal' doc on hiring</a></h2>
<p>Bryan sums this up nicely in the beginning, I'll add my takeaways for each bit.</p>
<ul>
<li>
<p>Aptitude: can the person actually code?</p>
</li>
<li>
<p>Education: have they persevered through boring lectures and stress?</p>
</li>
<li>
<p>Motivation: are you driven to write code everyday or is it Just Another Job?</p>
</li>
<li>
<p>Values, per the doc itself:</p>
</li>
</ul>
<blockquote>
<p>One observation is that one's values -- and the adherence or divergence from
those values -- will often be reflected in happiness and satisfaction with
work. When work strongly reflects one's values, one is much more likely to
find it satisfying; when values are compromised (even if for a good reason),
work is likely be unsatisfying.</p>
</blockquote>
<ul>
<li>Integrity: The usual verification that people are who they say they are and
not actually crazy, serial axe murders or simply bullshit artists.</li>
</ul>
<h2><a href="https://lethain.com/migrations/">Migrations: the sole scalable fix to tech debt</a></h2>
<p>You have legacy technology and you wish it would just go away, but how are you
going to euthanize it? You could write a new system and hide the other one in
the corner, perhaps? But you end up realising that your business relies quite
heavily to this chunk of code and that it's actually grown into such a mess you
can't fathom now moving away from it entirely and now need to run two things;
this is a fairly common problem and I think the gist of this article was spot
on: if you want to deprecate A, you need to be focused and clear about how B is
going to entirely replace it's functionality to the point where it can be
politely deleted out of existence, and you need to make this a common practice
as an engineering team as every piece of code you write is legacy the moment you
write it. Code rots, and, as such, that shiny new piece of tech you've just
built will one day need a successor.</p>
<p>In general the process is the same for any piece of software: do upfront
planning with documentation and good old fashioned thinking, get people on
board, don't be the machine and automate as much of the migration as possible,
help <em>track</em> the actual shift away from the older platform, and finally, don't
forget to celebrate your achievements! That last one is huge because if you
don't make migrations a big deal, people won't see the value in it!</p>
<h2><a href="https://www.amazon.com/Writing-Without-Bullshit-Career-Saying-ebook/dp/B01A5CEKQM/ref=sr_1_1?ie=UTF8&amp;qid=1544955550&amp;sr=8-1&amp;keywords=writing+without+bullshit">Writing Without Bullshit</a></h2>
<p>I'm actually quite surprised that this book devolved into a description of a
particular process, but I think it's a worthy ally in the fight to cut the fat
out of one's prose (the emphasis is in a workplace setting). Two major things of
note I took from this book were:</p>
<ul>
<li>
<p>Be short and to the point but scrutinize your use of data.</p>
</li>
<li>
<p>It's incredibly useful to get out 'fat outlines' of work before you start
obsessing on details and get lost in the subsequent worrying. I write like
this now in general: large bulk of content upfront and several passes of
refinement afterwards.</p>
</li>
<li>
<p>The 'iron imperative': &quot;Don't waste the readers time&quot;</p>
</li>
</ul>
<p>That last point kept having me think about the book <a href="https://www.amazon.com/Dont-Make-Think-Revisited-Usability/dp/0321965515/ref=sr_1_1?ie=UTF8&amp;qid=1544955670&amp;sr=8-1&amp;keywords=don%27t+make+me+think">Don't Make
Me</a>
Think where the crux of design should be about alleviating cognitive load on the
user of the interface. It's a powerful phrase to have handy when needing to
point out really lengthy bits of code, comments, or documentation, as well as
general communiques.</p>
<h2><a href="https://www.amazon.com/Messy-Power-Disorder-Transform-Lives-ebook/dp/B01BD1SU2E/ref=sr_1_1?ie=UTF8&amp;qid=1544955751&amp;sr=8-1&amp;keywords=messy+the+power">Messy: The Power of Disorder to Transform Our Lives</a></h2>
<p>This book was monumental in getting me comfortable with the idea of doing rough
groundwork upfront. In fact, some people describe this as the <a href="https://en.wikipedia.org/wiki/Pareto_principle">'paeto
principle'</a> where 'eighty
percent of the work comes from twenty percent of the effort'. In my mind I'm
sure Pareto never intended this to be about a specific ratio but rather about
how a small portion of input winds up relating to a large portion of the output.
I actually found no better succinct description of the book except at the start
(the rest is still worth the read):</p>
<blockquote>
<p>The argument of this book is that we often succumb to the temptation of a
tidy-minded approach when we would be better served by embracing a degree of
mess.</p>
</blockquote>
<h2><a href="https://www.amazon.com/Programming-Rust-Fast-Systems-Development/dp/1491927283/ref=sr_1_1?ie=UTF8&amp;qid=1544955863&amp;sr=8-1&amp;keywords=programming+rust">Programming Rust</a></h2>
<p>I've not really read a specific programming-language book in awhile, but I love
systems programming and Programming rust (along with several other rust books)
focus heavily on the subject; whether it's talking about error handling, rough
edges with Unicode, or even how different languages handle assignment in order
to explain the borrow checker and moves, I was constantly enthralled to pick
this book up despite it being close to six-hundred pages. It's gained the
classic 'dirty and crushed pages' aesthetic and it'll probably gain a bit more
as I keep trying to double down on rust.</p>
<h2><a href="https://www.amazon.com/Designing-Data-Intensive-Applications-Reliable-Maintainable/dp/1449373321/ref=sr_1_1?ie=UTF8&amp;qid=1544955948&amp;sr=8-1&amp;keywords=designing+data-intensive+applications">Designing Data-Intensive Applications</a></h2>
<p>I can't recommend this book enough. I actually finished reading this near the
end of 2017, but I love it so much that I wanted to write about it here. I
personally don't know of any other book that handles the fundamentals of
database internals (along with many modern improvements), database design,
clusters, nodes, schema encodings, discussions around guarantees (CAP, ACID) and
what are valid and invalid points, consensus in distributed systems, and even
modern data processing patterns all while in the context of proposing a credo
that data-intensive applications should uphold, in such an elegant and
ultimately fun way. I still read through the book for knowledge I may have
passed up or forgotten so it's a fantastic resource to have on my shelf.</p>
<p>It's also dawned on me that data processing <em>is</em> programming, and knowing more
and more about data and how to handle it is enlightening and empowering.</p>
<h2><a href="https://www.amazon.com/Thinking-Forth-Leo-Brodie/dp/0976458705/ref=sr_1_1?ie=UTF8&amp;qid=1544956045&amp;sr=8-1&amp;keywords=thinking+forth">Thinking Forth</a></h2>
<p><a href="https://twitter.com/lorentzframe/status/997997523301117953">Brian Beckman wrote a tweet I read awhile
back</a>, stating:</p>
<blockquote>
<p>&quot;SICP&quot; by Abelson &amp; Sussman should be read continuously, ~2 pages a day,
returning to page 1 every year. Ditto &quot;Thinking Forth&quot; by Leo Brodie, tho'
only ~1 page a day. The former teaches how to think, the latter how to
engineer. Both are in unpopular languages, on purpose.</p>
</blockquote>
<p>and having read most of the SICP, even watching the entire lecture series, but
never having heard of <em>Thinking Forth</em> (but having heard of the language), I was
intrigued to hear of a book put on the same page as the SICP! I am actually,
also, cheating here as I've read only half of it, but so far it's definitely a
different way of looking at software construction in the same vein that the SICP
went to lengths to describe.</p>
<p>The heaviest emphasis made so far in the book that I love seems drawn between
Domain Driven Design and traditional functional programming: words are vital to
how we code, the meaning they carry as well as their surrounding semantics; we
group words into lexicons which we can call 'components', and with 'components'
we get all the general benefits we get from composition. There is some forth
specific information nestled between, but <a href="https://twitter.com/lorentzframe/status/999121431559487489">Beckman is wise in a followup
tweet</a>, saying:</p>
<blockquote>
<p>If SICP were in, say, (popular) Python instead of (unpopular) Scheme, people
might be distracted by the Python and miss the thinking. Ditto if &quot;Thinking
Forth&quot; were in (popular) Java instead of (unpopular) Forth, people might miss
the deeper points about software engineering.</p>
</blockquote>
<p>I'm excited to finish it in January, in tandem with <em>Thinking in Systems: A
Primer</em>, which I've started just last week and has so far been an amazing way of
perceiving the structure of various systems from a proper, abstracted point of
view.</p>
<h2>Conclusion</h2>
<p>I originally thought a format involving simple review styled blurbs might be
handy, but it's kind of nice having not thought about some of these various
texts for a bit to really see what would stick. I hope this has been somewhat
useful or fun!</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>What makes a good pull request?</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/what-makes-a-good-pr.html</link>
      <guid>https://justanotherdot.com/posts/what-makes-a-good-pr.html</guid>
      <pubDate>Fri, 20 Jul 2018 20:40:08 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Pull Requests (or PRs) are a tango between two parties; the code author and the
code reviewer which I will simply refer to as the 'author' and 'reviewer' in the
remainder of this article. In a pull request, the author has provided code to
solve a particular problem and the reviewer is there to provide a feedback
mechanism to the author.</p>
<h2>Code review is not a gate keeping task</h2>
<p>I once worked for an organisation whose code review process centered around a
total lack of faith in its developers ability to deliver quality product; tech
leads acted as the gate keepers to their respective stacks forcing the average
developer to resort to underhanded tactics in order to get their changes
merged, regardless of quality or prospective bugs. This, in turn, meant the
gate keepers felt justified under the guise of 'keeping things safe'. Thus,
code wasn't being checked properly and wrong or flimsy changes would trickle
into master, making the code review process utterly broken.</p>
<p>As a software engineer, every line of code you ship is code you, or someone
else, will need to maintain, and as such, you should be fighting to deliver the
best quality you can offer, regardless of deadline. <strong>Code reviewers are there
to help people bring their code into the light of day where asking questions is
the chief tool a reviewer employs</strong>. This can include, but is not limited to,
probing to see if:</p>
<ul>
<li>Is the thought fully fleshed out?</li>
<li>Is this implementation correct for the problem it aims to solve?</li>
<li>Are the changes sound and principled?</li>
<li>Are there any performance or semantic concerns?</li>
</ul>
<p>I'm purposefully leaving out stylistic choices here as the discussion often
leads to the argument around adoption of some automated code-formatting tool.</p>
<h2>Raise early and raise often</h2>
<p>In &quot;Debugging Team's&quot;, the authors kick off the start of the book with a simple
analogy between two competing inventors. The one inventor does not want to share
his ideas for fear of them being poached by others, while the rival inventor
gleefully goes to local places where experts might hang out to get more
information about how to build her inventions.</p>
<p>Software development is no different in that knowing things earlier is always
better than knowing things later. Raising PRs even before they are 'complete'
(and appropriately marking them as WIPs or 'works in progress') allows people to
possibly, time permitting, look into your changes and see if there are any major
red flags.</p>
<p>That said, if you are a reviewer and are asked (or not!) to look at a set of
changes that is marked as a WIP, try to hold off on a more in-depth review until
the author changes this status. And to PR raisers, don't keep things in WIP
stage for too long, which brings me to my next point.</p>
<h2>PRs are for small chunks of code to merge often</h2>
<p>A PR should represent up to a day's worth of work. This is beneficial to both
parties in that it facilitates a 'merge often' approach for devs (and devs get
the little adrenaline kick from clicking that green <code>merge</code> button) and
reviewers can much more easily review a smaller hunk of changes. A reviewer
reviewing five PRs in the course of a week has to spend less time grokking
those individual changes than to review five days worth of work in a single PR.</p>
<p>Massive projects poised around scaled tooling and reviews such as the Linux
kernel would flat out reject a patch with, say, 3k additions and 1k removals. If
a project of that size and calibre, and that many international hands involved,
is marking code review of those dimensions as 'unmanageable', what hope does a
startup have at making fast, rapid changes in the same light?</p>
<p>Small PRs are also <em>focused</em> on a clear intent. Asking the author to fix
neighboring code 'just because' or refactoring/formatting several adjacent files
that are not directly tied to the immediate effort of the PR wastes the both
parties time. Opening a PR to refactor changes and another PR to add new
functionality is a much better way to get appropriate attention from reviewers.
As the joke goes:</p>
<blockquote>
<p>10 lines = 10 possible bugs, 100 lines = lgtm</p>
</blockquote>
<p>It's important to remember that a PR is not to encompass a single ticket or
issue. Tickets can have several PRs attached to them and all it takes is
lobbing <code>[FOO-123]</code> on top of one's PR title for Jira or marking <code>#&lt;issue number&gt;</code> in your description in GitHub. I like to call this act 'linking' and
it's useful for stakeholders to track down all the changes that have fed into a
particular ticket.</p>
<h2>Context matters</h2>
<p>Reviewers need to discuss with the author about the purpose of a set of changes
and how close or far off they are from that goal, but if the reviewer is
unclear about this goal, it's difficult for them to strike up a discussion with
the author.</p>
<p>In the context of OSS, raising a patch directly to a project such as the Linux
kernel is poor practice. If you want to make a change in any capacity it's best
first to contact the people who own the code on public channels. This provides
auditing and clear context for others. <strong>Your first instinct should be to raise
a PR unless it's a feature. If you feel uncertain about whether or not your
change is warranted, it's best to raise an issue first, instead.</strong></p>
<p>That said, raising PRs should feel natural; PRs are cheap and can be closed and
their branches pruned as need be, but regardless of the cost of raising a PR,
it's critical to include appropriate information. Some important things to
mention may be:</p>
<ul>
<li>What does this set of changes solve?</li>
<li>Is there a specific task (issue/ticket) that this relates to?</li>
<li>Is this blocked or blocking any other PRs/issues/tickets?</li>
<li>Is there any additional information that will help the reviewer know about my
manual testing of this ticket (screenshots, output from tooling, et. al.)?</li>
<li>Have you updated tests and documentation accordingly? Have you added tests
that the reviewer can skip to first to immediately see how you're proposed
changes are supposed to work and in what cases?</li>
<li>Is there current behaviour to contrast the new behaviour to?</li>
<li>Are there breaking changes present?</li>
</ul>
<p>The traditional approach for this was to include commentary in your actual
commit messages and headers. I don't think times have really changed in this
regard and the more context you sprinkle about the better, so long as you are
clear about your intent and you don't waste the reader's time.</p>
<h2>Check out changes locally when it makes sense</h2>
<p>A really healthy habit for reasonably sized changes is to always check out a PR
and see if it works for you. Some projects have powerful processes for testing
full 'e2e/raw hardware' scenarios such as Intel's <a href="https://01.org/lkp/documentation/0-day-test-service">zero-day testing
bot</a> which actually boots
up machines to test out differing version of the Linux kernel. While continuous
integration can catch a lot, it's important to sometimes get a human eye for
regressions that may not, or cannot, be encoded in automated tests. We all make
mistakes, and reviewers are there to add a layer of sanity checks to our
changes.</p>
<p>Use common sense. If a change is pretty sensible (e.g. a single line change to
update a variable name), you probably don't need to spend the time pulling the
change down, compiling, running the tests, and so forth. As the developer's
mantra goes, &quot;Don't be the machine&quot;!</p>
<h2>Clean up your mess</h2>
<p>Your changes have been merged and you can go on with your life, but before you
reach for beverage of choice, you should prune your dead branches. I actually
have a git bash script for this that I place in my <code>PATH</code> so I can call it as
<code>git wash</code>. The script is <a href="https://gist.github.com/justanotherdot/3e3a16df805d09a37e1c26bbedd23fcc">here</a>. When
run without arguments, this will delete the current branch you are on locally
and remotely so long as the branch specified to <code>git wash</code> is not master and the
remote branch is not protected. If you need other git functionality like this,
any script in your path with the name <code>git-&lt;thing&gt;</code> can be run as <code>git &lt;thing&gt;</code>.</p>
<h2>Conclusion</h2>
<p>Reviewing many small changes is much more manageable for a reviewer than
reviewing large, tangled changes. Decomposition in programming gives us the
ability to stitch together many small, verified solutions that lead up to an
equally trustworthy result and the same is no different in the process of
supplying code changes to a project; breaking up the changes you need to make
into reasonable chunks that can fit in everyone's heads not only helps to
provide code changes faster but it also paves foundations for robust and
resilient code.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Trampling Trampolines</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/trampling-trampolines.html</link>
      <guid>https://justanotherdot.com/posts/trampling-trampolines.html</guid>
      <pubDate>Thu, 24 May 2018 19:40:17 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <h2>Continuation Passing Style</h2>
<p>or CPS for short, is a way to continue a function call by calling into another function. The simplest example would be:</p>
<pre><code>function cps(x, return) {
  return(x);
}
</code></pre>
<p>The important thing is the callback is passed and it is called at the completion of the function, passing things along.</p>
<p>CPS is not a problem in languages where Last Call Optimisation is commonplace. What these languages do (normally of eager evaluation) is collapse the stack frame and call the function call so long as there is nothing else beyond the function. <a href="http://erlang.org/pipermail/erlang-questions/2016-October/090663.html">Heres a fun rant by Joe Armstrong regarding the implementation and implication of Tail/Last Call Optimisation</a>. Of note is how he is careful not to say this is the same as Tail Call Optimisation, or TCO, as that typically implies a recursive call.</p>
<h2>DIY</h2>
<p>Languages that dont collapse the stack or represent functions in a form that is conducive to fusion are subject to blowing the stack (exceeding its maximum size) when writing a recursive function. The function may be correct, but for particular values it may grow too large and too many stack frames will be pushed onto the programs stack.</p>
<p>There are some <a href="http://chrispenner.ca/posts/python-tail-recursion">interesting ways to mimic TCO</a> in languages that dont have native support for it. JavaScript does, technically, but implementation seems spotty across engines.  A clever way to mimic TCO in JavaScript is to rewrite your function to return a continuation, of sorts, and then wrapping it in another, generic, function (the trampoline) that knows about this arrangement in order to collapse the stack itself, for example:</p>
<pre><code>let ackermannGo = (n, m) =&gt; {
  if (m === 0) {
    return n+1;
  } else if (m &gt; 0 &amp;&amp; n === 0) {
    return ackermannGo(m-1, 1);
  } else if (m &gt; 0 &amp;&amp; n &gt; 0) {
    return ackermannGo(m-1, ackermannGo(m, n-1));
  } else {
    throw new Error(`ERROR: unhandled case m: ${m} and n: ${n}`);
  }
};
</code></pre>
<p>Ive chosen the <a href="https://en.wikipedia.org/wiki/Ackermann_function">Ackermann function</a> here as its a golden standard for testing recursive functionality in programming languages since its value grows rapidly even for small digits. Im also using the convention of naming things as <code>go</code> to specify recursive helper functions with arguments we dont care about. A common counterpart to <code>go</code> you might see (particularly popular in LISPs) is <code>do</code> .</p>
<p>If you play around with this function you should quickly find it exceeding the allotted call stack size. Lets fix this with a trampoline:</p>
<pre><code>let trampoline = fn =&gt; (...args) =&gt; {
  let rv = fn(...args);
  while (typeof rv === 'function') {
    rv = rv();
  }
  return rv;
};

ackermannGo = (n, m) =&gt; {
  if (m === 0) {
    return n+1;
  } else if (m &gt; 0 &amp;&amp; n === 0) {
    return () =&gt; ackermannGo(m-1, 1);
  } else if (m &gt; 0 &amp;&amp; n &gt; 0) {
    return () =&gt; ackermannGo(m-1, ackermannGo(m, n-1));
  } else {
    throw new Error(`urk: unhandled case m: ${m} and n: ${n}`);
  }
};
</code></pre>
<p>Note the zero-arity functions we are returning in order to signal that the return value can be applied (specifically lines 13 and 15). What kind of functions will <code>trampoline</code> fail on given its current implementation? When youve given it some thought, consider this case:</p>
<pre><code>let higherOrderFunc = (n, acc, offset) =&gt; {
  if (n &lt; 1) {
    return offset =&gt; acc+offset;
  }
  return () =&gt; higherOrderFunc(n-1, acc+n, offset);
}

let hof = trampoline(higherOrderFunc);
</code></pre>
<p>Although this will terminate, it wont give us the correct result. We want a closure in the end, but here we will wind up with <code>NaN</code> since that is the result of adding any number in JavaScript to <code>undefined</code>, and since we are calling the result value, <code>rv</code>, with no arguments, we are technically passing <code>undefined</code> to this final value.</p>
<p>A <em>structural</em> type system is one which cares only about the form of given values, whereas a <em>nominal</em> type system cares about the <em>names</em> that values have in the system. In a language like Haskell, wed use whats known as a data constructor to declare a type. Consider:</p>
<pre><code>data Cont a = Stop a | Cont (() -&gt; Cont a)
</code></pre>
<p>This says for any given value of <code>a</code>, I can either be a <code>Stop</code> value wrapping some given value of <code>a</code>, or I can be a <code>Cont</code> wrapping a function which takes <code>unit</code> (the <code>()</code>, or, in other words, no arguments that matters) to another <code>Cont</code> value</p>
<p>We can, again, mimic something similar using a <code>tag</code> field on an object, a la:</p>
<pre><code>higherOrderFunc = (n, acc, offset) =&gt; {
  if (n &lt; 1) {
    return {
      tag: 'stop',
      val: offset =&gt; acc+offset
    };
  }
  return {
    tag: 'cont',
    val: () =&gt; higherOrderFunc(n-1, acc+n, offset)
  };
};
</code></pre>
<p>Which we can leverage in a new definition of <code>trampoline</code>:</p>
<pre><code>trampoline = fn =&gt; (...args) =&gt; {
  let rv = fn(...args);
  while (rv.tag === 'cont') {
    rv = rv.val();
  }
  return rv.val; // Of tag 'stop'.
};
</code></pre>
<p>We only have two cases for our type, so when we no longer have a <code>cont</code> tag, we must have a <code>stop</code>, and with this we get the correct result: a function!</p>
<h2>Conclusion</h2>
<p>In mathematics it is just as important to reason about the types of objects we are dealing with as it is to reason about their values. The same is no different in programming. Even though you may say I hack in a dynamically typed language, I dont need to think about types, the inverse is actually the truth! Hacking in a dynamically typed environment means juggling these notions around in your head rather than allowing the type checker make sense of the form of things for you.</p>
<p><em>food for thought:</em> What weve done by tagging these values is upgrade a <code>union</code> type into a <code>discriminated union</code>. A <code>discriminated unions</code> is also sometimes known as a <code>sum</code> type. The power of passing around sum types is that we can reason about the cases in our code: recursion itself is similar to mathematical induction, and both are forms of breaking down data whereas their duals, co-recursion and co-induction, build up data. This is an important notion because it means that when we write things recursively in this form with inductive-like types (e.g. sums) we can pattern match on their values and know something about each case. In the above examples we knew that <code>cont</code> always contained a function that took no arguments and returned another <code>cont</code> or <code>stop</code> tagged object. When we finally got a <code>stop</code> we knew we had our final result we could return, and since there were only two values we could be sure that those were the only two cases worth exploring (show exhaustivity checking as well as case analysis). As is common with FP, some languages give you the power of actually statically checking this; ensuring that youve considered all cases, whereas in others youll be left to discipline or libraries to replicate this, just like trampolines.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Proficiency is Tiered and other Lies We Tell Ourselves</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/proficiency-is-tiered-and-other-lies-we-tell-ourselves.html</link>
      <guid>https://justanotherdot.com/posts/proficiency-is-tiered-and-other-lies-we-tell-ourselves.html</guid>
      <pubDate>Thu, 01 Mar 2018 15:48:02 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Tiered categorisations of knowledge and proficiency are fundamentally flawed as
they rest on the notion that all knowledge can eventually be obtained,
retained, and divvied up amongst n-many categories. Such categorisations also
ignore the fact that most skills rely on overlapping knowledge from various
domains. In this article I propose a way to evaluate subject matter in the
context of best prioritising <em>what should I learn next?</em> Ill also offer up an
approach to evaluating others that isnt based on skill level (admittedly
regurgitated from Amy Cuddy).</p>
<h2>A Tagging System</h2>
<p>Instead of suggesting that knowledge from a domain of expertise can be chunked
and tagged in toto, we consider an alternative tagging system where we look at
knowledge from three types of labels and, most importantly, accept that the
fringes are fuzzy:</p>
<ul>
<li>Fundamentals
<ul>
<li>There is usually a corpus of knowledge that everyone can agree upon is
pivotal to being competent/dangerous in a particular subject matter.
These may overlap to other skills and it may be unclear <em>which</em> skills they
overlap in, but what matters is that these skills are relatively obvious in
the domain of note.</li>
</ul>
</li>
<li>Nice-to-Haves
<ul>
<li>This is the knowledge that might be good to spend a bit of time on as it
refines and builds on fundamentals to introduce more powerful techniques
and practices. This is where the only clarity is that they are definitely
not fundamentals and they are definitely not esoteric.</li>
</ul>
</li>
<li>Trivia
<ul>
<li>This is the stuff you probably dont need to know, like that some AIX
machines have a weird bug in certain prompts where inputting uppercase
characters will cause the machine to reboot or that earlier, alternative
architectures supported 7-bit bytes. These tidbits of information
(sometimes not so miniscule!) are probably very costly to pick up and dont
give you much in return.</li>
</ul>
</li>
</ul>
<p>These tags map very much to the progression of learning a subject: when you
start learning a subject, everything is rough and unclear; you should focus on
exposing yourself to as much as knowledge as possible even if you dont quite
understand everything. This 5yo view of the world helps build the framework
wherein we can fill in further details as we step towards the nice-to-haves,
but instead of becoming an expert by picking up trivia, we try to avoid it,
and if it were important, then it would fall back into the nice-to-haves. This
is the important caveat to learning anything in general Im trying to make
here; mastering a subject has nothing to do with knowing absolutely everything
there is to know.</p>
<p>The practice of using these tags is simple: whenever youre faced with a
variety of options, pick fundamentals over nice-to-haves, nice-to-haves over
trivia, and (per that last regard) try to pick more fundamentals and
nice-to-haves in a variety of subject matter than trying to pick up a
collection of specific trivia for a single subject matter.</p>
<p>I liken this to the Pareto principle, which effectively states that input
effort is usually disproportionate to output gains, or, as the common quote
goes, 20% of the effort for 80% of the output (although its perfectly
feasible for the opposite situation to occur). This roughly implies that most
initial upfront work is high leverage and that driving towards expertise may
have little return on investment. What I like about this proposal is that it
accepts the fact that knowledge categorisation is messy and that theres
probably no one in the world that knows everything.</p>
<h2>Evaluation of Others</h2>
<p>One problem with the above proposal is that it doesnt consider the common
usage of such tiered categorisations: evaluation of others sets skills. Amy
Cuddy proposes that most people are judging you on your competency after
theyve judged you on whether or not they can trust you. I propose we try to
drop the skill-evaluation-at-moment-of-evaluation tactic and focus on
evaluating others in two primary metrics: trust and ability to advance ones
skills over any given period of time. Some people call this hiring for the
slope rather than the Y axis.</p>
<p>That said, Im predominantly a software engineer and in my experience I find
the former usage of this proposal to be the one I care about the most.
Determining whats appropriate for ourselves rather than trying to divvy people
up into boxes is a far more valuable use of engineering time, and further,
evaluating people on the merits of their enthusiasm, ability and desire to
continually learn, and their capacity to both work away and in teams is more
worth its weight in gold than if someone is a self-proclaimed 10x engineer
capable of cranking a lot of (read: complicated, un-maintainable, mal-scoped)
code.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Reading Code is Decoding</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/reading-code-is-decoding.html</link>
      <guid>https://justanotherdot.com/posts/reading-code-is-decoding.html</guid>
      <pubDate>Sat, 27 Jan 2018 13:43:09 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>Roger Antonsen says in his Ted Talk <a href="https://www.ted.com/talks/roger_antonsen_math_is_the_hidden_secret_to_understanding_the_world"><em>Mathematics is
the Secret to Understanding the
World</em></a>,
mathematics, or rather the act of understanding, is largely about:</p>
<ul>
<li>Discovering patterns</li>
<li>Devising language(s) to express said patterns</li>
<li>Making assumptions</li>
<li>Playing around with all of the above</li>
</ul>
<p>Early this January I finished reading <em>Coders at Work</em> and in each interview
there is a recurring question of how do you read code? Heres a rough summary
of some styles mentioned I found particularly useful:</p>
<ul>
<li>Get the code building early and often and make various changes to study
connections</li>
<li>Read it like literature whether printed out or jumping around</li>
<li>Rewrite the code into a version optimised for legibility</li>
<li>Puzzle through it the same way one would tackle a mathematical problem</li>
</ul>
<p>It turns out I had previously read <a href="http://www.gigamonkeys.com/code-reading/">a post from Peter
Seibel</a>, the books author, who had
tried on several occasions to start code reading groups at his places of work,
in which he states:</p>
<blockquote>
<p>It was sometime after that presentation that I finally realized the obvious:
code is not literature. We dont read code, we decode it. We examine it. A
piece of code is not literature; it is a specimen.</p>
</blockquote>
<p>He goes on to quote a passage (my favourite in the book) of his interview with
Knuth (emphasis added by me):</p>
<blockquote>
<p>Knuth: But its really worth it for what it builds in your brain. So how do I
do it? There was a machine called the Bunker Ramo 300 and somebody told me
that the Fortran compiler for this machine was really amazingly fast, but
nobody had any idea why it worked. I got a copy of the source-code listing
for it. I didnt have a manual for the machine, so I wasnt even sure what
the machine language was.</p>
<p>But I took it as an interesting challenge. I could figure out <code>BEGIN</code> and
then I would start to decode. The operation codes had some two-letter
mnemonics and so I could start to figure out This probably was a load
instruction, this probably was a branch. And I knew it was a Fortran
compiler, so at some point it looked at column seven of a card, and that was
where it would tell if it was a comment or not.</p>
<p>After three hours I had figured out a little bit about the machine. Then I
found these big, branching tables. So it was a puzzle and I kept just making
little charts like Im working at a security agency trying to decode a secret
code. But I knew it worked and I knew it was a Fortran compilerit wasnt
encrypted in the sense that it was intentionally obscure; it was only in code
because I hadnt gotten the manual for the machine.</p>
<p>Eventually I was able to figure out why this compiler was so fast.
Unfortunately it wasnt because the algorithms were brilliant; it was just
because they had used unstructured programming and hand optimized the code to
the hilt.</p>
<p>It was just basically the way you solve some kind of an unknown puzzlemake
tables and charts and get a little more information here and make a
hypothesis. In general when Im reading a technical paper, its the same
challenge. Im trying to get into the authors mind, trying to figure out
what the concept is. <strong>The more you learn to read other peoples stuff, the
more able you are to invent your own in the future, it seems to me.</strong></p>
</blockquote>
<p>Alas, if were to treat literacy in a human language as the combined skills of
writing <em>and</em> reading, why do we place so much emphasis on the former when it
comes to teaching how to code? I now actively seek out code to read for the
same reason Knuth mentions early in his interview; dispelling magic is an
invaluable skill we crucially need to keep improving. Treating things as a
black box may sometimes help reasoning but it doesnt mean we should keep the
covers on until the end of the universe.</p>
<p>Take my <a href="https://j2kun.svbtle.com/mathematicians-are-chronically-lost-and-confused">favourite mathematical
post</a>
by Jeremy Kun in which he discusses, with a wonderful supporting analogy from
Andrew Wiles about stumbling around a dark house looking for light switches,
that feeling lost is far more common and acceptable than the enlightened state
we assume intelligent role models seem to possess. These role models have
simply learned to live with and accept the discomfort of being lost because
thats what it means to be in a process of learning and growing!</p>
<p>Simon Peyton Jones is well known for stating how important it is to simply
<em>do</em>, no matter how humble the project in question may be. This is fantastic
advice for coding literacy; Writing this blog post involved an initial sit down
of a roughly one-thousand word brain dump followed thereafter by approximately
two days of refinements, with lots of rereading, simply honing in on the main
theme. Its important to get fingers moving and code executing, but its just
as important to advocate to new starters that reading is something they should
be pouring time and attention into.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>Fail Fast not Error Out</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/fail-fast-not-error-out.html</link>
      <guid>https://justanotherdot.com/posts/fail-fast-not-error-out.html</guid>
      <pubDate>Sat, 07 Oct 2017 12:50:02 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p><strong>tl;dr</strong> Static analysis is a form of 'failing fast' that does not consist of
leaving error based exit strategies (which should be reserved for situations
where the program simply cannot transition to a new state) in code that will
eventually be shipped to production.</p>
<p>The notion of 'failing fast' in programming details finding faults at the
earliest possible time; when the application developer is fitting out the code!
This seems to be sensible, but is often strangely antithetical to the notion of
'the only true test of code is production data'; how can we fail fast and catch
a ton of bugs when the truly icky bugs we want to smash are after we've done
some kind of deployment? Clearly the distinction here is to find bugs, in any
context, as soon as possible, production or otherwise, but that does mean the
concept can be carried over to production, where failing fast could mean major
problems (payments not being processed, account information being leaked, etc).</p>
<p>Ops people have devised all sorts of methods to roll out code in deployment to
handle situations like this; blue-green deployments, canary deployments, et.
al. all focus on testing code on a much smaller subset (on some segment of
traffic) accepting <em>some</em> failure as an acceptable loss to know if the code is
ok enough to push to 100% of the traffic. Percentage deployments put a lot of
focus on monitoring and logging. Essentially, people have to watch the metrics
after the roll out to make sure everything is ok.</p>
<p>A computation does not need to crash the program in order to fail fast:</p>
<ul>
<li>
<p>Errors are for irrecoverable states of program transition; the program
depends on writing to disk for some critical task, and the disk has been ripped
out of the server rack and can no longer be accessed via the kernel drivers.
The kernel tells us something very bad is up, and we die. This is fine, because
there's no sensible state to transition to in this scenario.</p>
</li>
<li>
<p>Exceptions are for situations where something bad happened, but it's not bad
enough to cause us to fail completely, i.e. we can do something to transition
to another sensible step. The general frame of mind is that exceptions can be
problematic when they are not caught, but can be a pain to constantly look out
for (this is the source of the 'checked exceptions' controversy in the Java
community). The primary problem with exceptions is that if an exception is not
'checked' or 'caught', then it will bubble up to the main function (entry
point) of the program and cause it to error out as above. Exceptions are said
to be sensible if they preserve <strong>progress</strong> and <strong>preservation</strong>, meaning that
they are able to move forward and they don't manipulate the types of
expressions where they are thrown. In most languages, however, we can't be sure
if something is going to throw an exception, so many programmers are told to be
defensive and paranoid; hardly the kinds of things you'd want out of people who
need to also be innovative.</p>
</li>
</ul>
<p>In most pure functional programming languages, we know less about lurking
exceptions, and this is of particular importance. When we have a type system,
which is effectively a lightweight proof system that gives us static guarantees
and checks at compile time (a form of 'fail fast' but without the problem of
leaving 'ticking time bombs' in our code base that may still present themselves
in production), then it makes no sense to fail fast in an error-prone way.
Abstractions such as monads and friends allow us to do this elegantly and
tersely.</p>
<p>It is far more ideal to let pure computations transition gracefully to new
states, failures to be found at <em>compile time</em>, and production code to be
robust and resiliant. If we extend this notion of static analysis to property
based testing, formal correctness practices, and even linters, among other
things, there are several smarter alternatives to failing quickly and
validating the correctness of our programs.</p>

        ]]></content:encoded>
    </item>
    
    <item>
      <title>A Start</title>
      <author>Ryan James Spencer</author>
      <link>https://justanotherdot.com/posts/hi.html</link>
      <guid>https://justanotherdot.com/posts/hi.html</guid>
      <pubDate>Sun, 17 Sep 2017 16:06:55 +1000</pubDate>
      <description></description>
      <content:encoded><![CDATA[
        <p>I've managed to hack together this blog using Chris Penner's alternative to
Hakyll, <a href="https://github.com/ChrisPenner/SitePipe">SitePipe</a>, as well as using a
CSS framework I've wanted to try out, <a href="http://bulma.io/">Bulma</a>, and host it on
github pages. My plan is to:</p>
<ol>
<li>Move over to some other hosting platform to do my own infra (either Digital
Ocean or Linode w/ some kind of SSL reverse proxy.)</li>
<li>Tidy up a little bit of the layout around the site.</li>
<li>Write some content!</li>
</ol>
<p>I had written a <a href="https://medium.com/@justanotherdot/sapir-whorf-and-you-f4b45ff2f216">post over at
Medium</a>
and while I liked the overall editing experience, I knew I'd eventually find
some things lacking e.g. Mathjax integration and the like, of which I was able
to sort of hack into my <a href="http://justanotherdot.tumblr.com/">previous tumblr</a>
thanks to having access to the HTML of my blog, and is another thing I'll need
to add here.</p>
<p>When I was originally looking to make my own blog my ideal layout consisted of
Markdown being dumped as HTML which would be sent over some kind of ajax
request to fill in an SPA. That still may happen, but at the moment this
workflow seems fine, and I'm hoping I can fulfill a personal quota of 250 words
per week, but we'll see how that goes.</p>
<p>Also, there's something to say about how generic (and sometimes even bland)
some publishing sites make the blog-to-blog experience. Yes, it is just text
and media, but even a little bit of a personal touch goes a long way, I think.
I worry that, especially in the realm of tech articles, people will feel the
'overal sleek' experience of something like Medium will help carry the weight
of their voices beyond the actual rigor of their articles.</p>

        ]]></content:encoded>
    </item>
    
  </channel>
</rss>