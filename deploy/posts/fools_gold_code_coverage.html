<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width" />
    <link rel="stylesheet" type="text/css" href="../assets/bulma.min.css" />
    <title>&#8226; Fool's Gold: Code Coverage</title>
  </head>
  <body>
    <section class="section">
      <div class="container">
        <div class="columns">
          <div class="column is-one-quarter">
            <a href="https://justanotherdot.com">
              <h1 class="title">
                justanotherdot &#8226;
              </h1>
            </a>
            <h1 class="subtitle">
              Ryan James Spencer
            </h1>
          </div>
          <div class="column is-half">
            <h1 class="title is-2">Fool's Gold: Code Coverage</h1>
            <h2 class="subtitle is-5">on October  1 2019,  9:05PM</h2>
            <div class="content is-medium">
              <p>If you are unfamiliar with code coverage, the idea is simple: you write
accompanying tests to code and a code coverage tool produces reports of lines
covered by tests and percentage of code covered to all lines of code. The hope
is that a higher coverage with tests means you'll have a correct system. Some
places even initiate quotas on required coverage per lines of new code being
introduced. &quot;If it doesn't have tests it doesn't exist&quot; is the argument for this
requirement; code without tests is potentially problematic code, but tests are
also untested chunks of code in our codebase. Consider this bit of React code,
(assuming jest as the test framework):</p>
<pre><code>test('Breadcrumb renders', () =&gt; {
  expect(() =&gt; {
    &lt;Breadcrumb/&gt;
  }).not.toThrow();
});
</code></pre>
<p>What is this testing exactly? Literally any other test, even one without the
<code>toThrow</code> expectation, would mark this as a failure on an exception being
thrown. This will light up code coverage though. People learn to cheat the
system, or please the metric of code coverage percentage going up, and focus
less on the guarantees the tests are providing them.</p>
<p>Does this help us deliver better products to end users? No.</p>
<p>Code coverage percentage is a useless metric. There is no way to know what
percentage of code written is code your end users actually care about. You may
write a continent of code, but only 0.01% of that code may actually be hit by
users. If you are using code coverage to tell you that you have greater than 0%
code coverage than you have a code organization issue or tests are not being
verified on creation. The easiest way to kick the tires is by making a test fail
to ensure it's not always passing. Tests take more effort to create because
developer's need to ensure the tests are valid and actually checking what we
want to check.</p>
<p>Here's a different approach: instrument your application to track invocations of
code paths. You can do with this tracing, structured logging, profiling replayed
traffic, etc. The technique doesn't matter, what does is the focus on what code
production users indirectly touch.</p>
<p>There are some decent descriptions on how to think about this <a href="https://kentcdodds.com/blog/how-to-know-what-to-test">from a human
perspective</a>, and any
approach that asks developer's to take a pause to reason about their code is
remarkable in my book, but actually knowing what your users are using is the
best way to determine what is code is valuable and what is dead.</p>
<p><strong>Code coverage is fool's gold.</strong></p>

            </div>
          </div>
        </div>
      </div>
    </section>
  </body>
</html>
